<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>JEP2</title><link>http://www.example.com/rss</link><description>This is the feed for items from my zotero.</description><language>en-US</language><lastBuildDate>Sun, 08 Dec 2019 22:32:17 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Untitled Response</title><link>http://www.example.com/articles/1</link><description>Frey, Bruno S.
nan</description><author>Frey, Bruno S.</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Untitled</title><link>http://www.example.com/articles/1</link><description>Autor, David H.
nan</description><author>Autor, David H.</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Retrospectives Hume on Money, Commerce, and the Science of Economics</title><link>http://www.example.com/articles/1</link><description>Schabas, Margaret; Wennerlind, Carl
nan</description><author>Schabas, Margaret; Wennerlind, Carl</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Esther Duflo: 2010 John Bates Clark Medalist</title><link>http://www.example.com/articles/1</link><description>Udry, Christopher
nan</description><author>Udry, Christopher</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Migrant Remittances</title><link>http://www.example.com/articles/1</link><description>Yang, Dean
nan</description><author>Yang, Dean</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Eight Questions about Brain Drain</title><link>http://www.example.com/articles/1</link><description>Gibson, John; McKenzie, David
The term "brain drain" dominates popular discourse on high-skilled migration, and for this reason, we use it in this article. However, as Harry Johnson noted, it is a loaded phrase implying serious loss. It is far from clear that such a loss actually occurs in practice; indeed, there is an increasing recognition of the possible benefits that skilled migration can offer both for migrants and for sending countries. This paper builds upon a recent wave of empirical research to answer eight key questions underlying much of the brain drain debate: 1) What is brain drain? 2) Why should economists care about it? 3) Is brain drain increasing? 4) Is there a positive relationship between skilled and unskilled migration? 5) What makes brain drain more likely? 6) Does brain gain exist? 7) Do high-skilled workers remit, invest, and share knowledge back home? 8) What do we know about the fiscal and production externalities of brain drain?</description><author>Gibson, John; McKenzie, David</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Economics and Emigration: Trillion-Dollar Bills on the Sidewalk?</title><link>http://www.example.com/articles/1</link><description>Clemens, Michael A.
nan</description><author>Clemens, Michael A.</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Mechanism Experiments and Policy Evaluations</title><link>http://www.example.com/articles/1</link><description>Ludwig, Jens; Kling, Jeffrey R.; Mullainathan, Sendhil
Randomized controlled trials are increasingly used to evaluate policies. How can we make these experiments as useful as possible for policy purposes? We argue greater use should be made of experiments that identify the behavioral mechanisms that are central to clearly specified policy questions, what we call "mechanism experiments." These types of experiments can be of great policy value even if the intervention that is tested (or its setting) does not correspond exactly to any realistic policy option.</description><author>Ludwig, Jens; Kling, Jeffrey R.; Mullainathan, Sendhil</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Internal Migration in the United States</title><link>http://www.example.com/articles/1</link><description>Molloy, Raven; Smith, Christopher L.; Wozniak, Abigail
nan</description><author>Molloy, Raven; Smith, Christopher L.; Wozniak, Abigail</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Killing Me Softly: The Fetal Origins Hypothesis</title><link>http://www.example.com/articles/1</link><description>Almond, Douglas; Currie, Janet
In the epidemiological literature, the fetal origins hypothesis associated with David J. Barker posits that chronic, degenerative conditions of adult health, including heart disease and type 2 diabetes, may be triggered by circumstances decades earlier, particularly, by in utero nutrition. Economists have expanded on this hypothesis, investigating a broader range of fetal shocks and circumstances and have found a wealth of later-life impacts on outcomes including test scores, educational attainment, and income, along with health. In the process, they have provided some of the most credible observational evidence in support of the hypothesis. The magnitude of the impacts is generally large. Thus, the fetal origins hypothesis has not only survived contact with economics, but has flourished.</description><author>Almond, Douglas; Currie, Janet</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Field Experiments with Firms</title><link>http://www.example.com/articles/1</link><description>Bandiera, Oriana; Barankay, Iwan; Rasul, Imran
We discuss how the use of field experiments sheds light on long-standing research questions relating to firm behavior. We present insights from two classes of experiments-within and across firms-and draw common lessons from both sets. Field experiments within firms generally aim to shed light on the nature of agency problems. Along these lines, we discuss how field experiments have provided new insights on shirking behavior and the provision of monetary and nonmonetary incentives. Field experiments across firms generally aim to uncover firms' binding constraints by exogenously varying the availability of key inputs such as labor, physical capital, and managerial capital. We conclude by discussing some of the practical issues researchers face when designing experiments and by highlighting areas for further research.</description><author>Bandiera, Oriana; Barankay, Iwan; Rasul, Imran</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Role of Theory in Field Experiments</title><link>http://www.example.com/articles/1</link><description>Card, David; DellaVigna, Stefano; Malmendier, Ulrike
nan</description><author>Card, David; DellaVigna, Stefano; Malmendier, Ulrike</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Why Economists Should Conduct Field Experiments and 14 Tips for Pulling One Off</title><link>http://www.example.com/articles/1</link><description>List, John A.
In this introduction to the symposium, I first offer an overview of the spectrum of experimental methods in economics, from laboratory experiments to the field experiments that are the subject of this symposium. I then offer some thoughts about the potential gains from doing economic research using field experiments and my own mental checklist of 14 steps to improve the chances of carrying out an economics field experiment successfully.</description><author>List, John A.</author><pubDate>Sat, 01 Jan 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Empirical Industrial Organization: A Progress Report</title><link>http://www.example.com/articles/1</link><description>Einav, Liran; Levin, Jonathan
The field of industrial organization has made dramatic advances over the last few decades in developing empirical methods for analyzing imperfect competition and the organization of markets. These new methods have diffused widely: into merger reviews and antitrust litigation, regulatory decision making, price setting by retailers, the design of auctions and marketplaces, and into neighboring fields in economics, marketing, and engineering. Increasing access to firm-level data and in some cases the ability to cooperate with firms or governments in experimental research designs is offering new settings and opportunities to apply these ideas in empirical work. This essay begins with a sketch of how the field has evolved to its current state, in particular how the field's emphasis has shifted over time from attempts to relate aggregate measures across industries toward more focused studies of individual industries. The second and primary part of the essay describes several active areas of inquiry. We also discuss some of the impacts of this research and specify topics where research efforts have been more or less successful. The last section steps back to offer a broader perspective. We address some current debates about research emphasis in the field, and more broadly about empirical methods, and offer some thoughts on where future research might go.</description><author>Einav, Liran; Levin, Jonathan</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Columbian Exchange: A History of Disease, Food, and Ideas</title><link>http://www.example.com/articles/1</link><description>Nunn, Nathan; Qian, Nancy
This paper provides an overview of the long-term impacts of the Columbian Exchange - that is, the exchange of diseases, ideas, food crops, technologies, populations, and cultures between the New World and the Old World after Christopher Columbus' voyage to the Americas in 1492. We focus on the aspects of the exchange that have been most neglected by economic studies; namely the transfer of diseases, food crops, and knowledge between the two Worlds. We pay particular attention to the effects of the exchange on the Old World.</description><author>Nunn, Nathan; Qian, Nancy</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Corporate Audits and How to Fix Them</title><link>http://www.example.com/articles/1</link><description>Ronen, Joshua
Auditors are supposed to be watchdogs, but in the last decade or so, they sometimes looked like lapdogs -- more interested in serving the companies they audited than in assuring a flow of accurate information to investors. The auditing profession is based on what looks like a structural infirmity: auditors are paid by the companies they audit. An old German proverb holds: "Whose bread I eat, his song I sing." While this saying was originally meant as a prayer of thanksgiving, the old proverb takes on a darker meaning for those who study the auditing profession. This paper begins with an overview of the practice of audits, the auditing profession, and the problems that auditors continue to face in terms not only of providing audits of high quality, but also in providing audits that investors feel comfortable trusting to be of high quality. It then turns to a number of reforms that have been proposed, including ways of building reputation, liability reform, capitalizing or insuring auditing firms, and greater competition in the auditing profession. However, none of these suggested reforms, individually or collectively, severs the agency relation between the client management and the auditors. As a result, the conflict of interest, although it can be mitigated by some of these reforms, continues to threaten auditors' independence, both real and perceived. In conclusion, I'll discuss my own proposal for financial statements insurance, which would redefine the relationship between auditors and firms in such a way that auditors would no longer be beholden to management.</description><author>Ronen, Joshua</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Markets The Credit Rating Agencies</title><link>http://www.example.com/articles/1</link><description>White, Lawrence J.
This paper will explore how the financial regulatory structure propelled three credit rating agencies - Moody's, Standard &amp; Poor's (S&amp;P), and Fitch - to the center of the U.S. bond markets - and thereby virtually guaranteed that when these rating agencies did make mistakes, these mistakes would have serious consequences for the financial sector. We begin by looking at some relevant history of the industry, including the series of events that led financial regulators to outsource their judgments to the credit rating agencies (by requiring financial institutions to use the specific bond creditworthiness information that was provided by the major rating agencies) and when the credit rating agencies shifted their business model from "investor pays" to "issuer pays." We then look at how the credit rating industry evolved and how its interaction with regulatory authorities served as a barrier to entry. We then show how these ingredients combined to contribute to the subprime mortgage debacle and associated financial crisis. Finally, we consider two possible routes for public policy with respect to the credit rating industry: One route would tighten the regulation of the rating agencies, while the other route would reduce the required centrality of the rating agencies and thereby open up the bond information process in a way that has not been possible since the 1930s.</description><author>White, Lawrence J.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Gender Gap in Secondary School Mathematics at High Achievement Levels: Evidence from the American Mathematics Competitions</title><link>http://www.example.com/articles/1</link><description>Ellison, Glenn; Swanson, Ashley
This paper uses a new data source, American Mathematics Competitions, to examine the gender gap among high school students at very high achievement levels. The data bring out several new facts. There is a large gender gap that widens dramatically at percentiles above those that can be examined using standard data sources. An analysis of unobserved heterogeneity indicates that there is only moderate variation in the gender gap across schools. The highest achieving girls in the U.S. are concentrated in a very small set of elite schools, suggesting that almost all girls with the ability to reach high math achievement levels are not doing so.</description><author>Ellison, Glenn; Swanson, Ashley</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Explaining the Gender Gap in Math Test Scores: The Role of Competition</title><link>http://www.example.com/articles/1</link><description>Niederle, Muriel; Vesterlund, Lise
The mean and standard deviation in performance on math test scores are only slightly larger for males than for females. Despite minor differences in mean performance, many more boys than girls perform at the right tail of the distribution. This gender gap has been documented for a series of math tests including the AP calculus test, the mathematics SAT, and the quantitative portion of the Graduate Record Exam (GRE). The objective of this paper is not to discuss whether the mathematical skills of males and females differ, be it a result of nurture or nature. Rather we argue that the reported test scores do not necessarily match the gender differences in math skills. We will present results that suggest that the evidence of a large gender gap in mathematics performance at high percentiles in part may be explained by the differential manner in which men and women respond to competitive test-taking environments. The effects in mixed-sex settings range from women failing to perform well in competitions, to women shying away from environments in which they have to compete. We find that the response to competition differs for men and women, and in the examined environment, gender difference in competitive performance does not reflect the difference in noncompetitive performance. We argue that the competitive pressures associated with test taking may result in performances that do not reflect those of less-competitive settings. Of particular concern is that the distortion is likely to vary by gender and that it may cause gender differences in performance to be particularly large in mathematics and for the right tail of the performance distribution. Thus the gender gap in math test scores may exaggerate the math advantage of males over females.</description><author>Niederle, Muriel; Vesterlund, Lise</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Geographic Variation in the Gender Differences in Test Scores</title><link>http://www.example.com/articles/1</link><description>Pope, Devin G.; Sydnor, Justin R.
The causes and consequences of gender disparities in standardized test scores - especially in the high tails of achievement - have been a topic of heated debate. The existing evidence on standardized test scores largely confirms the prevailing stereotypes that more men than women excel in math and science while more women than men excel in tests of language and reading. We provide a new perspective on this gender gap in test scores by analyzing the variation in these disparities across geographic areas. We illustrate that male-female ratios of students scoring in the high ranges of standardized tests vary significantly across the United States. This variation is systematic in several important ways. In particular, states where males are highly overrepresented in the top math and science scores also tend to be states where women are highly overrepresented in the top reading scores. This pattern suggests that states vary in their adherence to stereotypical gender performance, rather than favoring one sex over the other across all subjects. Furthermore, since the genetic distinction and the hormonal differences between sexes that might affect early cognitive development (that is, innate abilities) are likely the same regardless of the state in which a person happens to be born, the variation we find speaks to the nature-versus-nurture debates surrounding test scores and suggests environments significantly impact gender disparities in test scores.</description><author>Pope, Devin G.; Sydnor, Justin R.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Theory, General Equilibrium, and Political Economy in Development Economics</title><link>http://www.example.com/articles/1</link><description>Acemoglu, Daron
nan</description><author>Acemoglu, Daron</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Diagnostics before Prescription</title><link>http://www.example.com/articles/1</link><description>Rodrik, Dani
nan</description><author>Rodrik, Dani</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Uneven Growth: A Framework for Research in Development Economics</title><link>http://www.example.com/articles/1</link><description>Ray, Debraj
nan</description><author>Ray, Debraj</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Giving Credit Where It Is Due</title><link>http://www.example.com/articles/1</link><description>Banerjee, Abhijit V.; Duflo, Esther
In the last few years, field experiments have emerged as an attractive new tool in the effort to elaborate our understanding of economic issues relevant to poor countries and poor people. By enabling the researcher to precisely control the variation in the data, field experiments allow the estimation of parameters and testing of hypotheses that would be very difficult to implement with observational data. The results of this body of empirical work, in turn, have pushed theory in new directions. Much of this paper illustrates the power of this interplay between experimental and theoretical thinking. Rather than discussing this in the abstract, we focus on one area where the recent empirical work has been particularly exciting and useful - credit. Credit markets in developing countries offer up many facts and puzzles that lead us to build theories based on informational constraints and psychological limitations. The empirical work inspired by these theories, in turn, has generated both support for the theories, which then influenced policy thinking, and new puzzles, which have prompted new efforts to improve the theory. We see the substantive, two-way conversation taking place between theory and data around credit markets in developing economies as a promising template for the field.</description><author>Banerjee, Abhijit V.; Duflo, Esther</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Microeconomic Approaches to Development: Schooling, Learning, and Growth</title><link>http://www.example.com/articles/1</link><description>Rosenzweig, Mark R.
Within the field of economic development over the past 15 years or so, particularly significant advances have been made in what can be loosely called micro-development, an area defined principally by the units that are examined, not by a particular methodological approach. The units may be individuals, households, networks, banks, government agencies and so on, as opposed to countries. Within this area, economists use a wide variety of empirical methods informed to different degrees by economic models, they use data from developed and developing countries, and some use no data at all, to shed light on development questions. The best of this work speaks to the major questions of development and even informs, if not provides the foundation for, macro models of development and growth. I will illustrate the variety of approaches to development issues that microeconomists have employed by focusing on studies that illuminate and quantify the major mechanisms posited by growth theorists who highlight the role of education in fostering growth.</description><author>Rosenzweig, Mark R.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Searching for Effective Teachers with Imperfect Information</title><link>http://www.example.com/articles/1</link><description>Staiger, Douglas O.; Rockoff, Jonah E.
Over the past four decades, empirical researchers - many of them economists - have accumulated an impressive amount of evidence on teachers. In this paper, we ask what the existing evidence implies for how school leaders might recruit, evaluate, and retain teachers. We begin by summarizing the evidence on five key points, referring to existing work and to evidence we have accumulated from our research with the nation's two largest school districts: Los Angeles and New York City. First, teachers display considerable heterogeneity in their effects on student achievement gains. Second, estimates of teacher effectiveness based on student achievement data are noisy measures. Third, teachers' effectiveness rises rapidly in the first year or two of their teaching careers but then quickly levels out. Fourth, the primary cost of teacher turnover is not the direct cost of hiring and firing, but rather is the loss to students who will be taught by a novice teacher rather than one with several years of experience. Fifth, it is difficult to identify at the time of hire those teachers who will prove more effective. As a result, better teachers can only be identified after some evidence on their actual job performance has accumulated. We then explore what these facts imply for how principals and school districts should act, using a simple model in which schools must search for teachers using noisy signals of teacher effectiveness. The implications of our analysis are strikingly different from current practice. Rather than screening at the time of hire, the evidence on heterogeneity of teacher performance suggests a better strategy would be identifying large differences between teachers by observing the first few years of teaching performance and retaining only the highest-performing teachers.</description><author>Staiger, Douglas O.; Rockoff, Jonah E.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Aiming for Efficiency Rather than Proficiency</title><link>http://www.example.com/articles/1</link><description>Neal, Derek
The No Child Left Behind law is flawed for many reasons, but the most important is that it is built around proficiency targets. Proficiency rates are not useful metrics of school performance because universal proficiency is not a socially efficient goal for principals and teachers. Further, the variation in proficiency rates among schools reflects, in large part, interschool differences in student background characteristics. The designers of accountability systems must move away from systems designed around a one-size-fits-all standard and begin designing systems that organize and promote competition among schools. Well-organized competition among schools is the best vehicle for making sure that schools use public funds efficiently. If education officials pursue this paradigm, they must develop relative performance measures that assess the outcomes of these contests while making reasonable allowance for differences in student populations served by public schools. I will discuss a method for deriving context-specific measures of school performance. A percentile performance index tells public officials how often the students in a particular school or classroom perform better than students in other schools who began the year in similar circumstances with respect to their prior achievements, the compositions of their classmates, and their family backgrounds. This index of relative performance provides the information policymakers need to make preliminary judgments concerning when to reorganize a given school and give a new staff the opportunity to prove they can do better.</description><author>Neal, Derek</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Quality and Distribution of Teachers under the No Child Left Behind Act</title><link>http://www.example.com/articles/1</link><description>Hanushek, Eric A.; Rivkin, Steven G.
The main effects of No Child Left Behind on the quality of teaching are likely to come through two provisions of the act. First, NCLB establishes benchmarks based on test score pass rates that schools must meet in order to remain in good standing and avoid sanctions. Since teachers are central to student performance, this accountability component of NCLB is likely to have direct effects on both the demand for and supply of teachers and therefore on both the composition of the stock of public school teachers and the distribution of those teachers among schools. Second, NCLB explicitly requires districts to have "highly qualified" teachers, and the enunciation and enforcement of such a standard might have an additional effect on the composition of teachers. We will discuss three avenues by which these requirements might affect the quality of teachers. First, we will argue that the requirements for "highly qualified" teachers are unlikely to have had any perceptible effect on the performance of students. Second, the combination of quality requirements and the more-stringent testing environment could make teaching appear more costly and risky as a profession and thus alter the composition of new entrants, but at least so far, we find no evidence of such effects. Finally, the accountability provisions might change the dynamics of the labor market for teachers, including decisions about hiring and job separation. While not completely understood, this channel might be quite important, especially at low-performing schools where the stress of the accountability requirements is highest. We will provide new evidence from Texas on the relationship between school accountability ratings and teacher transitions both out of schools and out of grades three through eight, the grades subject to NCLB testing requirements. Finally, we offer some observations about potential policy implications and a future research agenda.</description><author>Hanushek, Eric A.; Rivkin, Steven G.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Teachers' Views on No Child Left Behind: Support for the Principles, Concerns about the Practices</title><link>http://www.example.com/articles/1</link><description>Murnane, Richard J.; Papay, John P.
In this article, we describe teachers' views of the behavioral responses the No Child Left Behind legislation has elicited and the extent to which research reveals evidence of these responses and their effects on the distribution of student achievement. We focus on teachers' reactions to three aspects of NCLB that are particularly relevant to them: 1) the testing requirements and the rules determining "Adequate Yearly Progress" (AYP) under NCLB; 2) the sanctions imposed on schools that fail to meet AYP; and 3) the requirement that all teachers of core academic subjects be "highly qualified" in their areas of teaching assignment. Overall, we find that teachers overwhelmingly support the principles underlying the No Child Left Behind legislation, including that schools should be held accountable for educating all children well. However, teachers are concerned that the incentives created by some provisions of the law have elicited unintended responses that reduce the quality of education provided to at least some children.</description><author>Murnane, Richard J.; Papay, John P.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Measurement Matters: Perspectives on Education Policy from an Economist and School Board Member</title><link>http://www.example.com/articles/1</link><description>Lang, Kevin
One of the potential strengths of the No Child Left Behind (NCLB) Act enacted in 2002 is that the law requires the production of an enormous amount of data, particularly from tests, which, if used properly, might help us improve education. As an economist and as someone who served 13 years on the School Committee in Brookline Massachusetts, until May 2009, I have been appalled by the limited ability of districts to analyze these data; I have been equally appalled by the cavalier manner in which economists use test scores and related measures in their analyses. The summary data currently provided are very hard to interpret, and policymakers, who typically lack statistical sophistication, cannot easily use them to assess progress. In some domains, most notably the use of average test scores to evaluate teachers or schools, the education community is aware of the biases and has sought better measures. The economics and statistics communities have both responded to and created this demand by developing value-added measures that carry a scientific aura. However, economists have largely failed to recognize many of the problems with such measures. These problems are sufficiently important that they should preclude any automatic link between these measures and rewards or sanctions. They do, however, contain information and can be used as a catalyst for more careful evaluation of teachers and schools, and as a lever to induce principals and other administrators to act on their knowledge.</description><author>Lang, Kevin</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Emmanuel Saez: 2009 John Bates Clark Medalist</title><link>http://www.example.com/articles/1</link><description>Bernheim, B. Douglas
Emmanuel Saez, winner of the 2009 John Bates Clark Medal, has distinguished himself by making fundamental contributions concerning critical theoretical and empirical issues within the field of public economics. He is one of those exceptional scholars whose work reflects a broad and thoroughly integrated vision. In carefully and creatively implementing that vision, he has led a remarkable resurgence of interest in tax policy research over the last decade. Emmanuel's work can be divided into five areas: the theory of optimal taxes and transfers; the measurement of income and wealth distributions; the measurement of behavioral responses to personal taxation; the taxation of corporate dividends; and retirement saving. A great deal of his work is closely interrelated across these topics, which makes the whole considerably greater than the sum of the parts. In effect, he has bridged the chasm between theory and practical policymaking by attacking the policy design problem from both sides at once. This article provides a survey of Emmanuel's work.</description><author>Bernheim, B. Douglas</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Mobile Phones and Economic Development in Africa</title><link>http://www.example.com/articles/1</link><description>Aker, Jenny C.; Mbiti, Isaac M.
Access to and use of mobile telephony in sub-Saharan Africa has increased dramatically over the past decade. Mobile telephony has brought new possibilities to the continent. Across urban-rural and rich-poor divides, mobile phones connect individuals to individuals, information, markets, and services. These effects can be particularly dramatic in rural Africa, where in many places mobile phones have represented the first modern telecommunications infrastructure of any kind. Mobile phones have greatly reduced communication costs, thereby allowing individuals and firms to send and to obtain information quickly and cheaply on a variety of economic, social, and political topics. An emerging body of research shows that the reduction in communication costs associated with mobile phones has tangible economic benefits, improving agricultural and labor market efficiency and producer and consumer welfare in specific circumstances and countries. This paper first examines the evolution of mobile phone coverage and adoption in sub-Saharan Africa over the past decade. We then explore the main channels through which mobile phones can effect economic outcomes and appraise current evidence of its potential to improve economic development. We conclude with directions for future research and outline the necessary conditions for mobile phones to promote broader economic development in Africa.</description><author>Aker, Jenny C.; Mbiti, Isaac M.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Markets State Franchise Laws, Dealer Terminations, and the Auto Crisis</title><link>http://www.example.com/articles/1</link><description>Lafontaine, Francine; Morton, Fiona Scott
nan</description><author>Lafontaine, Francine; Morton, Fiona Scott</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Other Transformation in Econometric Practice: Robust Tools for Inference</title><link>http://www.example.com/articles/1</link><description>Stock, James H.
Angrist and Pischke highlight one aspect of the research that has positively transformed econometric practice and teaching. They emphasize the rise of experiments and quasi-experiments as credible sources of identification in microeconometric studies, which they usefully term "design-based research." But in so doing, they miss an important part of the story: a second research strand aimed at developing tools for inference that are robust to subsidiary modeling assumptions. My first aim in these remarks therefore is to highlight some key developments in this area. I then turn to Angrist and Pischke's call for adopting experiments and quasi-experiments in macroeconometrics; while sympathetic, I suspect the scope for such studies is limited. I conclude with some observations on the current debate about whether experimental methods have gone too far in abandoning economic theory.</description><author>Stock, James H.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Credibility Revolution in Empirical Economics: How Better Research Design is Taking the Con out of Econometrics</title><link>http://www.example.com/articles/1</link><description>Angrist, Joshua D.; Pischke, Joern-Steffen
Since Edward Leamer's memorable 1983 paper, "Let's Take the Con out of Econometrics," empirical microeconomics has experienced a credibility revolution. While Leamer's suggested remedy, sensitivity analysis, has played a role in this, we argue that the primary engine driving improvement has been a focus on the quality of empirical research designs. The advantages of a good research design are perhaps most easily apparent in research using random assignment. We begin with an overview of Leamer's 1983 critique and his proposed remedies. We then turn to the key factors we see contributing to improved empirical work, including the availability of more and better data, along with advances in theoretical econometric understanding, but especially the fact that research design has moved front and center in much of empirical micro. We offer a brief digression into macroeconomics and industrial organization, where progress - by our lights - is less dramatic, although there is work in both fields that we find encouraging. Finally, we discuss the view that the design pendulum has swung too far. Critics of design-driven studies argue that in pursuit of clean and credible research designs, researchers seek good answers instead of good questions. We briefly respond to this concern, which worries us little.</description><author>Angrist, Joshua D.; Pischke, Joern-Steffen</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Tantalus on the Road to Asymptopia</title><link>http://www.example.com/articles/1</link><description>Leamer, Edward E.
nan</description><author>Leamer, Edward E.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>A Structural Perspective on the Experimentalist School</title><link>http://www.example.com/articles/1</link><description>Keane, Michael P.
What has always bothered me about the "experimentalist" school is the false sense of certainty it conveys. My view, like Leamer's, is that there is no way to escape the role of assumptions in statistical work, so our conclusions will always be contingent. Hence, we should be circumspect about our degree of knowledge. I present some lessons for economics from the field of marketing, a field where broad consensus has been reached on many key issues over the past twenty years. In marketing, 1) the structural paradigm is dominant, 2) the data are a lot better than in some fields of economics, and 3) there is great emphasis on external validation. Of course, good data always helps. I emphasize that the ability to do controlled experiments does not obviate the need for theory, and finally I address different approaches to model validation.</description><author>Keane, Michael P.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>But Economics Is Not an Experimental Science</title><link>http://www.example.com/articles/1</link><description>Sims, Christopher A.
The fact is, economics is not an experimental science and cannot be. "Natural" experiments and "quasi" experiments are not in fact experiments. They are rhetorical devices that are often invoked to avoid having to confront real econometric difficulties. Natural, quasi-, and computational experiments, as well as regression discontinuity design, can all, when well applied, be useful, but none are panaceas. The essay by Angrist and Pischke, in its enthusiasm for some real accomplishments in certain subfields of economics, makes overbroad claims for its favored methodologies. What the essay says about macroeconomics is mainly nonsense. Consequently, I devote the central part of my comment to describing the main developments that have helped take some of the con out of macroeconomics. Recent enthusiasm for single-equation, linear, instrumental variables approaches in applied microeconomics has led many in these fields to avoid undertaking research that would require them to think formally and carefully about the central issues of nonexperimental inference - what I see and many see as the core of econometrics. Providing empirically grounded policy advice necessarily involves confronting these difficult central issues.</description><author>Sims, Christopher A.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Taking the Dogma out of Econometrics: Structural Modeling and Credible Inference</title><link>http://www.example.com/articles/1</link><description>Nevo, Aviv; Whinston, Michael D.
Without a doubt, there has been a "credibility revolution" in applied econometrics. One contributing development has been in the improvement and increased use in data analysis of "structural methods"; that is, the use of models based in economic theory. Structural modeling attempts to use data to identify the parameters of an underlying economic model, based on models of individual choice or aggregate relations derived from them. Structural estimation has a long tradition in economics, but better and larger data sets, more powerful computers, improved modeling methods, faster computational techniques, and new econometric methods such as those mentioned above have allowed researchers to make significant improvements. While Angrist and Pischke extol the successes of empirical work that estimates "treatment effects" based on actual or quasi-experiments, they are much less sanguine about structural analysis and hold industrial organization up as an example where "progress is less dramatic." Indeed, reading their article one comes away with the impression that there is only a single way to conduct credible empirical analysis. This seems to us a very narrow and dogmatic approach to empirical work; credible analysis can come in many guises, both structural and nonstructural, and for some questions structural analysis offers important advantages. In this comment, we address the criticism of structural analysis and its use in industrial organization, and consider why empirical analysis in industrial organization differs in such striking ways from that in fields such as labor, which have recently emphasized the methods favored by Angrist and Pischke.</description><author>Nevo, Aviv; Whinston, Michael D.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Understanding the Mechanisms of Economic Development</title><link>http://www.example.com/articles/1</link><description>Deaton, Angus
In this paper, I advocate the investigation, testing, and modification of mechanisms as a progressive empirical research strategy for the field of economic development (and other areas of applied economics). I discuss three lines of work that have elucidated mechanisms that are relevant for development: 1) connections between saving and growth; 2) the determinants of commodity prices, which are a key source of income for many developing countries; and 3) some unexpected puzzles that arise in considering the linkages between income and food consumption. In each case, my discussion illustrates the positivist approach to the hypotheticodeductive method. In this approach, mechanisms are proposed, key predictions derived and tested, and if falsified, the mechanisms are rejected or modified. If the predictions of a mechanism are confirmed, if they are sufficiently specific, and if they are hard to explain in other ways, we attach additional credence to the mechanism, albeit provisionally since later evidence may undermine it. Sometimes the falsifications can be repaired by changing supplementary assumptions, and sometimes they involve long steps backwards where the model is abandoned; and often there is disagreement about which is the correct response. But the end result is an accumulation of useful knowledge and understanding.</description><author>Deaton, Angus</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Why Does the Economy Fall to Pieces after a Financial Crisis?</title><link>http://www.example.com/articles/1</link><description>Hall, Robert E.
nan</description><author>Hall, Robert E.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Financial Intermediation and Macroeconomic Analysis</title><link>http://www.example.com/articles/1</link><description>Woodford, Michael
nan</description><author>Woodford, Michael</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Economic Crisis from a Neoclassical Perspective</title><link>http://www.example.com/articles/1</link><description>Ohanian, Lee E.
nan</description><author>Ohanian, Lee E.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Natural Expectations and Macroeconomic Fluctuations</title><link>http://www.example.com/articles/1</link><description>Fuster, Andreas; Laibson, David; Mendel, Brock
nan</description><author>Fuster, Andreas; Laibson, David; Mendel, Brock</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Macroeconomics after the Crisis: Time to Deal with the Pretense-of-Knowledge Syndrome</title><link>http://www.example.com/articles/1</link><description>Caballero, Ricardo J.
The recent financial crisis has damaged the reputation of macroeconomics, largely for its inability to predict the impending financial and economic crisis. To be honest, this inability to predict does not concern me much. It is almost tautological that severe crises are essentially unpredictable, for otherwise they would not cause such a high degree of distress. What does concern me about my discipline is that its current coreby which I mainly mean the so-called dynamic stochastic general equilibrium approachhas become so mesmerized with its own internal logic that it has begun to confuse the precision it has achieved about its own world with the precision that it has about the real one. This is dangerous for both methodological and policy reasons. To be fair to our field, an enormous amount of work at the intersection of macroeconomics and corporate finance has been chasing many of the issues that played a central role during the current crisis, including liquidity evaporation, collateral shortages, bubbles, crises, panics, fire sales, risk-shifting, contagion, and the like. However, much of this literature belongs to the periphery of macroeconomics rather than to its core. I will discuss the distinction between the core and the periphery of macroeconomics as well as the futile nature of the integrationist movement-that is, the process of gradually bringing the insights of the periphery into the dynamic stochastic general equilibrium structure. I argue that the complexity of macroeconomic interactions limits the knowledge we can ever attain, and that we need to place this fact at the center of our analysis. We should consider what this complexity does to the actions and reactions of the economic agent, and seek analytical tools and macroeconomic policies that are robust to the enormous uncertainty to which we are confined.</description><author>Caballero, Ricardo J.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Shopping for Anonymous Shell Companies: An Audit Study of Anonymity and Crime in the International Financial System</title><link>http://www.example.com/articles/1</link><description>Sharman, J. C.
nan</description><author>Sharman, J. C.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Treasure Islands</title><link>http://www.example.com/articles/1</link><description>Hines, James R.
In movies and novels, tax havens are often settings for shady international deals; in practice, they are rather less flashy. Tax havens, also known as "offshore financial centers" or "international financial centers," are countries and territories that offer low tax rates and favorable regulatory policies to foreign investors. For example, tax havens typically tax inbound investment at zero or very low rates and further encourage investment with telecommunications and transportation facilities, other business infrastructure, favorable legal environments, and limited bureaucratic hurdles to starting new firms. Tax havens are small; most are islands; all but a few have populations below one million; and they have above-average incomes. The United States and other higher-tax countries frequently express concerns over how tax havens may affect their economies. Do they erode domestic tax collections; attract economic activity away from higher-tax countries; facilitate criminal activities; or reduce the transparency of financial accounts and so impede the smooth operation and regulation of legal and financial systems around the world? Do they contribute to excessive international tax competition? These concerns are plausible, albeit often founded on anecdotal rather than systematic evidence. Yet tax haven policies may also benefit other economies and even facilitate the effective operation of the tax systems of other countries. This paper evaluates evidence of the economic effects of tax havens.</description><author>Hines, James R.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Activist Fiscal Policy</title><link>http://www.example.com/articles/1</link><description>Auerbach, Alan J.; Gale, William G.; Harris, Benjamin H.
nan</description><author>Auerbach, Alan J.; Gale, William G.; Harris, Benjamin H.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Catastrophe Economics: The National Flood Insurance Program</title><link>http://www.example.com/articles/1</link><description>Michel-Kerjan, Erwann O.
nan</description><author>Michel-Kerjan, Erwann O.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Job Market for New Economists: A Market Design Perspective</title><link>http://www.example.com/articles/1</link><description>Coles, Peter; Cawley, John; Levine, Phillip B.; Niederle, Muriel; Roth, Alvin E.; Siegfried, John J.
nan</description><author>Coles, Peter; Cawley, John; Levine, Phillip B.; Niederle, Muriel; Roth, Alvin E.; Siegfried, John J.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Retrospectives An Early Supply-Side-Demand-Side Controversy: Petty, Law, Cantillon</title><link>http://www.example.com/articles/1</link><description>Berdell, John
Early modern Europe in the late seventeenth and early eighteenth centuries witnessed an unprecedented increase in the rate of economic growth, and governments entertained a wide range of proposals aimed at developing and harnessing foreign trade and emerging financial markets. In his magisterial survey of foreign trade doctrine titled Studies in the Theory of International Trade (1936), Jacob Viner pointed out that enlightened authors of that time were often nonbullionist mercantilists: they favored export promotion and import reduction not on the grounds that it would lead to an accumulation of gold, but on the grounds that it would increase trade and employment. My focus here is on how some key economists of this time period-William Petty, John Law, and Richard Cantillon-adumbrated disputes between supply-side and demand-side macroeconomics that have continued to the present day.</description><author>Berdell, John</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>How Debt Markets Have Malfunctioned in the Crisis</title><link>http://www.example.com/articles/1</link><description>Krishnamurthy, Arvind
The financial crisis that began in 2007 is especially a crisis in debt markets. A full understanding of what happened in the financial crisis requires investigation into the plumbing of debt markets. During a financial crisis, when funds often cannot be raised easily or quickly, the fundamental values for certain assets can become separated for a time from market prices, with consequences that can echo into the real economy. This article will explain in concrete ways how debt markets can malfunction, with deleterious consequences for the real economy. After a quick overview of debt markets, I discuss three areas that are crucial in all debt markets decisions: risk capital and risk aversion; repo financing and haircuts; and counterparty risk. In each of these areas, feedback effects can arise so that less liquidity and a higher cost for finance can reinforce each other in a contagious spiral. I will document the remarkable rise in the premium that investors placed on liquidity during the crisis. Next, I will show how these issues caused debt markets to break down; indeed, fundamental values and market values seemed to diverge across several markets and products that were far removed from the "toxic" subprime mortgage assets at the root of the crisis. Finally, I will discuss briefly four steps that the Federal Reserve took to ease the crisis and how each was geared to a specific systemic fault that arose during the crisis.</description><author>Krishnamurthy, Arvind</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Failure Mechanics of Dealer Banks</title><link>http://www.example.com/articles/1</link><description>Duffie, Darrell
During the recent financial crisis, major dealer banks - that is, banks that intermediate markets for securities and derivatives - suffered from new forms of bank runs. The most vivid examples are the 2008 failures of Bear Stearns and Lehman Brothers. Dealer banks are often parts of large complex financial organizations whose failures can damage the economy significantly. As a result, they are sometimes considered "too big to fail." The mechanics by which dealer banks can fail and the policies available to treat the systemic risk of their failures differ markedly from the case of conventional commercial bank runs. These failure mechanics are the focus of this article. This is not a review of the financial crisis of 2007-2009. Systemic risk is considered only in passing. Both the financial crisis and the systemic importance of large dealer banks are nevertheless obvious and important motivations.</description><author>Duffie, Darrell</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Credit Default Swaps and the Credit Crisis</title><link>http://www.example.com/articles/1</link><description>Stulz, Rene M.
Many observers have argued that credit default swaps contributed significantly to the credit crisis. Of particular concern to these observers are that credit default swaps trade in the largely unregulated over-the-counter market as bilateral contracts involving counterparty risk and that they facilitate speculation involving negative views of a firm's financial strength. Some observers have suggested that credit default swaps would not have made the crisis worse had they traded on exchanges. I conclude that credit default swaps did not cause the dramatic events of the credit crisis, that the over-the-counter credit default swaps market worked well during much of the crisis, and that exchange trading has both advantages and costs compared to over-the-counter trading. Though I argue that eliminating over-the-counter trading of credit default swaps could reduce social welfare, I also recognize that much research is needed to understand better and to quantify the social gains and costs of derivatives in general and credit default swaps in particular.</description><author>Stulz, Rene M.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Did Fair-Value Accounting Contribute to the Financial Crisis?</title><link>http://www.example.com/articles/1</link><description>Laux, Christian; Leuz, Christian
The recent financial crisis has led to a major debate about fair-value accounting. Many critics have argued that fair-value accounting, often also called mark-to-market accounting, has significantly contributed to the financial crisis or, at least, exacerbated its severity. In this paper, we assess these arguments and examine the role of fair-value accounting in the financial crisis using descriptive data and empirical evidence. Based on our analysis, it is unlikely that fair-value accounting added to the severity of the 2008 financial crisis in a major way. While there may have been downward spirals or asset-fire sales in certain markets, we find little evidence that these effects are the result of fair-value accounting. We also find little support for claims that fair-value accounting leads to excessive write-downs of banks' assets. If anything, empirical evidence to date points in the opposite direction, that is, toward the overvaluation of bank assets during the crisis.</description><author>Laux, Christian; Leuz, Christian</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Mental Retirement</title><link>http://www.example.com/articles/1</link><description>Rohwedder, Susann; Willis, Robert J.
Early retirement appears to have a significant negative impact on the cognitive ability of people in their early 60s that is both quantitatively important and causal. We obtain this finding using cross-nationally comparable survey data from the United States, England, and Europe that allow us to relate cognition and labor force status. We argue that the effect is causal by making use of a substantial body of research showing that variation in pension, tax, and disability policies explain most variation across countries in average retirement rates. (In an informal manner, we are arguing that public policies that affect the age of retirement may be used as instrumental variables to generate cross-country variation in retirement behavior in order to identify the causal effect of retirement on cognition.)</description><author>Rohwedder, Susann; Willis, Robert J.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>How Longer Work Lives Ease the Crunch of Population Aging</title><link>http://www.example.com/articles/1</link><description>Maestas, Nicole; Zissimopoulos, Julie
Population aging is not a looming crisis of the future - it is already here. Economic challenges arise when the increase in people surviving to old age and the decline in the number of young people alive to support them cause the growth in society's consumption needs to outpace growth in its productive capacity. The ultimate impact of population aging on our standard of living in the future depends a great deal on how long people choose to work before they retire from the labor force. Here, there is reason for optimism. A constellation of forces, some just now gaining momentum, has raised labor force participation at older ages at just the time it is needed. We examine the most important factors behind the increase in labor force participation realized to date: the shift in the skill composition of the workforce, and technological change. We argue that forces such as changes in the structure of employer-provided pensions and Social Security are likely to propel future increases in labor force participation at older ages. The labor market is accommodating older workers to some degree, and older men and women are themselves adapting on a number of fronts, which could substantially lessen the economic impact of population aging. Age-related health declines and the reluctance of employers to hire and retain older workers present challenges, but the outlook for future gains in labor force participation at older ages is promising.</description><author>Maestas, Nicole; Zissimopoulos, Julie</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>What the Stock Market Decline Means for the Financial Security and Retirement Choices of the Near-Retirement Population</title><link>http://www.example.com/articles/1</link><description>Gustman, Alan L.; Steinmeier, Thomas L.; Tabatabai, Nahid
This paper investigates the effect of the current recession on the retirement age population. Data from the Health and Retirement Study suggest that those approaching retirement age (early boomers ages 53 to 58 in 2006) have only 15.2 percent of their wealth in stocks, held directly or in defined contribution plans or IRAs. Their vulnerability to a stock market decline is limited by the high value of their Social Security wealth, which represents over a quarter of the total household wealth of the early boomers. In addition, their defined contribution plans remain immature, so their defined benefit plans represent sixty five percent of their pension wealth. Simulations with a structural retirement model suggest the stock market decline will lead the early boomers to postpone their retirement by only 1.5 months on average. Health and Retirement Study data also show that those approaching retirement are not likely to be greatly or immediately affected by the decline in housing prices. We end with a discussion of important difficulties facing those who would use labor market policies to increase the employment of older workers.</description><author>Gustman, Alan L.; Steinmeier, Thomas L.; Tabatabai, Nahid</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Economic Theory and the World of Practice: A Celebration of the (S, s) Model</title><link>http://www.example.com/articles/1</link><description>Caplin, Andrew; Leahy, John
It was the question of how best to balance the costs of ordering and of running out of stock against the costs of holding excess inventory that inspired Kenneth Arrow, Theodore Harris, and Jacob Marschak to introduce the (S, s) model in 1951. In this celebratory article, we show how this model not only answered important practical questions, but also opened the door to a quite startling range of important and challenging follow-up questions, many of great practical importance and analytic depth. The (S, s) model has become one of the touchstone models of economics, opening new vistas of applied economic theory to all who internalize its structure. Today it is universally applied to solve questions faced in inventory control. The core model elements, uncertainty and fixed costs of adjustment, are ubiquitous, which has resulted in its becoming the general purpose economic model of discrete adjustment. The (S, s) model has also become a profound source of inspiration for macroeconomists seeking to understand the role that discrete microeconomic adjustments play in macroeconomic fluctuations. Looking forward, we foresee rapid growth in the use of (S, s) modeling to aid households making complex and costly financial decisions, such as when and how to terminate a mortgage. In the projected era of "household operations research," new modeling challenges will arise due to enriched feedback from the world of practice.</description><author>Caplin, Andrew; Leahy, John</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Why Do Management Practices Differ across Firms and Countries?</title><link>http://www.example.com/articles/1</link><description>Bloom, Nicholas; Van Reenen, John
Economists have long puzzled over the astounding differences in productivity between firms and countries. In this paper, we present evidence on a possible explanation for persistent differences in productivity at the firm and the national level - namely, that such differences largely reflect variations in management practices. We have, over the last decade, undertaken a large survey research program to systematically measure management practices across firms, industries, and countries. Our survey approach focuses on aspects of management like systematic performance monitoring, setting appropriate targets, and providing incentives for good performance. We explain how we measure management; identify some basic patterns in our data; then turn to the question of why management practices vary so much across firms and nations. What we find is a combination of imperfectly competitive markets, family ownership of firms, regulations restricting management practices, and informational barriers allow bad management to persist.</description><author>Bloom, Nicholas; Van Reenen, John</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Retrospectives Engel Curves</title><link>http://www.example.com/articles/1</link><description>Chai, Andreas; Moneta, Alessio
Engel curves describe how household expenditure on particular goods or services depends on household income. German statistician Ernst Engel (1821-1896) was the first to investigate this relationship systematically in an article published about 150 years ago. The best-known single result from the article is "Engel's law," which states that the poorer a family is, the larger the budget share it spends on nourishment. We revisit Engel's article, including its context and the mechanics of the argument. Because the article was completed a few decades before linear regression techniques were established and income effects were incorporated into standard consumer theory, Engel was forced to develop his own approach to analyzing household expenditure patterns. We find his work contains some interesting features in juxtaposition to both the modern and classical literature. For example, Engel's way of estimating the expenditure-income relationship resembles a data-fitting technique called the "regressogram" that is nonparametric - in that no functional form is specified before the estimation. Moreover, Engel introduced a way of categorizing household expenditures in which expenditures on commodities that served the same purpose by satisfying the same underlying "want" were grouped together. This procedure enabled Engel to discuss the welfare implications of his results in terms of the Smithian notion that individual welfare is related to the satisfaction of wants. At the same time, he avoided making a priori assumptions about which specific goods were necessities, assumptions which were made by many classical economists like Adam Smith. Finally, we offer a few thoughts about some modern literature that builds on Engel's research.</description><author>Chai, Andreas; Moneta, Alessio</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Recommendations for Further Reading</title><link>http://www.example.com/articles/1</link><description>Taylor, Timothy
nan</description><author>Taylor, Timothy</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>When Safe Proved Risky: Commercial Paper during the Financial Crisis of 2007-2009</title><link>http://www.example.com/articles/1</link><description>Kacperczyk, Marcin; Schnabl, Philipp
Commercial paper is a short-term debt instrument issued by large corporations. The commercial paper market has long been viewed as a bastion of high liquidity and low risk. But twice during the financial crisis of 2007-2009, the commercial paper market nearly dried up and ceased being perceived as a safe haven. Major interventions by the Federal Reserve, including large outright purchases of commercial paper, were eventually used to support both issuers of and investors in commercial paper. We will offer an analysis of the commercial paper market during the financial crisis. First, we describe the institutional background of the commercial paper market. Second, we analyze the supply and demand sides of the market. Third, we examine the most important developments during the crisis of 2007-2009. Last, we discuss three explanations of the decline in the commercial paper market: substitution to alternative sources of financing by commercial paper issuers, adverse selection, and institutional constraints among money market funds.</description><author>Kacperczyk, Marcin; Schnabl, Philipp</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Three Arab Worlds</title><link>http://www.example.com/articles/1</link><description>Rauch, James E.; Kostyshak, Scott
Given the attention currently focused on the Arab world in part as a result of adjustments in U.S. foreign policy, a fresh look at Arab socioeconomic performance is in order. The Arab world is defined by language rather than ethnicity. The League of Arab States, formed in 1945, consists of all countries in which (a dialect of) Arabic is the spoken language of the majority. It is useful to compare the human development diversity of the Arab world to that of Latin America, another vast geographic area defined by language and culture. Our strategy in this article is therefore to disaggregate the Arab world into Arab sub-Saharan Africa, Arab fuel-endowed economies, and a remainder we call the Arab Mediterranean, and to compare these three Arab worlds to non-Arab sub-Saharan Africa, non-Arab fuel endowed economies, and the rest of the non-Arab world. We will evaluate Arab socioeconomic progress from 1970 to as close to the present as the data allow.</description><author>Rauch, James E.; Kostyshak, Scott</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>World Oil: Market or Mayhem?</title><link>http://www.example.com/articles/1</link><description>Smith, James L.
Many observers regard the world oil market as a puzzle. Why are oil prices so volatile? Why did prices spike in the summer of 2008, and what role did speculators play? How important is OPEC? Where are oil prices headed in the long run? Is "peak oil" a genuine concern? Any attempt to answer these questions must be informed and disciplined by economics. We examine the evidence on each of these issues and provide an interpretation of developments in the world oil market from the perspective of economic theory.</description><author>Smith, James L.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Economics of Two-Sided Markets</title><link>http://www.example.com/articles/1</link><description>Rysman, Marc
Broadly speaking, a two-sided market is one in which 1) two sets of agents interact through an intermediary or platform, and 2) the decisions of each set of agents affects the outcomes of the other set of agents, typically through an externality. In the case of a video game system, for instance PlayStation, the intermediary is the console producer - Sony - while the two sets of agents are consumers and video game developers. Neither consumers nor game developers will be interested in the PlayStation if the other party is not. Similarly, a successful payment card requires both consumer usage and merchant acceptance, where both consumers and merchants value each others' participation. Many more products fit into this paradigm, such as search engines, newspapers, and almost any advertiser-supported media (examples in which consumers typically negatively value, rather than positively value, the participation of the other side), as well as most software or title-based operating systems and consumer electronics. This paper seeks to explain what two-sided markets are and why they interest economists. I discuss the strategies that firms typically consider, and I highlight a number of puzzling outcomes from the perspective of the economics of two-sided markets. Finally, I consider the implications for public policy, particularly antitrust and regulatory policy, where there have been a number of recent issues involving media, computer operating systems, and payment cards.</description><author>Rysman, Marc</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Interview with Edmund S. Phelps</title><link>http://www.example.com/articles/1</link><description>Vane, Howard R.; Mulhearn, Chris
Edmund S. Phelps has been McVickar Professor of Political Economy at Columbia University in New York City, New York, since 1982 and director of the Center on Capitalism and Society at Columbia University's Earth Institute since 2001. In 2006, he was awarded the Nobel Memorial Prize in Economic Science "for his analysis of intertemporal tradeoffs in macroeconomic policy." We interviewed Professor Phelps at his hotel in San Francisco, on January 3, 2009, while attending the annual meeting of the Allied Social Science Associations.</description><author>Vane, Howard R.; Mulhearn, Chris</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Grade Information and Grade Inflation: The Cornell Experiment</title><link>http://www.example.com/articles/1</link><description>Bar, Talia; Kadiyali, Vrinda; Zussman, Asaf
Grade inflation and high grade levels have been subjects of concern and public debate in recent decades. In the mid-1990s, Cornell University's Faculty Senate had a number of discussions about grade inflation and what might be done about it. In April 1996, the Faculty Senate voted to adopt a new grade reporting policy which had two parts: 1) the publication of course median grades on the Internet; and 2) the reporting of course median grades in students' transcripts. The policy change followed the determination of a university committee that "it is desirable for Cornell University to provide more information to the reader of a transcript and produce more meaningful letter grades." It was hoped that "More accurate recognition of performance may encourage students to take courses in which the median grade is relatively low." The median grade policy has remained to date only partially implemented: median grades have been reported online since 1998 but do not yet appear in transcripts. We evaluate the effect of the implemented policy on patterns of course choice and grade inflation. Specifically, we test two related hypotheses: First, all else being equal, the availability of online grade information will lead to increased enrollment into leniently graded courses. Second, high-ability students will be less attracted to the leniently graded courses than their peers. Building on these results we perform an exercise that identifies the extent to which the change in student behavior resulted in an increase in the university-wide mean grade.</description><author>Bar, Talia; Kadiyali, Vrinda; Zussman, Asaf</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>What Are Grades Made Of?</title><link>http://www.example.com/articles/1</link><description>Achen, Alexandra C.; Courant, Paul N.
The term "grade inflation" covers a multitude of phenomena, some of which are even alleged to be sins. Continuing increases in average grades have been widely documented in many universities over the last several decades. Also widely documented, and often associated with grade inflation, are systematic differences in grade levels by field of study, with a common belief that the sciences and math grade harder than the social sciences, which in turn grade harder than the humanities - and that economics behaves more like the natural sciences than like the social sciences. The general persistence of these relative differences in grades seem to us to be more interesting and more difficult to explain than the persistence of modest grade inflation in general, and they are the principal focus of this paper. Why, for example, should average grades in English be much higher than average grades in chemistry? And what is going on when relative grades change, when a department's grading practices change markedly relative to other departments? We explore such questions using detailed data on grades at the University of Michigan from Fall 1992 through Winter 2008.</description><author>Achen, Alexandra C.; Courant, Paul N.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Subsidizing Creativity through Network Design: Zero-Pricing and Net Neutrality</title><link>http://www.example.com/articles/1</link><description>Lee, Robin S.; Wu, Tim
This paper focuses on the pricing aspect of the "net neutrality" debate - in particular, the de facto ban on fees levied by Internet service providers on content providers to reach users. This "zero-price" rule may prove desirable for several reasons. Using a two-sided market analysis, we suggest that it subsidizes creativity and innovation in new content creation - goals shared by copyright and patent laws. The rule also helps to solve a coordination problem: since Internet service providers do not completely internalize the effects of their own pricing decisions, lack of regulation may lead to even higher fees charged by all. Finally, allowing for such fees runs the risk of creating horizontally differentiated Internet service providers with different libraries of accessible content, thereby foreclosing consumers and leading to Internet fragmentation.</description><author>Lee, Robin S.; Wu, Tim</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Online Advertising Industry: Economics, Evolution, and Privacy</title><link>http://www.example.com/articles/1</link><description>Evans, David S.
Online advertising accounts for almost 9 percent of all advertising in the United States. This share is expected to increase as more media is consumed over the Internet and as more advertisers shift spending to online technologies. The expansion of Internet-based advertising is transforming the advertising business by providing more efficient methods of matching advertisers and consumers and transforming the media business by providing a source of revenue for online media firms that competes with traditional media firms. The precipitous decline of the newspaper industry is one manifestation of the symbiotic relationship between online content and advertising. Online-advertising is provided by a series of interlocking multisided platforms that facilitate the matching of advertisers and consumers. These intermediaries increasingly make use of detailed individual data, predictive methods, and matching algorithms to create more efficient matches between consumers and advertisers. Some of their methods raise public policy issues that require balancing benefits from providing consumers more valuable advertising against the possible loss of valuable privacy.</description><author>Evans, David S.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Priced and Unpriced Online Markets</title><link>http://www.example.com/articles/1</link><description>Edelman, Benjamin
Some online resources are free and others are not - but it can be hard to predict which resources are in which category. In some cases, users are charged for things such as web-based e-mail, wireless Internet access, and software, while in other cases, they aren't. Zero prices offer important benefits, even relative to small positive prices. For one, fee-free access reduces transaction costs - eliminating the need for billing systems as well as, in many cases, account setup, usernames, and the like. Furthermore, zero prices seem to create an environment of experimentation and progress for products and consumers. Finally, consumers overwhelmingly favor zero-price products, even beyond what might be predicted by their ordinary efforts to maximize consumer surplus. Yet experience in other contexts offers cause for concern. Although marginal costs may be near zero for many levels of use of online resources, costs generally eventually increase as usage nears a capacity constraint given by technological capability or system design. More generally, experience in other contexts repeatedly reveals overconsumption, scarcity, and even hoarding when resources are provided without charge. With competing forces both supporting and opposing zero prices, typical Internet-related activities - like surfing the web, web searches, and e-mail, along with behind-the-scenes practices like domain names and the allocation of IP (Internet protocol) addresses - present a natural context to reevaluate our sense of the tradeoffs that arise between free and a positive price.</description><author>Edelman, Benjamin</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Economics of Online Crime</title><link>http://www.example.com/articles/1</link><description>Moore, Tyler; Clayton, Richard; Anderson, Ross
This paper will focus on online crime, which has taken off as a serious industry since about 2004. Until then, much of the online nuisance came from amateur hackers who defaced websites and wrote malicious software in pursuit of bragging rights. But now criminal networks have emerged - online black markets in which the bad guys trade with each other, with criminals taking on specialized roles. Just as in Adam Smith's pin factory, specialization has led to impressive productivity gains, even though the subject is now bank card PINs rather than metal ones. Someone who can collect bank card and PIN data, electronic banking passwords, and the information needed to apply for credit in someone else's name can sell these data online to anonymous brokers. The brokers in turn sell the credentials to specialist cashiers who steal and then launder the money. We will examine the data on online crime; discuss the collective-action aspects of the problem; demonstrate how agile attackers shift across national borders as earlier targets wise up to their tactics; describe ways to improve law-enforcement coordination; and we explore how defenders' incentives affect the outcomes.</description><author>Moore, Tyler; Clayton, Richard; Anderson, Ross</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Retrospectives Trouble in the Inaugural Issue of the American Economic Review: The Cross/Eaves Controversy</title><link>http://www.example.com/articles/1</link><description>May, Ann Mari; Dimand, Robert W.
The papers from the first year of the American Economic Review are included in the Archives of the American Economic Association. While researching the early years of the AEA, Ann Mari May came across a folder marked "Controversies, Criticisms, etc."-which stood out in the midst of a review of AEA minutes and reports. This folder included a bulky file on what AER Editor Davis Rich Dewey would come to refer to as the "Cross/Eaves Controversy"-a controversy that, according to a letter he wrote, would give him "no end of trouble." The trouble erupted with a book review that appeared in the first issue of the American Economic Review. The review, written by Ira Cross, addressed a book by Lucile Eaves entitled A History of California Labor Legislation. The controversy that ensued illustrates the eternally fascinating interaction of the reviewer and the reviewed and casts a revealing light on the era's standards and rituals of scholarly conduct, on the drawing of disciplinary boundaries as economics became a more distinct academic discipline, and on the differing treatment of men and women in the academic life of the time.</description><author>May, Ann Mari; Dimand, Robert W.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Recommendations for Further Reading Comments</title><link>http://www.example.com/articles/1</link><description>Johnston, Carl
nan</description><author>Johnston, Carl</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Field Experiments in Class Size from the Early Twentieth Century</title><link>http://www.example.com/articles/1</link><description>Rockoff, Jonah
A vast majority of adults believe that class size reductions are a good way to improve the quality of public schools. Reviews of the research literature, on the other hand, have provided mixed messages on the degree to which class size matters for student achievement. Here I will discuss a substantial, but overlooked, body of experimental work on class size that developed prior to World War II. These field experiments did not have the benefit of modern econometrics, and only a few were done on a reasonably large scale. However, they often used careful empirical designs, and the collective magnitude of this body of work is considerable. Moreover, this research produced little evidence to suggest that students learn more in smaller classes, which stands in contrast to some, though not all, of the most recent work by economists. In this essay, I provide an overview of the scope and breadth of the field experiments in class size conducted prior to World War II, the motivations behind them, and how their experimental designs were crafted to deal with perceived sources of bias. I discuss how one might interpret the findings of these early experimental results alongside more recent research.</description><author>Rockoff, Jonah</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Liabilities and Risks of State-Sponsored Pension Plans</title><link>http://www.example.com/articles/1</link><description>Novy-Marx, Robert; Rauh, Joshua D.
As of December 2008, state governments had approximately $1.94 trillion set aside in pension funds for their employees. How does the value of these assets compare to the present value of states' pension liabilities? Just as future Social Security and Medicare liabilities do not appear in the headline numbers of the U.S. federal debt, the financial liability from underfunded public pensions does not appear in the headline numbers of state debt. If pensions are underfunded, then the gap between pension assets and liabilities is off-balance-sheet government debt. We show that government accounting standards require states to use procedures that severely understate their liabilities. We then discuss the true economic funding of state public pension plans. Using market-based discount rates that reflect the risk profile of the pension liabilities, we calculate that the present value of the already-promised pension liabilities of the 50 U.S. states amount to $5.17 trillion, assuming that states cannot default on pension benefits that workers have already earned. Net of the $1.94 trillion in assets, these pensions are underfunded by $3.23 trillion. This "pension debt" dwarfs the states' publicly traded debt of $0.94 trillion. And we show that even before the market collapse of 2008, the system was economically severely underfunded, though public actuarial reports presented the plans' funding status in a more favorable light.</description><author>Novy-Marx, Robert; Rauh, Joshua D.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Mortality Inequality</title><link>http://www.example.com/articles/1</link><description>Peltzman, Sam
The paper describes how changes in the inequality of lifetimes have contributed to changes in the social distribution of welfare. I address the following questions: How can we measure inequality of lifetimes? How has this kind of inequality changed over time? How is this inequality related to increased longevity? How do these trends differ across and within countries? Unequal longevity was once a major source of social inequality, perhaps even more important in some sense than income inequality, for a long time. But over the last century, this inequality has declined drastically in high-income countries and is now comparatively trivial.</description><author>Peltzman, Sam</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Taxation in Theory and Practice</title><link>http://www.example.com/articles/1</link><description>Mankiw, N. Gregory; Weinzierl, Matthew; Yagan, Danny
The optimal design of a tax system is a topic that has long fascinated economic theorists and flummoxed economic policymakers. This paper explores the interplay between tax theory and tax policy. It identifies key lessons policymakers might take from the academic literature on how taxes ought to be designed, and it discusses the extent to which these lessons are reflected in actual tax policy.</description><author>Mankiw, N. Gregory; Weinzierl, Matthew; Yagan, Danny</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Playing the Admissions Game: Student Reactions to Increasing College Competition</title><link>http://www.example.com/articles/1</link><description>Bound, John; Hershbein, Brad; Long, Bridget Terry
Gaining entrance to a four-year college or university, particularly a selective institution, has become increasingly competitive over the last several decades. We document this phenomenon and show how it has varied across different parts of the student ability distribution and across regions, with the most pronounced increases in competition being found among higher-ability students and in the Northeast. Additionally, we explore how the college preparatory behavior of high school seniors has changed in response to the growth in competition. We also discuss the theoretical implications of increased competition on longer-term measures of learning and achievement and attempt to test them empirically; the evidence and related literature, while limited, suggests little long-term benefit.</description><author>Bound, John; Hershbein, Brad; Long, Bridget Terry</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Changing Selectivity of American Colleges</title><link>http://www.example.com/articles/1</link><description>Hoxby, Caroline M.
Over the past few decades, the average college has not become more selective: the reverse is true, though not dramatically. People who believe that college selectivity is increasing may be extrapolating from the experience of a small number of colleges such as members of the Ivy League, Stanford, Duke, and so on. These colleges have experienced rising selectivity, but their experience turns out to be the exception rather than the rule. Only the top 10 percent of colleges are substantially more selective now than they were in 1962. Moreover, at least 50 percent of colleges are substantially less selective now than they were in 1962. To understand changing selectivity, we must focus on how the market for college education has re-sorted students among schools as the costs of distance and information have fallen. In the past, students' choices were very sensitive to the distance of a college from their home, but today, students, especially high-aptitude students, are far more sensitive to a college's resources and student body. It is the consequent re-sorting of students among colleges that has, at once, caused selectivity to rise in a small number of colleges while simultaneously causing it to fall in other colleges. This has had profound implications for colleges' resources, tuition, and subsidies for students. I demonstrate that the stakes associated with choosing a college are greater today than they were four decades ago because very selective colleges are offering very large per-student resources and per-student subsidies, enabling admitted students to make massive human capital investments.</description><author>Hoxby, Caroline M.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Changing Household Financial Opportunities and Economic Security</title><link>http://www.example.com/articles/1</link><description>Dynan, Karen E.
Households have experienced an expansion of financial opportunities over the past several decades. Expanded financial opportunities, such as the democratization of credit and new lending approaches, can yield benefits in terms of household economic security. However, the financial crisis that began in 2007 has powerfully illustrated that expanded financial opportunities can also pose dangers for households. By increasing the scope for investment in risky assets, people may end up with larger swings in wealth than they had anticipated. Households may borrow too much and then face obligations that are unsustainable given their resources. To explore these issues, I examine household data on wealth, assets, and liabilities going back 25 years and, in some cases, 45 years. I argue that changes in household finances in the decades leading up to the mid-1990s - including the gradual rise in indebtedness - likely increased household well-being, on balance, and contributed to a decline in aggregate economic volatility. However, changes in finances since the mid-1990s - in particular, a much sharper rate of increase in household debt - appear to have been destabilizing for many individual households and ultimately for the economy as a whole. I consider how the lessons learned in the current crisis might change household financial opportunities and choices going forward.</description><author>Dynan, Karen E.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Online Comments for American Economic Association Journals</title><link>http://www.example.com/articles/1</link><description>Autor, David H.
nan</description><author>Autor, David H.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Market-based Policy Options to Control US Greenhouse Gas Emissions</title><link>http://www.example.com/articles/1</link><description>Metcalf, Gilbert E.
The United States is moving closer to enacting a policy to reduce domestic emissions of greenhouse gases. A key element in any plan to reduce emissions will be to place a price on greenhouse gas emissions. This paper discusses the different approaches that can be taken to price emissions and assesses their strengths and weaknesses.</description><author>Metcalf, Gilbert E.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Economic Effects of Climate Change</title><link>http://www.example.com/articles/1</link><description>Tol, Richard S. J.
I review the literature on the economic impacts of climate change, an externality that is unprecedentedly large, complex, and uncertain. Only 14 estimates of the total damage cost of climate change have been published, a research effort that is in sharp contrast to the urgency of the public debate and the proposed expenditure on greenhouse gas emission reduction. These estimates show that climate change initially improves economic welfare. However, these benefits are sunk. Impacts would be predominantly negative later in the century. Global average impacts would be comparable to the welfare loss of a few percent of income, but substantially higher in poor countries. Still, the impact of climate change over a century is comparable to economic growth over a few years. There are over 200 estimates of the marginal damage cost of carbon dioxide emissions. The uncertainty about the social cost of carbon is large and right-skewed. For a standard discount rate, the expected value is $50/tC, which is much lower than the price of carbon in the European Union but much higher than the price of carbon elsewhere. Current estimates of the damage costs of climate change are incomplete, with positive and negative biases. Most important among the missing impacts are the indirect effects of climate change on economic development; large-scale biodiversity loss; low-probability, high-impact scenarios; the impact of climate change on violent conflict; and the impacts of climate change beyond 2100. From a welfare perspective, the impact of climate change is problematic because population is endogenous, and because policy analyses should separate impatience, risk aversion, and inequity aversion between and within countries.</description><author>Tol, Richard S. J.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Coming Global Climate-Technology Revolution</title><link>http://www.example.com/articles/1</link><description>Barrett, Scott
Emissions of CO2 and other greenhouse gases can be reduced significantly using existing technologies, but stabilizing concentrations will require a technological revolution-a "revolution" because it will require fundamental change, achieved within a relatively short period of time. Inspiration for a climate-technology revolution is often drawn from the Apollo space program or the Manhattan Project, but averting dangerous climate change cannot be "solved" by a single new technology, deployed by a single government. The technological changes needed to address climate change fundamentally will have to be pervasive; they will have to involve markets; and they will have to be global in scope. My focus in this paper is not on the moderate emission reductions that can be achieved using existing technologies, but on the breakthrough technologies that are needed to reduce emissions dramatically. The challenges are formidable. Indeed, it is possible that the revolution needed to dramatically reduce emissions of greenhouse gases will fail. Should the climate change abruptly, the incentive to "engineer" the climate will be strong. There will be a climate-technology revolution, but its nature will depend on the institutions we develop to address the challenge we face.</description><author>Barrett, Scott</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Role of Prices in Measuring the Poor's Living Standards</title><link>http://www.example.com/articles/1</link><description>Broda, Christian; Leibtag, Ephraim; Weinstein, David E.
In this paper, we revisit two pieces of conventional wisdom in the current debate about poverty, paying close attention to the price data underlying these findings: that the poor pay more than households of higher income for the goods and services they purchase; and that poverty rates, at least as measured by the U.S. Census, have remained essentially flat since the late 1960s, raising questions about the success of the policies implemented to reduce poverty. By examining scanner data on thousands of household purchases, we find that the poor pay less-not more-for the goods they purchase. And by extending the advances on price measurement in the recent decade back to the 1970s, we find that current poverty rates are less than half of the official numbers.</description><author>Broda, Christian; Leibtag, Ephraim; Weinstein, David E.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Consumer Shopping Behavior: How Much Do Consumers Save?</title><link>http://www.example.com/articles/1</link><description>Griffith, Rachel; Leibtag, Ephraim; Leicester, Andrew; Nevo, Aviv
This paper documents the potential and actual savings that consumers realize from four particular types of purchasing behavior: purchasing on sale; buying in bulk (at a lower per unit price); buying generic brands; and choosing outlets. How much can and do households save through each of these behaviors? How do these patterns vary with consumer demographics? We use data collected by a marketing firm on all food purchases brought into the home for a large, nationally representative sample of U.K. households in 2006. We are interested in how consumer choice affects the measurement of price changes. In particular, a standard price index based on a fixed basket of goods will overstate the rise in the true cost of living because it does not properly consider sales and bulk purchasing. According to our measures, the extent of this bias might be of the same or even greater magnitude than the better-known substitution and outlet biases.</description><author>Griffith, Rachel; Leibtag, Ephraim; Leicester, Andrew; Nevo, Aviv</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Nominal Share Price Puzzle</title><link>http://www.example.com/articles/1</link><description>Weld, William C.; Michaely, Roni; Thaler, Richard H.; Benartzi, Shlomo
The average nominal share prices of common stocks traded on the New York Stock Exchange have remained constant at approximately $35 per share since the Great Depression as a result of stock splits. It is surprising that U.S. firms actively maintained constant nominal prices for their shares while general prices in the economy went up more than tenfold. This is especially puzzling given that commissions paid by investors on trading ten $35 shares are about ten times those paid on a single $350 share. We review potential explanations including signaling and optimal trading ranges and find that none of the existing theories are able to explain the observed constant nominal prices. We suggest that the evidence is consistent with the idea that customs and norms can explain the nominal price puzzle.</description><author>Weld, William C.; Michaely, Roni; Thaler, Richard H.; Benartzi, Shlomo</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>(Un)Happiness in Transition</title><link>http://www.example.com/articles/1</link><description>Guriev, Sergei; Zhuravskaya, Ekaterina
Despite strong growth performance in transition economies in the last decade, residents of transition countries report abnormally low levels of life satisfaction. Using data from the World Values Survey and other sources, we study various explanations of this phenomenon. First, we document that the disparity in life satisfaction between residents of transition and nontransition countries is much larger among the elderly. Second, we find that deterioration in public goods provision, an increase in macroeconomic volatility, and a mismatch of human capital of residents educated before transition (which disproportionately affects the aged population) explain a great deal of the difference in life satisfaction between transition countries and other countries with similar income and other macroeconomic conditions. The rest of the gap is explained by the difference in the quality of the samples. As in other countries, life satisfaction in transition countries is strongly related to income; but, due to a higher nonresponse of high-income individuals in transition countries, the survey-data estimates of the recent increase in life satisfaction, driven by 10-year sustained economic growth in transition region, are biased downwards. The evidence suggests that if the region keeps growing, life satisfaction in transition countries will catch up with the "normal" level in the near future.</description><author>Guriev, Sergei; Zhuravskaya, Ekaterina</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Faculty without Students: Resource Allocation in Higher Education</title><link>http://www.example.com/articles/1</link><description>Johnson, William R.; Turner, Sarah
Colleges and universities display substantial differences in the ratio of students to faculty across fields or disciplines. At Harvard University, for example, economics has about 16 students majoring in the subject per full-time-teaching equivalent, while in other departments such as astronomy, Slavic, German, and Celtic, the number of teaching faculty exceeds the number of student majors. We begin by presenting some evidence on the extent of the variation in faculty resource allocation by field and the broad changes over the last several decades. We then consider potential economic explanations for these striking patterns. For example, a basic education production function, which seeks to maximize aggregate student learning subject to a faculty salary budget constraint, will require that faculty be allocated across fields so that relative marginal gains in student learning equal relative faculty salaries. Differences across fields in student-faculty ratios could then arise either from differences in the pedagogical technology across fields or variation in relative faculty salaries. Additional university goals, such as research and graduate program productivity, or adjustment costs, as imposed by the tenure system, could also generate variation across fields in student-faculty ratios. However, we have only limited evidence that these arguments can explain the ongoing disparities in student-faculty ratios across fields and disciplines, which suggests that a substantial part of the explanation may reside in the politics rather than the economics of decision making in institutions of higher education.</description><author>Johnson, William R.; Turner, Sarah</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Legal Realism for Economists</title><link>http://www.example.com/articles/1</link><description>Stephenson, Matthew C.
Economists have made great progress in understanding the incentives and behavior of actors who operate outside of traditional economic markets, including voters, legislators, and bureaucrats. The incentives and behavior of judges, however, remain largely opaque. Do judges act as neutral third-party enforcers of substantive decisions made by others? Are judges "ordinary" policymakers who advance whatever outcomes they favor without any special consideration for law as such? Emerging recent scholarship has started to explore more nuanced conceptions of how law, facts, and judicial preferences may interact to influence judicial decisions. This work develops a perspective on judging that can usefully be understood as the modern manifestation of American Legal Realism, a jurisprudential movement of lawyers, judges, and law professors that flourished in the early twentieth century. The purpose of this essay is to introduce, in simplified form, the Realist account of judicial decision making; to contrast this view with alternative theories about law and judging; and to sketch out how a more explicit integration of the Realists' conceptual insights about law and judicial behavior might enrich the rapidly expanding economic work in this field.</description><author>Stephenson, Matthew C.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Retrospectives: Who Said "Debauch the Currency": Keynes or Lenin?</title><link>http://www.example.com/articles/1</link><description>White, Michael V.; Schuler, Kurt
One frequently quoted passage from the work of John Maynard Keynes is that "the best way to destroy the capitalist system [is] to debauch the currency." The passage, attributed to Vladimir Illyich Lenin, appears in Keynes' book The Economic Consequences of the Peace, which became an international bestseller when it was published in 1919. Economic historian Frank W. Fetter and others have expressed doubt that Keynes was really quoting Lenin because they found no such statement in Lenin's collected published writings. Fetter suggested that Keynes based his remark on stories about what the Soviets were supposed to be saying that he heard at the Paris peace conference of 1919. It is now possible to show that Keynes based his remark on a report of an interview with Lenin published by London and New York newspapers in April 1919. Keynes' discussion of inflation in the Economic Consequences can then be read as an extended commentary on the remarks attributed to Lenin in the interview. While the report of the interview was not reprinted after 1919, it will be also shown here that Lenin responded to Keynes in a speech that was reprinted in his Collected Works.</description><author>White, Michael V.; Schuler, Kurt</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Job Loss and the Fraying of the Implicit Employment Contract</title><link>http://www.example.com/articles/1</link><description>Hallock, Kevin F.
Most workers have one employment contract that is explicit and another one that is implicit. The explicit employment contract specifies working hours, compensation, and job tasks. The implicit contract involves expectations about the extent to which the employment relationship is likely to continue over time. Will the firms will seek to avoid mass layoffs unless or until absolutely necessary? Will firms cushion the wages and compensation of employees to some extent from broad swings in the economy? Will employees show some degree of loyalty to the firm? This paper will argue that, along a number of dimensions, the nature of the worker-firm employment relationship may have changed substantially in recent years - a group of changes that as a whole have negatively affected the lives of workers and produced modest, if any, benefits for firms. If employers have become less involved with cushioning the blow of unemployment and avoiding layoffs where possible, then public policy might have a role to play in spreading the burden of a down labor market so that the burden is not borne so heavily by those who lose their jobs entirely.</description><author>Hallock, Kevin F.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Evolution of Medical Spending Risk</title><link>http://www.example.com/articles/1</link><description>Gruber, Jonathan; Levy, Helen
How has the economic risk of health spending changed over time for U.S. households? We describe trends in aggregate health spending in the United States and how private insurance markets and public insurance programs have changed over time. We then present evidence from Consumer Expenditure Survey microdata on how the distribution of household spending on health - that is, out-of-pocket payments for medical care plus the household's share of health insurance premiums - has changed over time. This distribution has shifted up over time - households spend more on medical care and insurance than they used to - but for the purposes of measuring change in risk, it is not the mean but the dispersion of this distribution that is of interest. We consider two measures of dispersion that serve as proxies for household risk: the standard deviation of the distribution of household health spending and the ratio of the 90th percentile of spending to the median (the so-called "90/50 gap"). We find, surprisingly, that neither has increased despite the rapid rise in aggregate health spending. This conclusion holds true for broad subgroups of the population (for example, the nonelderly as a group) but not for some narrowly-defined subgroups (for example, low-income families with children). We next consider how much risk households should face, from the perspective of economic efficiency. Household risk may not have changed much over the past several decades, but do we have any evidence that this level represents either too much or too little risk? Finally, we discuss implications for public policy - in particular, for current debates over expanding health insurance coverage to the uninsured.</description><author>Gruber, Jonathan; Levy, Helen</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Rising Instability of US Earnings</title><link>http://www.example.com/articles/1</link><description>Gottschalk, Peter; Moffitt, Robert
The inequality of earnings and of family incomes in the United States has increased since the late 1970s. The large rise in earnings inequality between the 1970s and the 1990s could reflect either a rise in disparity of permanent incomes, a rise in earnings instability, or some portion of both. In this paper, we provide longitudinal measures that separate changes in income inequality into changes that permanently change income to new levels and those that only reflect transitory change. We refer to the latter as changes in "income instability" and discuss how the instability of individual earnings and family income in the United States has evolved - as a whole as well as for different types of individuals and families - over the last quarter century. We consider alternative definitions of instability that have been proposed, and establish that all studies find that instability is considerably higher today than in the mid-1970s. This increase in instability is not a recent phenomenon. Earnings instability rose sharply in the late 1970s and early 1980s, then stabilized at these high levels through the recent period, although it may be increasing once again. We also discuss the factors that may be driving this increase in instability.</description><author>Gottschalk, Peter; Moffitt, Robert</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Economics of Structured Finance</title><link>http://www.example.com/articles/1</link><description>Coval, Joshua; Jurek, Jakub; Stafford, Erik
This paper investigates the spectacular rise and fall of structured finance. The essence of structured finance activities is the pooling of economic assets like loans, bonds, and mortgages, and the subsequent issuance of a prioritized capital structure of claims, known as tranches, against these collateral pools. As a result of the prioritization scheme used in structuring claims, many of the manufactured tranches are far safer than the average asset in the underlying pool. This ability of structured finance to repackage risks and to create "safe" assets from otherwise risky collateral led to a dramatic expansion in the issuance of structured securities, most of which were viewed by investors to be virtually risk-free and certified as such by the rating agencies. At the core of the recent financial market crisis has been the discovery that these securities are actually far riskier than originally advertised. We examine how the process of securitization allowed trillions of dollars of risky assets to be transformed into securities that were widely considered to be safe. We highlight two features of structured finance products - the extreme fragility of their ratings to modest imprecision in evaluating underlying risks, and their exposure to systematic risks - that go a long way in explaining the spectacular rise and fall of structured finance. We conclude with an assessment of what went wrong and the relative importance of rating agency errors, investor credulity, and perverse incentives and suspect behavior on the part of issuers, rating agencies, and borrowers.</description><author>Coval, Joshua; Jurek, Jakub; Stafford, Erik</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Foreign Aid Practices Reply</title><link>http://www.example.com/articles/1</link><description>Anonymous
nan</description><author>Anonymous</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Foreign Aid Practices</title><link>http://www.example.com/articles/1</link><description>Berglof, Erik
nan</description><author>Berglof, Erik</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Foreign Aid Practices</title><link>http://www.example.com/articles/1</link><description>Ramankutty, Ramesh
nan</description><author>Ramankutty, Ramesh</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Retrospectives On the Definition of Economics</title><link>http://www.example.com/articles/1</link><description>Backhouse, Roger E.; Medema, Steven G.
Modern economists do not subscribe to a homogeneous definition of their subject. Surveying definitions of economics from contemporary principles of economics textbooks, we find that economics is the study of the economy, the study of the coordination process, the study of the effects of scarcity, the science of choice, and the study of human behavior. At a time when economists are tackling subjects as diverse as growth, auctions, crime, and religion with a methodological toolkit that includes real analysis, econometrics, laboratory experiments, and historical case studies, and when they are debating the explanatory roles of rationality and behavioral norms, any concise definition of economics is likely to be inadequate. This lack of agreement on a definition does not necessarily pose a problem for the subject. Economists are generally guided by pragmatic considerations of what works or by methodological views emanating from various sources, not by formal definitions: to repeat the comment attributed to Jacob Viner, economics is what economists do. However, the way the definition of economics has evolved is more than a historical curiosity. At times, definitions are used to justify what economists are doing. Definitions can also reflect the direction in which their authors want to see the subject move and can even influence practice.</description><author>Backhouse, Roger E.; Medema, Steven G.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Markets Red Light States: Who Buys Online Adult Entertainment?</title><link>http://www.example.com/articles/1</link><description>Edelman, Benjamin
This paper studies the adult online entertainment industry, particularly the consumption side of the market. In particular, it focuses on the demographics and consumption patterns of those who subscribe to adult entertainment websites. On the surface, this business would seem to face a number of obstacles. Regulatory and legal barriers have already been mentioned. In addition, those charging for access to adult entertainment face competition from similar content available without a fee. In the context of adult entertainment, free access offers consumers an extra benefit: online payments tend to create records documenting the fact of a customer's purchase; consumers of free content may feel more confident that their purchases will remain confidential. More broadly, measured levels of religiosity in American are high. On the other hand, social critics often argue that the rise of Internet pornography is contributing to a coarsening of American culture. Do consumption patterns of online adult entertainment reveal two separate Americas? Or is the consumption of online adult entertainment widespread, regardless of legal barriers, potential for embarrassment, and even religious conviction?</description><author>Edelman, Benjamin</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The US Equity Return Premium: Past, Present, and Future</title><link>http://www.example.com/articles/1</link><description>DeLong, J. Bradford; Magin, Konstantin
For more than a century, diversified long-horizon investments in America's stock market have consistently received much higher returns than investors in bonds: a return gap averaging 6 percent per year. An enormous amount of creative and ingenious work by a great many economists has gone into seeking explanations for the so-called "equity premium return puzzle," but so far without a fully satisfactory answer. We first review the facts about the equity premium and then discuss a range of explanations that have been proposed. We conclude that the equity premium puzzle has not been solved: it remains a puzzle. And we anticipate that the equity return premium will continue, albeit at a smaller level than in the past - perhaps four percent per year. (The final draft of this paper was written before the recent stock market crash. As of October 2008, we can say that the crash does not fundamentally alter our conclusions and actually strengthens the case for a substantial future equity premium.)</description><author>DeLong, J. Bradford; Magin, Konstantin</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Microfinance Meets the Market</title><link>http://www.example.com/articles/1</link><description>Cull, Robert; Demirguec-Kunt, Asli; Morduch, Jonathan
In this paper, we examine the economic logic behind microfinance institutions and consider the movement from socially oriented nonprofit microfinance institutions to for-profit microfinance. Drawing on a large dataset that includes most of the world's leading microfinance institutions, we explore eight questions about the microfinance "industry": Who are the lenders? How widespread is profitability? Are loans in fact repaid at the high rates advertised? Who are the customers? Why are interest rates so high? Are profits high enough to attract profit-maximizing investors? How important are subsidies? The evidence suggests that investors seeking pure profits would have little interest in most of the institutions we see that are now serving poorer customers. We will suggest that the future of microfinance is unlikely to follow a single path. The recent clash between supporters of profit-driven Banco Compartamos and of the Grameen Bank with its "social business" model offers us a false choice. Commercial investment is necessary to fund the continued expansion of microfinance, but institutions with strong social missions, many taking advantage of subsidies, remain best placed to reach and serve the poorest customers, and some are doing so at a massive scale. The market is a powerful force, but it cannot fill all gaps.</description><author>Cull, Robert; Demirguec-Kunt, Asli; Morduch, Jonathan</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Beware of Venturing into Private Equity</title><link>http://www.example.com/articles/1</link><description>Phalippou, Ludovic
As a step towards understanding whether a private equity governance structure reduces overall agency conflicts relative to a public equity governance structure (as is often argued), this paper describes the contracts between private equity funds and investors, and the returns earned by investors. The paper sets the stage with a puzzle: the average performance of private equity funds is above that of the Standard and Poor's 500 - the main public stock market index - before fees are charged, but below that benchmark after fees are charged. Why are the payments to private equity buyout funds so large? Why does the marginal investor invest in buyout funds? I explore one potential answer (and probably the most controversial): that some investors are fooled. I show that the fee contracts for these funds are opaque. Considering this and the way that compensation contracts bury, in details, costly provisions that are difficult to justify on the basis of proper incentive alignment, it would be premature to assert that the agency conflicts are lower in private equity than in public equity.</description><author>Phalippou, Ludovic</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Leveraged Buyouts and Private Equity</title><link>http://www.example.com/articles/1</link><description>Kaplan, Steven N.; Stroemberg, Per
In a leveraged buyout, a company is acquired by a specialized investment firm using a relatively small portion of equity and a relatively large portion of outside debt financing. The leveraged buyout investment firms today refer to themselves (and are generally referred to) as private equity firms. We describe and present time series evidence on the private equity industry, considering both firms and transactions. We discuss the existing empirical evidence on the economics of the firms and transactions. We consider similarities and differences between the recent private equity wave and the wave of the 1980s. Finally, we speculate on what the evidence implies for the future of private equity.</description><author>Kaplan, Steven N.; Stroemberg, Per</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Reflections on Northern Rock: The Bank Run that Heralded the Global Financial Crisis</title><link>http://www.example.com/articles/1</link><description>Shin, Hyun Song
The U.K. bank Northern Rock became the first high-profile casualty of the global financial crisis of 2007-2008 when it suffered its depositor run in September 2007. In spite of the television images of long lines of depositors outside its branch offices, the run on Northern Rock was unlike the textbook retail depositor run caused by coordination failure. Also, contrary to received wisdom, its reliance on securitization was not an immediate factor in its failure. Rather, its problems stemmed from its high leverage coupled with reliance on institutional investors for short-term funding. When the de-leveraging in the credit markets began in August 2007, Northern Rock was uniquely vulnerable to the shrinking of lender balance sheets arising from the tick-up in measured risks. Financial regulation that relies on risk-weighted capital requirements is powerless against such runs. The Northern Rock case also offers lessons concerning the economics of short-term debt.</description><author>Shin, Hyun Song</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Deciphering the Liquidity and Credit Crunch 2007-2008</title><link>http://www.example.com/articles/1</link><description>Brunnermeier, Markus K.
nan</description><author>Brunnermeier, Markus K.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Crisis and Responses: The Federal Reserve in the Early Stages of the Financial Crisis</title><link>http://www.example.com/articles/1</link><description>Cecchetti, Stephen G.
Realizing that their traditional instruments were inadequate for responding to the crisis that began on August 9, 2007, Federal Reserve officials improvised. Beginning in mid-December 2007, they implemented a series of changes directed at ensuring that liquidity would be distributed to those institutions that needed it most. Conceptually, this meant America's central bankers shifted from focusing solely on the size of their balance sheet, which they use to keep the overnight interbank lending rate close to their chosen target, to manipulating the composition of their assets as well. In this paper, I examine the Federal Reserve's conventional and unconventional responses to the financial crisis of 2007-2008.</description><author>Cecchetti, Stephen G.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Rise in Mortgage Defaults</title><link>http://www.example.com/articles/1</link><description>Mayer, Christopher; Pence, Karen; Sherlund, Shane M.
The first hints of trouble in the mortgage market surfaced in mid-2005, and conditions subsequently began to deteriorate rapidly. Mortgage defaults and delinquencies are particularly concentrated among borrowers whose mortgages are classified as "subprime" or "near-prime." The main factors underlying the rise in mortgage defaults appear to be declines in house prices and deteriorated underwriting standards, in particular an increase in loan-to-value ratios and in the share of mortgages with little or no documentation of income. Contrary to popular perception, the growth in unconventional mortgages products, such as those with prepayment penalties, interest-only periods, and teaser interest rates, does not appear to be a significant factor in defaults through mid-2008 because borrowers who had problems with these products could refinance into different mortgages. However, as markets realized the extent of the poor underwriting, underwriting standards tightened and borrowers began to face difficulties refinancing; this dynamic suggests that these unconventional products could pose problems going forward.</description><author>Mayer, Christopher; Pence, Karen; Sherlund, Shane M.</author><pubDate>Thu, 01 Jan 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Secrets of the academy: The drivers of university endowment success</title><link>http://www.example.com/articles/1</link><description>Lerner, Josh; Schoar, Antoinette; Wang, Jialan
University endowments have received much attention recently for their superior investment returns compared with other institutional investors. This study documents trends in college and university endowment returns and investments in the United States between 1992 and 2005 using data on over a thousand schools. Such endowments have generally performed well over this time period, with a median growth rate of 7.4 percent per year and median return of 6.9 percent. This sector has been dominated both in size and performance by the endowments of elite universities such as the Ivy League schools. The top 20 endowments grew more than 9 percent annually on a real basis between 1992 and 2005. As of 2007, the two largest endowments, belonging to Harvard and Yale, have grown to $35 billion and $22 billion in size, respectively. Much of the growth in endowment size has been driven by investment performance. As we will show in the paper, the top endowments posted impressive returns in 2005, averaging a net real return of 12.3 percent, compared to 4.4 percent posted by the S&amp;P 500 index in the same year. We investigate the underlying drivers of these high returns and show that performance is related to the size of endowment, the quality of the student body, and the use of alternative investments. We caution ordinary investors that mimicking the strategies of the top endowments would not necessarily result in similar returns.</description><author>Lerner, Josh; Schoar, Antoinette; Wang, Jialan</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Probability and uncertainty in economic modeling</title><link>http://www.example.com/articles/1</link><description>Gilboa, Itzhak; Postlewaite, Andrew W.; Schmeidler, David
Economic modeling assumes, for the most part, that agents are Bayesian, that is, that they entertain probabilistic beliefs, objective or subjective, regarding any event in question. We argue that the formation of such beliefs calls for a deeper examination and for explicit modeling. Models of belief formation may enhance our understanding of the probabilistic beliefs when these exist, and may also help us characterize situations in which entertaining such beliefs is neither realistic nor necessarily rational.</description><author>Gilboa, Itzhak; Postlewaite, Andrew W.; Schmeidler, David</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Peer effects and alcohol use among college students</title><link>http://www.example.com/articles/1</link><description>Kremer, Michael; Levy, Dan
This paper examines the extent to which college students who drink alcohol influence their peers. We exploit a natural experiment in which students at a large state university were randomly assigned roommates through a lottery system. We find that on average, males assigned to roommates who reported drinking in the year prior to entering college had a Grade Point Average (GPA) one quarter-point lower than those assigned to nondrinking roommates. The effect of initial assignment to a drinking roommate persists into the second year of college and possibly grows. The effect is especially large for students who drank alcohol themselves in the year prior to college. In contrast to the males, females' GPAs do not appear affected by roommates' drinking prior to college. Furthermore, students' college GPA is not significantly affected by roommates' high school grades, admission test scores, or family background. These findings are more consistent with models in which peers change people's preferences than with models in which peers change people's choice sets. Surprisingly, the policy of segregating drinkers by having substance-free housing could potentially lower average GPA in the university.</description><author>Kremer, Michael; Levy, Dan</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>A pragmatic approach to capital account liberalization</title><link>http://www.example.com/articles/1</link><description>Prasad, Eswar S.; Rajan, Raghuram G.
In the mid-1990s, mainstream economists of nearly all stripes commonly recommended capital account liberalization - that is, allowing a free flow of funds in and out of a country's economy - as an essential step in the process of economic development. But then came the East Asian financial crisis of 1997-98, in which even seemingly healthy and well-managed economies like those of South Korea were engulfed by massive capital outflows and tremendous currency volatility, and capital account liberalization became quite controversial in the economics profession. A decade later, now that time has quelled passions and intervening research can shed more light on the debate, it appears that both the costs and benefits of capital account liberalization may have been misunderstood in that earlier debate. Now it appears that the main benefits of capital account liberalization for emerging markets are indirect, more related to their role in building other institutions than to the increased financing provided by capital inflows. And these indirect benefits are important enough that countries should look for creative approaches to capital account liberalization that would help attain these benefits while reducing the risks. Countries don't have much choice but to plan for capital account liberalization because capital accounts are de facto becoming more open over time, whatever governments may do to try to control them.</description><author>Prasad, Eswar S.; Rajan, Raghuram G.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Forensic finance</title><link>http://www.example.com/articles/1</link><description>Ritter, Jay R.
During popular prime-time television shows, forensic investigators use specialized but wide-ranging scientific knowledge of chemical trace evidence, bacteria, DNA, teeth, insects, and other specialties to collect and sift evidence of possible crimes. In economics and finance, forensic investigators apply their own specialized knowledge of prices, quantities, timing, and market institutions - and sometimes discover or substantiate evidence that is used by regulatory or criminal enforcement agencies. In this article, I will discuss four recent topics in forensic finance, all of which have attracted media attention: 1) the late trading of mutual funds, 2) stock option backdating, 3) the allocation of underpriced initial public offerings to corporate executives, and 4) changes in the records of stock analyst recommendations. In most of these cases, once certain practices or patterns have been publicized, financial industry practice has changed.</description><author>Ritter, Jay R.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Will the stork return to Europe and Japan? Understanding fertility within developed nations</title><link>http://www.example.com/articles/1</link><description>Feyrer, James; Sacerdote, Bruce; Stern, Ariel Dora
We seek to explain the differences in fertility rates across high-income countries by focusing on the interaction between the increasing status of women in the workforce and their status in the household, particularly with regards to child care and home production. We observe three distinct phases in women's status generated by the gradual increase in women's workforce opportunities. In the earliest phase, characteristic of the 1950s and 1960s in the United States, women earn low wages relative to men and are expected to shoulder all of the child care at home. As a result, most women specialize in home production and raising children. In an intermediate stage, women have improved (but not equal) labor market opportunities, but their household status lags. Women in this stage are still expected to do the majority of child care and household production. Increasing access to market work increases the opportunity cost of having children, and fertility falls. Female labor force participation increases. Working women in this phase of development have the strongest disincentives to having additional children since the entire burden of child care falls on them. In the final phase of development, women's labor market opportunities begin to equal those of men. In addition, the increased household bargaining power that comes from more equal wages results in much higher (if not gender-equal) male participation in household production. Female labor force participation is higher than in the intermediate phase. The increased participation of men in the household also reduces the disincentives for women to have additional children, and fertility rates rise compared to the intermediate phase. The intermediate, low-fertility phase might describe Japan, Italy, and Spain in the present day, while the Scandinavian countries, the Netherlands, and the modern-day United States may be entering the final phase. After presenting the empirical evidence, we predict that high-income countries with the lowest fertility rates are likely to see an increase in fertility in the coming decades.</description><author>Feyrer, James; Sacerdote, Bruce; Stern, Ariel Dora</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Parental education and parental time with children</title><link>http://www.example.com/articles/1</link><description>Guryan, Jonathan; Hurst, Erik; Kearney, Melissa
This paper examines parental time allocated to the care of one's children. Using data from the recent American Time Use Surveys, we highlight some interesting cross-sectional patterns in time spent by American parents as they care for their children: we find that higher-educated parents spend more time with their children; for example, mothers with a college education or greater spend roughly 4.5 hours more per week in child care than mothers with a high school degree or less. This relationship is striking, given that higher-educated parents also spend more time working outside the home. This robust relationship holds across all subgroups examined, including both nonworking and working mothers and working fathers. It also holds across all four subcategories of child care: basic, educational, recreational, and travel related to child care. From an economic perspective, this positive education gradient in child care (and a similar positive gradient found for income) can be viewed as surprising, given that the opportunity cost of time is higher for higher-educated, high-wage adults. In sharp contrast, the amount of time allocated to home production and to leisure falls sharply as education and income rise. We conclude that child care is best modeled as being distinct from typical home production or leisure activities, and thinking about it differently suggests important questions for economists to explore. Finally, using data from a sample of 14 countries, we explore whether the same patterns holds across countries and within other countries.</description><author>Guryan, Jonathan; Hurst, Erik; Kearney, Melissa</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Education and the age profile of literacy into adulthood</title><link>http://www.example.com/articles/1</link><description>Cascio, Elizabeth; Clark, Damon; Gordon, Nora
nan</description><author>Cascio, Elizabeth; Clark, Damon; Gordon, Nora</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The lengthening of childhood</title><link>http://www.example.com/articles/1</link><description>Deming, David; Dynarski, Susan
Over the past 40 years, the age at which children enter first grade has slowly drifted upward. In the fall of 1968, 96 percent of six-year-old children were enrolled in first grade or above. By 2005, the proportion had dropped to 84 percent, mainly because a substantial share of six-year-olds were still in kindergarten. About a third of the increase in age at school entry can be explained by legal changes. Almost every state has increased the age at which children are allowed to start primary school. The other two-thirds of the increase in the age at school entry reflects the individual decisions of parents and teachers who choose to keep children out of kindergarten or first grade even when they are legally eligible to attend. This practice is sometimes called "red-shirting," a phrase originally used to describe the practice of holding college athletes out of play until they have grown larger and stronger. Red-shirting is referred to as "the gift of time" in education circles, reflecting a perception that children who have been allowed to mature for another year will benefit more from their schooling. As we will discuss, little evidence supports this perception. It is indeed true that in any grade, older children tend to perform better academically than the younger children. In the early grades there is a strong, positive relationship between a child's age in months and his performance relative to his peers. But there is little evidence that being older than your classmates has any long-term, positive effect on adult outcomes such as IQ, earnings, or educational attainment. By contrast, there is substantial evidence that entering school later reduces educational attainment (by increasing high school dropout rates) and depresses lifetime earnings (by delaying entry into the labor market).</description><author>Deming, David; Dynarski, Susan</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Global imbalances: Globalization, demography, and sustainability</title><link>http://www.example.com/articles/1</link><description>Cooper, Richard N.
The current account deficit of the United States has been large in recent years, both in absolute size and relative to GDP. In 2006, it reached $811 billion, 6.1 percent of GDP. It has become a dominant feature of the world economy; if you sum up the current account deficits of all nations that are running deficits in the world economy, the U.S. deficit accounts for about 70 percent of the total. This paper looks beyond the national income accounting relationships to offer a more complex view of the U.S. imbalance. I argue that the generally rising U.S. trade deficit over the last 10-15 years is a natural outcome of two important forces in the world economy - globalization of financial markets and demographic change - and therefore that the U.S. current account deficit is likely to remain large for at least a decade. In a globalized market, the United States has a comparative advantage in producing marketable securities and in exchanging low-risk debt for higher-risk equity. It is not surprising that savers around the world want to put a growing portion of their savings into the U.S. economy. I argue that serious efforts to reduce the U.S. deficit, even collaborative efforts with other countries, may well precipitate a financial crisis and an economic downturn every bit as severe as the one that many fear could result from a disorderly market adjustment to the trade deficit.</description><author>Cooper, Richard N.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Resolving the global imbalance: The dollar and the US saving rate</title><link>http://www.example.com/articles/1</link><description>Feldstein, Martin
The massive deficit in the U.S. trade and current accounts is one of the most striking features of the current global economy and, to some observers, one of the most worrying. Although the current account deficit finally began to shrink in 2007, it remained at more than 5 percent of GDP - more than $700 billion. While some observers claim that the U.S. economy can continue to have trade deficits of this magnitude for years - some would say for decades - into the future, I believe that such enormous deficits cannot continue and will decline significantly in the coming years. This paper discusses the reasons for that decline and the changes that are needed in the U.S. saving rate and in the value of the dollar to bring it about. Reducing the U.S. current account deficit does not require action by the U.S. government or by the governments of America's trading partners. Market forces alone will cause the U.S. trade deficit to decline further. In practice, however, changes in government policies at home and abroad may lead to faster reductions in the U.S. trade deficit. More important, the response of the U.S. and foreign governments and central banks will determine the way in which the global economy as a whole adjusts to the decline in the U.S. trade deficit. Reductions in the U.S. current account deficit will of course imply lower aggregate trade surpluses in the rest of the world. Taken by itself, a reduction in any country's trade surplus will reduce aggregate demand and therefore employment in that country. I will therefore look at what other countries - China, Japan, and European countries - can do to avoid the adverse consequences of the inevitable decline of the U.S. trade deficit.</description><author>Feldstein, Martin</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>What the seller won't tell you: Persuasion and disclosure in markets</title><link>http://www.example.com/articles/1</link><description>Milgrom, Paul
Imagine that you are considering an investment in a new public offering of a firm's shares. The firm's officers make a presentation that includes an audited financial statement, an earnings forecast reviewed by its prestigious investment bankers, and an impressive demonstration of its new technology. Or suppose that you are buying a new furnace to replace an old one that is not working well. The salesman displays a chart showing that the projected total life-cycle cost of one particular model, including capital costs and fuel usage over the projected lifetime of the furnace, is lower than that of some competing models you have considered. This paper reviews the theoretical arguments about how sellers disclose information in an attempt to encourage buyers, and the potential role for regulation in encouraging efficient disclosure of information. How well does a system of private reporting work? When should we expect all the relevant information to be reported? If testing and reporting by the seller are costly, will too little testing and reporting be done? Or too much? When some information is withheld, what sort of information is withheld? How do rational buyers respond to such withholding? How are prices and welfare affected? What role is there for laws and regulations to improve the functioning of markets? We address these questions by studying the theory of persuasion games -- games in which one or more sellers provide verifiable information to buyers to influence the actions they take.</description><author>Milgrom, Paul</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Competition and truth in the market for news</title><link>http://www.example.com/articles/1</link><description>Gentzkow, Matthew; Shapiro, Jesse M.
In this essay, we evaluate the case for competition in news markets from the perspective of economics. First, we consider the simple proposition that when more points of view are heard and defended, beliefs will converge to the truth. This concept of "competition" is several steps removed from market competition among actual media firms, but it has played a prominent role in the legal arguments for a free press. We then explore three mechanisms by which increasing competition, or more precisely increasing the number of independently-owned firms, can limit bias or distortions that originate on the supply-side of the media market: First, when governments attempt to manipulate news, competition can increase the likelihood that the media remain independent. Second, when news providers have an interest in manipulating consumers' beliefs, diversity in such incentives can reduce the risk of information being suppressed or distorted. Third, competition may drive firms to invest in providing timely and accurate coverage. Overall, we argue that there are robust reasons to expect competition to be effective in disciplining supply-side bias. Next, we ask how the effect of competition changes when distortions originate on the demand side of the market - when consumers themselves demand biased or less socially relevant news. We find that increased competition may or may not improve welfare in these cases, though we caution against using this as a justification for concentrating media power in the hands of state-controlled or regulated firms.</description><author>Gentzkow, Matthew; Shapiro, Jesse M.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Media freedom, political knowledge, and participation</title><link>http://www.example.com/articles/1</link><description>Leeson, Peter T.
This paper examines the relationship between media freedom from government control and citizens' political knowledge, political participation, and voter turnout. To explore these connections, I first examine media freedom and citizens' political knowledge in thirteen central and eastern European countries with data from Freedom House's Freedom of the Press report and the European Commission's Candidate Countries Eurobarometer survey. Next, I consider media freedom and citizens' political participation in 60 countries using data from the World Values Survey. Finally, I investigate media freedom and voter turnout in these same 60 or so countries with data from the International Institute for Democracy and Electoral Assistance. I find that where government owns a larger share of media outlets and infrastructure, regulates the media industry more, and does more to control the content of news, citizens are more politically ignorant and apathetic. Where the media is less regulated and there is greater private ownership in the media industry, citizens are more politically knowledgeable and active. These results are robust to sample, specification, and alternative measures of media freedom.</description><author>Leeson, Peter T.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Identity theft</title><link>http://www.example.com/articles/1</link><description>Anderson, Keith B.; Durbin, Erik; Salinger, Michael A.
Identity theft is made possible by the nature of modern payment systems. In the modern economy, sellers are willing to offer goods and services to strangers in exchange for a promise to pay, provided the promise is backed up by data that link the buyer to a specific account or credit history. Identity theft involves acquiring enough data about another person to counterfeit this link, enabling the thief to acquire goods while attributing the charge to another person's account. In this article, we discuss what is (and is not) known about the prevalence and cost of identity theft, describe the institutional framework in which identity theft takes place, and consider some of the main policy issues associated with the problem.</description><author>Anderson, Keith B.; Durbin, Erik; Salinger, Michael A.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Taking the pulse of the economy: Measuring GDP</title><link>http://www.example.com/articles/1</link><description>Landefeld, J. Steven; Seskin, Eugene P.; Fraumeni, Barbara M.
This article provides a broad overview of the measurement techniques used in estimating GDP and the national accounts in the United States. In the United States, the GDP and the national accounts estimates are fundamentally based on detailed economic census data and other information that is available only once every five years. The challenge lies in developing a framework and methods that take these economic census data and combine them using a mosaic of monthly, quarterly, and annual economic indicators to produce quarterly and annual GDP estimates. One problem is that the other economic indicators that are used to extrapolate GDP in between the five-year economic census data - such as retail sales, housing starts, and manufacturers shipments of capital goods - are often collected for purposes other than estimating GDP and may embody definitions that differ from those used in the national accounts. Another problem is some data are simply not available for the earlier estimates in the reporting process. For the initial monthly estimates of GDP, data on about 25 percent of GDP - especially in the service sector - are not available, and so these sectors of the economy are estimated based on past trends and whatever related data are available. The initial monthly GDP estimates based on these extrapolations are revised as more complete data become available In producing the national accounts estimates, the Bureau of Economic Analysis attempts to strike a balance between accuracy and timeliness so that the estimates can be used to monitor real overall economic growth and inflation, as well as major sectors of interest.</description><author>Landefeld, J. Steven; Seskin, Eugene P.; Fraumeni, Barbara M.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Markets - Transparency and the corporate bond market</title><link>http://www.example.com/articles/1</link><description>Bessembinder, Hendrik; Maxwell, William
nan</description><author>Bessembinder, Hendrik; Maxwell, William</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Per-unit garbage charges</title><link>http://www.example.com/articles/1</link><description>Dijkgraaf, Elbert; Gradus, Raymond
To be considered for publication in the Comments section, Letters should be relatively short-generally fewer than 1,000 words-and should be sent to the editors at &lt; jep@jepjournal.org.&gt;. The editors will choose which letters will be published. All published Letters will be subject to editing for style and length.</description><author>Dijkgraaf, Elbert; Gradus, Raymond</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Per-unit garbage charges - Reply</title><link>http://www.example.com/articles/1</link><description>Anonymous
nan</description><author>Anonymous</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>A retrospecitve look at the U.S. productivity growth resurgence (vol 22, pg 3, 2008)</title><link>http://www.example.com/articles/1</link><description>Jorgenson, D. W.; Ho, M. S.; Stiroh, K. J.
nan</description><author>Jorgenson, D. W.; Ho, M. S.; Stiroh, K. J.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The quality of medical advice in low-income countries</title><link>http://www.example.com/articles/1</link><description>Das, Jishnu; Hammer, Jeffrey; Leonard, Kenneth
This paper documents the quality of medical advice in low-income countries. Our evidence on health care quality in low-income countries is drawn primarily from studies in four countries: Tanzania, India, Indonesia, and Paraguay. We provide an overview of recent work that uses two broad approaches: medical vignettes (in which medical providers are presented with hypothetical cases and their responses are compared to a checklist of essential procedures) and direct observation of the doctor-patient interaction These two approaches have proved quite informative. For example, doctors in Tanzania complete less than a quarter of the essential checklist for patients with classic symptoms of malaria, a disease that kills 63,000-96,000 Tanzanians each year. A public-sector doctor in India asks one (and only one) question in the average interaction: "What's wrong with you?" We present systematic evidence in this paper to show that these isolated facts represent common patterns. We find that the quality of care in low-income countries as measured by what doctors know is very low, and that the problem of low competence is compounded due to low effort - doctors provide lower standards of care for their patients than they know how to provide. We discuss how the properties and correlates of measures based on vignettes and observation may be used to evaluate policy changes. Finally, we outline the agenda in terms of further research and measurement.</description><author>Das, Jishnu; Hammer, Jeffrey; Leonard, Kenneth</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>What do nongovernmental organizations do?</title><link>http://www.example.com/articles/1</link><description>Werker, Eric; Ahmed, Faisal Z.
Nongovernmental organizations are one group of players who are active in the efforts of international development and increasing the welfare of poor people in poor countries. Nongovernmental organizations are largely staffed by altruistic employees and volunteers working towards ideological, rather than financial, ends. Their founders are often intense, creative individuals who sometimes come up with a new product to deliver or a better way to deliver existing goods and services. They are funded by donors, many of them poor or anonymous. Yet these attributes should not be unfamiliar to economists. Development NGOs, like domestic nonprofits, can be understood in the framework of not-for-profit contracting. It is easy to conjure up a glowing vision of how the efforts of NGOs could focus on problem solving without getting bogged down in corruption or bureaucracy. But the strengths of the NGO model have some corresponding weaknesses - in agenda setting, decision making, and resource allocation. We highlight three factors in explaining the increased presence of NGOs in the last few decades: a trend towards more outsourcing of government services; new ventures by would-be not-for-profit "entrepreneurs"; and the increasing professionalization of existing NGOs.</description><author>Werker, Eric; Ahmed, Faisal Z.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Income, health, and well-being around the world: Evidence from the Gallup World Poll</title><link>http://www.example.com/articles/1</link><description>Deaton, Angus
During 2006, the Gallup Organization conducted a World Poll that used an identical questionnaire for national samples of adults from 132 countries. I analyze the data on life satisfaction and on health satisfaction and look at their relationships with national income, age, and life-expectancy. The analysis confirms a number of earlier findings and also yields some new and different results. Average life satisfaction is strongly related to per capita national income. High-income countries have greater life-satisfaction than low-income countries. Each doubling of income is associated with almost a one-point increase in life satisfaction on a scale from 0 to 10 and, unlike most previous findings, the effect holds across the range of international incomes; if anything, it is slightly stronger among rich countries. Conditional on the level of national per capita income, the effects of economic growth on life satisfaction are negative, not positive as would be predicted by previous discussion and previous micro-based empirical evidence. Neither life satisfaction nor health satisfaction responds strongly to objective measures of health, such as life expectancy or the prevalence of HIV infection, so that neither provides a reliable indicator of population well-being over all domains, or even over health.</description><author>Deaton, Angus</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Where does the money go? Best and worst practices in foreign aid</title><link>http://www.example.com/articles/1</link><description>Easterly, William; Pfutze, Tobias
This paper does not address the issue of aid effectiveness - that is, the extent to which foreign aid dollars actually achieve their goals - but on "best practices" in the way in which official aid is given, an important component of the wider debate. First we discuss best practice for an ideal aid agency and the difficulties that aid agencies face because they are typically not accountable to their intended beneficiaries. Next we consider the transparency of aid agencies and four additional dimensions of aid practice: specialization, or the degree to which aid is not fragmented among too many donors, too many countries, and too many sectors for each donor); selectivity, or the extent to which aid avoids corrupt autocrats and goes to the poorest countries; use of ineffective aid channels such as tied aid, food aid, and technical assistance; and the overhead costs of aid agencies. We compare 48 aid agencies along these dimensions, distinguishing between bilateral and multilateral ones. Using the admittedly limited information we have, we rank the aid agencies on different dimensions of aid practice and then provide one final comprehensive ranking. We present these results as an illustrative exercise to move the aid discussion forward.</description><author>Easterly, William; Pfutze, Tobias</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>What is middle class about the middle classes around the world?</title><link>http://www.example.com/articles/1</link><description>Banerjee, Abhijit V.; Duflo, Esther
nan</description><author>Banerjee, Abhijit V.; Duflo, Esther</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Sluggish institutions in a dynamic world: Can unions and industrial competition coexist?</title><link>http://www.example.com/articles/1</link><description>Hirsch, Barry T.
During the 1930s and 1940s, collective bargaining emerged as the workplace governance norm in much of the U.S. industrial sector. Following its peak in the 1950s, union density in the U.S. private sector fell steadily, to only 7.4 percent in 2006. Governance shifted from a formalized union norm to one of constrained managerial discretion. In competitive and dynamic economic environments, a union tax on company earnings and slow response to economic shocks combine to produce poor performance by union companies. Two industries - automotives and airlines - are used to illustrate these points. If worker-based institutions are to flourish, they must add value and permit companies to perform at levels similar to those obtained under evolving nonunion governance norms.</description><author>Hirsch, Barry T.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Guaranteed trouble: The economic effects of the pension benefit guaranty corporation</title><link>http://www.example.com/articles/1</link><description>Brown, Jeffrey R.
How did the Pension Benefit Guaranty Corporation, a government corporation created to insure the pensions of workers and retirees in bankrupt firms, end up facing financial distress of its own? How did an organization designed to strengthen retirement security come to be seen as contributing to retirement insecurity? The superficial answer is that the PBGC's current funding problem arises from the decline in stock market prices in 2000, which reduced pension assets, and the fall in interest rates at about the same time, which boosted the present value of pension liabilities. But more fundamentally, much of the blame for the poor financial state of the PBGC, as well as the defined benefit system more generally, lies in some major design flaws of the PBGC pension insurance program. Specifically, the PBGC has: 1) failed to properly price insurance and thus encouraged excessive risk-taking by plan sponsors; 2) failed to promote adequate funding of pension obligations; and 3) failed to promote sufficient information disclosure to market participants. Together, these three flaws produced a system in which many firms fail to adequately fund their pension obligations, knowing that in financial distress, they can dump their pension liabilities onto the PBGC. Though the Pension Protection Act of 2006 made some progress in improving the PBGC program, it failed to correct these three major problems fully. Absent further reform, substantial problems will continue to plague the private defined benefit pension system in decades to come. To prevent this deterioration, this paper concludes that Congress should transfer much of the responsibility for defined benefit pension insurance to compulsory private markets.</description><author>Brown, Jeffrey R.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Dispelling some misconceptions about agricultural trade liberalization</title><link>http://www.example.com/articles/1</link><description>Tokarick, Stephen
There has been a great deal of public discussion over the impact that agricultural trade liberalization would likely have, especially on low-income countries. Unfortunately, the public discussion has been characterized by a number of misconceptions. This paper provides a clarifying discussion of the issues involved. Among the key points addressed are 1) agricultural "subsidies" are not nearly as large as has been portrayed; 2) tariffs are actually far more distortionary than subsidies and some low-income countries actually benefit from rich country subsides; and 3) widespread tariff reductions will not inflict large damage on developing countries as a result of preference erosion. The case for removing agricultural trade barriers remains compelling, even without the exaggerations and misconceptions.</description><author>Tokarick, Stephen</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Markets - Ready-mixed concrete</title><link>http://www.example.com/articles/1</link><description>Syverson, Chad
Concrete's natural color is gray. Its favored uses are utilitarian. Its very ubiquity causes it to blend into the background. But ready-mix concrete does have one remarkable characteristic: other than manufactured ice, perhaps no other manufacturing industry faces greater transport barriers. The transportation problem arises because ready-mix concrete both has a low value-to-weight ratio and is highly perishable - it absolutely must be discharged from the truck before it hardens. These transportation barriers mean ready-mixed concrete must be produced near its customers. For the same reason, foreign trade in ready-mixed concrete is essentially nonexistent. This article is an introduction to the basics of the market for ready-mix concrete, focusing mainly on its consumers and its producers in the United States, but with occasional comparisons to other countries when contrasts are useful.</description><author>Syverson, Chad</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Recommendations for further reading</title><link>http://www.example.com/articles/1</link><description>Taylor, Timothy
nan</description><author>Taylor, Timothy</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Untitled</title><link>http://www.example.com/articles/1</link><description>Solow, Robert
nan</description><author>Solow, Robert</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Untitled</title><link>http://www.example.com/articles/1</link><description>Weidenbaum, Murray
nan</description><author>Weidenbaum, Murray</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Recommendations for further reading - Response from V. V. Chari and Patrick J. Kehoe</title><link>http://www.example.com/articles/1</link><description>Anonymous
nan</description><author>Anonymous</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal abolition of FCC spectrum allocation</title><link>http://www.example.com/articles/1</link><description>Hazlett, Thomas W.
Ronald Coase based his 1959 call for spectrum markets on theoretical conjecture. Today abundant evidence supports his case. Targeted liberalization in cellular markets, as contrasted with regulatory planning of the digital TV transition and other traditional policies, suggest enormous efficiency gains are available from wider use of "the price system." With exclusive frequency rights assigned to owners, markets widely reconfigure spectrum use, coordinating complex spectrum sharing. Resulting social gains include increased consumer surplus from enhanced technological innovation and wireless service competition. A social bonus arrives in the benefits associated with wider scope for free speech. Yet, the administrative allocation system continues to distribute rents and garner political support. Liberal reforms, in contrast, produce large but broadly dispersed efficiency gains and are undersupplied. This paper proposes an incremental extension of property rights in spectrum to move beyond the current rent-seeking equilibrium, eliminating the Federal Communications Commission's centralized spectrum allocation process and, with it, an "attractive nuisance" generating anticonsumer outcomes.</description><author>Hazlett, Thomas W.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Biological measures of the standard of living</title><link>http://www.example.com/articles/1</link><description>Steckel, Richard H.
When economists investigate long-term trends and socioeconomic differences in the standard of living or quality of life, they have traditionally focused on monetary measures such as gross domestic product - which has occupied center stage for over 50 years. In recent decades, however, scholars have increasingly recognized the limitations of monetary measures while seeking useful alternatives. This essay examines the unique and valuable contributions of four biological measures - life expectancy, morbidity, stature, and certain features of skeletal remains - to understand levels and changes in human well-being. People desire far more than material goods and in fact they are quite willing to trade or give up material things in return for better physical or psychological health. For most people, health is so important to their quality of life that it is useful to refer to the "biological standard of living." Biological measures may be especially valuable for historical studies and for other research circumstances where monetary measures are thin or lacking. A concluding section ruminates on the future evolution of biological approaches in measuring happiness.</description><author>Steckel, Richard H.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Is the food and drug administration safe and effective?</title><link>http://www.example.com/articles/1</link><description>Philipson, Tomas J.; Sun, Eric
In the United States, the Food and Drug Administration (FDA) provides public oversight of the safety and efficacy of drugs; medical devices; biologics like vaccines and blood products; cosmetics; radiation-emitting electronic products; veterinary products; and all foods, except meat and poultry (which are regulated by the Department of Agriculture). According to the FDA, the products it regulates account for more than one-fifth of U.S. consumer spending. In the area of medical products, the FDA is responsible for determining whether marketed products are both safe and effective before and after they have been marketed. In this paper, we will explore whether the policies of the agency itself are safe and effective. We stress two issues, one static and one dynamic. The static issue concerns the potential duplication inefficiency when product safety is protected not only by the FDA but also by the private sector through product liability law. Put another way, what is the rationale for using product liability and the FDA to regulate drug safety? While intuitively it may seem that two systems must be better than one in ensuring drug safety, each system comes with costs. We then turn to the dynamic issue, the speed-safety trade off, and consider the extent to which higher safety is achieved at a cost of later market entry of effective and even life-saving products. We assess the Prescription Drug User Fee Acts (PDUFAs), which increased the speed of the agency's regulatory process starting in 1992, although according to some, at the cost of reducing drug safety. We conclude by suggesting a research agenda for future work on the Food and Drug Administration.</description><author>Philipson, Tomas J.; Sun, Eric</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Has economic analysis improved regulatory decisions?</title><link>http://www.example.com/articles/1</link><description>Hahn, Robert W.; Tetlock, Paul C.
In response to the increasing impact of regulation, several governments have introduced economic analysis as a way of trying to improve regulatory policy. This paper provides a comprehensive assessment of government-supported economic analysis of regulation. We find that there is growing interest in the use of economic tools, such as benefit-cost analysis; however, the quality of analysis in the U.S. and European Union frequently fails to meet widely accepted guidelines. Furthermore, the relationship between analysis and policy decisions is tenuous. To address this situation, we recommend pursuing an agenda in which economics plays a more central role in regulatory decision making. In addition, we suggest that prediction markets could help improve regulatory policy and improve measurement of the impact of regulation.</description><author>Hahn, Robert W.; Tetlock, Paul C.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>A retrospective look at the US productivity growth resurgence</title><link>http://www.example.com/articles/1</link><description>Jorgenson, Dale W.; Ho, Mun S.; Stiroh, Kevin J.
It is widely recognized that information technology was critical to the dramatic acceleration of U.S. labor productivity growth in the mid 1990s. This paper traces the evolution of productivity estimates to document how and when this perception emerged. Early studies concluded that information technology was relatively unimportant. Only after the massive information technology investment boom of the late 1990s did this investment and underlying productivity increases in the information technology-producing sectors come to be identified as important sources of growth. Although information technology has diminished in significance since the dot-com crash of 2000 and observed growth rates have slowed recently, we project that private sector productivity growth will average around 2.4 percent per year for the next decade, only moderately below the average of the post-1995 period.</description><author>Jorgenson, Dale W.; Ho, Mun S.; Stiroh, Kevin J.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The productivity gap between Europe and the United States: Trends and causes</title><link>http://www.example.com/articles/1</link><description>van Ark, Bart; O'Mahony, Mary; Timmer, Marcel P.
Since the mid-1990s, labor productivity growth in Europe has significantly slowed compared to earlier decades. In contrast, labor productivity growth in the United States accelerated, so that a new productivity gap has opened up. This paper shows that this development is attributable to the slower emergence of the knowledge economy in Europe. We consider various explanations which are not mutually exclusive. These include lower growth contributions from investment in information and communication technology; the small share of information and communications technology-producing industries in Europe; and slower multifactor productivity growth, which proxies for advances in technology and innovation. Underlying these are issues related to the functioning of European labor markets and the high level of product market regulation in Europe. The paper emphasizes the key role of market service sectors in accounting for the productivity growth divergence between the two regions. We argue that improved productivity growth in Europe's market services will be needed to avoid a further widening of the productivity gap.</description><author>van Ark, Bart; O'Mahony, Mary; Timmer, Marcel P.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Accounting for growth: Comparing China and India</title><link>http://www.example.com/articles/1</link><description>Bosworth, Barry; Collins, Susan M.
Since 1980, China and India have achieved remarkable rates of economic growth and poverty reduction. The emergence of China and India as major forces in the global economy has been one of the most significant economic developments of the past quarter century. This paper examines sources of economic growth in the two countries, comparing and contrasting their experiences over the past 25 years. In this paper, we investigate patterns of economic growth for China and India by constructing growth accounts that uncover the supply-side sources of output change for each economy. Some of the results confirm themes that have emerged from the prior literature on the economic development of the two countries, however, some new findings emerge as well. In addition to decompositions of aggregate growth, we construct separate accounts for the three major economic sectors: agriculture; industry; and services. This level of detail enables us to highlight key differences in the development paths taken by China and India. In conclusion, we assess the prospects for future growth in each country.</description><author>Bosworth, Barry; Collins, Susan M.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Transparency and the Corporate Bond Market Response from Hendrik Bessembinder and William Maxwell</title><link>http://www.example.com/articles/1</link><description>Anonymous
nan</description><author>Anonymous</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Transparency and the Corporate Bond Market</title><link>http://www.example.com/articles/1</link><description>Tempelman, Jerry H.
nan</description><author>Tempelman, Jerry H.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Retrospectives Guinnessometrics: The Economic Foundation of "Student's" t</title><link>http://www.example.com/articles/1</link><description>Ziliak, Stephen T.
In economics and other sciences, "statistical significance" is by custom, habit, and education a necessary and sufficient condition for proving an empirical result. The canonical routine is to calculate what's called a t-statistic and then to compare its estimated value against a theoretically expected value of it, which is found in "Student's" t table. A result yielding a t-value greater than or equal to about 2.0 is said to be "statistically significant at the 95 percent level." Alternatively, a regression coefficient is said to be "statistically significantly different from the null, p = .05." Canonically speaking, if a coefficient clears the 95 percent hurdle, it warrants additional scientific attention. If not, not. The first presentation of "Student's" test of significance came a century ago in 1908, in "The Probable Error of a Mean," published by an anonymous "Student." The author's commercial employer required that his identity be shielded from competitors, but we have known for some decades that the article was written by William Sealy Gosset (1876-1937), whose entire career was spent at Guinness's brewery in Dublin, where Gosset was a master brewer and experimental scientist. Perhaps surprisingly, the ingenious "Student" did not give a hoot for a single finding of "statistical" significance, even at the 95 percent level of significance as established by his own tables. Beginning in 1904, "Student," who was a businessman besides a scientist, took an economic approach to the logic of uncertainty, arguing finally that statistical significance is "nearly valueless" in itself.</description><author>Ziliak, Stephen T.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Are We Finally Winning the War on Cancer?</title><link>http://www.example.com/articles/1</link><description>Cutler, David M.
President Nixon declared what came to be known as the "war on cancer" in 1971 in his State of the Union address. At first the war on cancer went poorly: despite a substantial increase in resources, age-adjusted cancer mortality increased by 8 percent between 1971 and 1990, twice the increase from 1950 through 1971. However, between 1990 and 2004, age-adjusted cancer mortality fell by 13 percent. This drop translates into an increase in life expectancy at birth of half a year--roughly a quarter of the two-year increase in life expectancy over this time period and a third of the increase in life expectancy at age 45. The decline brings cancer mortality to its lowest level in 60 years. In the war on cancer, optimism has replaced pessimism. In this paper, I evaluate the reasons for the reduction in cancer mortality. I highlight three factors as leading to improved survival. Most important is cancer screening: mammography for breast cancer and colonoscopy for colorectal cancer. These technologies have had the largest impact on survival, at relatively moderate cost. Second in importance are personal behaviors, especially the reduction in smoking. Tobacco-related mortality reduction is among the major factors associated with better health, likely at a cost worth paying. Third in importance, and more controversial, are treatment changes. Improvements in surgery, radiation, and chemotherapy have contributed to improved survival for a number of cancers, but at high cost. The major challenge for cancer care in the future is likely to be the balancing act between what we are able to do and what it makes sense to pay for.</description><author>Cutler, David M.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Is American Health Care Uniquely Inefficient?</title><link>http://www.example.com/articles/1</link><description>Garber, Alan A.; Skinner, Jonathan
The U.S. health system has been described as the most competitive, heterogeneous, inefficient, fragmented, and advanced system of care in the world. In this paper, we consider two questions: First, is the U.S. healthcare system productively efficient relative to other wealthy countries, in the sense of producing better health for a given bundle of hospital beds, physicians, nurses, and other factor inputs? Second, is the United States allocatively efficient relative to other countries, in the sense of providing highly valued care to consumers? For both questions, the answer is most likely no. Although no country can claim to have eliminated inefficiency, the United States has high administrative costs, fragmented care, and stands out with regard to heterogeneity in treatment because of race, income, and geography. The U.S. healthcare system is also more likely to pay for diagnostic tests, treatments, and other forms of care before effectiveness is established and with little consideration of the value they provide. A number of proposed reforms that are designed to ameliorate shortcomings of the U.S. healthcare system, such as quality improvement initiatives and coverage expansions, are unlikely by themselves to reduce expenditures. Addressing allocative inefficiency is a far more difficult task but central to controlling costs.</description><author>Garber, Alan A.; Skinner, Jonathan</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Incremental Universalism for the United States: The States Move First?</title><link>http://www.example.com/articles/1</link><description>Gruber, Jonathan
The latest wave of health care proposals and laws in the United Sates has been marked by what I call "incremental universalism" - that is, getting to universal health insurance coverage by filling the gaps in the existing system, rather than ripping up the system and starting over. In this paper, I provide an overview of "incremental universalism" as an approach to healthcare reform, explore the issues it raises, and examine how these issues are being addressed at the state level, focusing primarily on the healthcare reform plan enacted by Massachusetts in April 2006. This sweeping bill altered insurance markets, subsidized insurance coverage for a large swath of the population, introduced a new health insurance purchasing mechanism (the "Connector"), and mandated insurance coverage for almost all citizens. The Massachusetts experience has led to similar proposals in a number of states, including a major (but ultimately failed) effort in California. I am far from an objective observer in discussing the Massachusetts law. I was one of the architects of the law and since 2006 have been a member of the board overseeing its implementation. Despite this bias and the fact that the ambitious Massachusetts plan is still in relatively early stages of implementation, I can say that some early results point to major successes for this reform.</description><author>Gruber, Jonathan</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Providing Prescription Drug Coverage to the Elderly: America's Experiment with Medicare Part D</title><link>http://www.example.com/articles/1</link><description>Duggan, Mark; Healy, Patrick; Morton, Fiona Scott
The federal government's Medicare program did not provide general prescription drug coverage for the first 40 years of its existence. Thus, more than 30 percent of the 44 million elderly and disabled beneficiaries of the program lacked insurance coverage for prescribed medications. The Medicare Prescription Drug, Improvement, and Modernization Act of 2003 established a voluntary outpatient prescription drug benefit known as Medicare Part D. This program took effect in 2006 and represents the largest expansion of an entitlement program since the start of Medicare itself. The design of Part D is of particular interest to economists for at least three reasons: First, the program has the potential to affect significantly both the health and the economic well-being of the more than 44 million individuals currently enrolled in Medicare. Second, Part D has substantially increased government spending on health care despite the projections that such spending was already on an unsustainable path. Third, Part D represents an ambitious attempt to use market mechanisms in the delivery of a large-scale entitlement program. Part D has been controversial. In this paper, we aim to shed light on the various issues raised by the Part D program, including the incentives inherent in the competition among plans, the forces that affect drug prices, and the sustainability of Part D in the face of adverse selection and moral hazard. We conclude that Part D has succeeded in a number of important ways, however, substantial room for improvement remains.</description><author>Duggan, Mark; Healy, Patrick; Morton, Fiona Scott</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Organizational Fragmentation and Care Quality in the US Healthcare System</title><link>http://www.example.com/articles/1</link><description>Cebul, Randall D.; Rebitzer, James B.; Taylor, Lowell J.; Votruba, Mark E.
Many goods and services can be readily provided through a series of unconnected transactions, but in health care, close coordination over time and within care episodes improves both health outcomes and efficiency. Close coordination is problematic in the U.S. healthcare system because the financing and delivery of care is distributed across a variety of distinct and often competing entities, each with its own objectives, obligations, and capabilities. These fragmented organizational structures lead to disrupted relationships, poor information flows, and misaligned incentives that combine to degrade care quality and increase costs. We illustrate our argument with examples taken from the insurance and hospital industries, and discuss possible responses to the problems resulting from organizational fragmentation.</description><author>Cebul, Randall D.; Rebitzer, James B.; Taylor, Lowell J.; Votruba, Mark E.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Overlapping Generations: The First Jubilee</title><link>http://www.example.com/articles/1</link><description>Weil, Philippe
nan</description><author>Weil, Philippe</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Economic Aftermath of Hurricane Katrina</title><link>http://www.example.com/articles/1</link><description>Vigdor, Jacob
On August 29, 2005, Hurricane Katrina swept into Louisiana and New Orleans, a city built largely on land reclaimed from swamp, witnessed massive failures in its levees. Much of the city and its surrounding suburbs were inundated; those residents of the city who had not heeded warnings to flee the approaching storm were evacuated in its wake. In less than a week, the city's population declined from over 400,000 to near zero. Census Bureau estimates indicate that almost two years after the storm, by July 1, 2007, nearly half of these evacuees had yet to return. Will the future New Orleans bear any resemblance to the city that existed prior to Katrina? Most government authorities, from city officials to federal spokespersons, insist that New Orleans must - and should - be fully rebuilt. Many environmental scientists question whether such a rebuilding would be sensible, given the city's precarious geological position and the contribution of past land reclamation to the city's current vulnerability. The more basic positive question of whether the city will come back, however, is fundamentally an economic one. After Hurricane Katrina, will the city of New Orleans continue to be a preferred location for more than 400,000 residents and their employers? Or will the disaster shift the city to a new equilibrium level of employment and population?</description><author>Vigdor, Jacob</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Interpreting the Great Moderation: Changes in the Volatility of Economic Activity at the Macro and Micro Levels</title><link>http://www.example.com/articles/1</link><description>Davis, Steven J.; Kahn, James A.
Most advanced economies have experienced a striking decline in the volatility of aggregate economic activity since the early 1980s. Volatility reductions are evident for output and employment at the aggregate level and across most industrial sectors and expenditure categories. Inflation and inflation volatility have also declined dramatically. Previous studies offer several potential explanations for this "Great Moderation." We review evidence on the Great Moderation in conjunction with evidence about volatility trends at the micro level. We combine the two types of evidence to develop a tentative story for important components of the aggregate volatility decline and its consequences. The key ingredients are declines in firm-level volatility and aggregate volatility - most dramatically in the durable goods sector. Surprisingly, this has occurred without a decline in household consumption volatility and individual earnings uncertainty. Our explanation for the aggregate volatility decline stresses improved supply-chain management, particularly in the durable goods sector, and, less important, a shift in production and employment from goods to services. We provide evidence that better inventory control made a substantial contribution to declines in firm-level and aggregate volatility. Consistent with this view, if we look past the turbulent 1970s and early 1980s much of the moderation reflects a decline in high frequency (short-term) fluctuations. While these developments represent efficiency gains, they do not imply (nor is there evidence for) a reduction in economic uncertainty faced by individuals and households.</description><author>Davis, Steven J.; Kahn, James A.</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Susan C. Athey: John Bates Clark Award Winner 2007</title><link>http://www.example.com/articles/1</link><description>Roberts, John
Susan Carleton Athey is the 2007 recipient of the American Economic Association's John Bates Clark Medal, which is "awarded biennially to that American economist under the age of forty who is adjudged to have made the most significant contribution to economic thought and knowledge." I have had the immense pleasure of being Susan's teacher, her advisor, her coauthor, and her friend. Yet I never cease to be amazed at her abilities and her accomplishments on so many dimensions. The AEA specifically cited her work in four distinct areas: monotone information models; industrial organization and particularly auctions; macroeconomics; and econometrics. Yet there is even more breadth to Susan's research contributions than this suggests, as I will show.</description><author>Roberts, John</author><pubDate>Tue, 01 Jan 2008 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Repugnance as a constraint on markets</title><link>http://www.example.com/articles/1</link><description>Roth, Alvin E.
This essay examines how repugnance sometimes constrains what transactions and markets we see. When my colleagues and I have helped design markets and allocation procedures, we have often found that distaste for certain kinds of transactions is a real constraint, every bit as real as the constraints imposed by technology or by the requirements of incentives and efficiency. I'll first consider a range of examples, from slavery and indentured servitude (which are much more repugnant now than they once were) to lending money for interest (which used to be widely repugnant but no longer is), and from bans on eating horse meat in California to bans on dwarf tossing in France. An example of special interest will be the widespread laws against the buying and selling of organs for transplantation. The historical record suggests that while repugnance can change over time, it can persist for a very long time, although changes in institutions that reflect repugnance can occur relatively quickly when the underlying repugnance changes.</description><author>Roth, Alvin E.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Firms in international trade</title><link>http://www.example.com/articles/1</link><description>Bernard, Andrew B.; Jensen, J. Bradford; Redding, Stephen J.; Schott, Peter K.
Since the mid-1990s, researchers have used micro datasets to study countries' production and trade at the firm level and have found that exporting firms differ substantially from firms that solely serve the domestic market. Across a wide range of countries and industries, exporting firms have been shown to be larger, more productive, more skill- and capital-intensive, and to pay higher wages than nonexporting firms. These differences exist even before exporting begins and have important consequences for evaluating the gains from trade and their distribution across factors of production. The new empirical research challenges traditional models of international trade and, as a result, the focus of the international trade field has shifted from countries and industries towards firms and products. Recently available transaction-level U.S. trade data reveal new stylized facts about firms' participation in international markets, and recent theories of international trade incorporating the behavior of heterogenous firms have made substantial progress in explaining patterns of trade and productivity growth.</description><author>Bernard, Andrew B.; Jensen, J. Bradford; Redding, Stephen J.; Schott, Peter K.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Heuristics and biases in retirement savings behavior</title><link>http://www.example.com/articles/1</link><description>Benartzi, Shlomo; Thaler, Richard H.
Standard economic theories of saving implicitly assume that households have the cognitive ability to solve the relevant optimization problem and the willpower to execute the optimal plan. Both of the implicit assumptions are suspect. Even among economists, few spend much time calculating a personal optimal savings rate. Instead, most people cope by adopting simple heuristics, or rules of thumb. In this paper, we investigate both the heuristics and the biases that emerge in the area of retirement savings. We examine the decisions employees make about whether to join a savings plan, how much to contribute, and how to invest. Saving for retirement is a difficult problem, and most employees have little training upon which to draw in making the relevant decisions. Perhaps as a result, investors are relatively passive. They are slow to join advantageous plans; they make infrequent changes; and they adopt naive diversification strategies. In short, they need all the help they can get. We discuss the possible role of interventions aiming to improve retirement decision making. Fortunately, many effective ways to help participants are also the least costly interventions: namely, small changes in plan design, sensible default options, and opportunities to increase savings rates and rebalance portfolios automatically.</description><author>Benartzi, Shlomo; Thaler, Richard H.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Are you sure you're saving enough for retirement?</title><link>http://www.example.com/articles/1</link><description>Skinner, Jonathan
Many view the soon-to-retire Baby Boomers as woefully unprepared for their golden years, while other economists have taken a more sanguine view of American levels of saving. And if Americans are failures at saving enough for retirement, why are some retirees so happy? The seemingly simple question of "Am I saving enough for retirement?" is apparently not so simple at all. Instead, it touches on a variety of deeper issues in economics, psychology, and health policy. I use the program ESPlanner to present life-cycle retirement wealth targets for a range of incomes and situations typical of American Economic Association members. (Readers are warned that life-cycle retirement wealth targets presented in this paper may lead to feelings of financial inadequacy.)</description><author>Skinner, Jonathan</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Producing organ donors</title><link>http://www.example.com/articles/1</link><description>Howard, David H.
Organ transplantation is one of the greatest technological achievements of modern medicine, but the ability of patients to benefit from transplantation is limited by shortages of transplantable organs. The median waiting time for patients placed on the kidney transplant waiting list is over three years. Median waiting times for hearts and livers are seven months and two years, respectively. From 1995 to 2005, the number of patients placed on the waiting list for organ transplants grew at an annualized rate of 4 percent per year. As a result of the growth in the demand for organs, many observers have questioned whether the current system is capable of providing enough transplantable organs. Transplant physicians and policymakers are seriously debating proposals to pay donors and their families and to change the legal regime governing the process of obtaining consent to donation. This paper provides an overview of the rules and practices that govern the organ procurement system and reviews proposals to increase donation rates, with a focus on deceased donors.</description><author>Howard, David H.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Introducing incentives in the market for live and cadaveric organ donations</title><link>http://www.example.com/articles/1</link><description>Becker, Gary S.; Elias, Julio Jorge
We evaluate the introduction of monetary incentives in the market for live and cadaveric organ donations. We show that monetary incentives would increase the supply of organs for transplant sufficiently to eliminate the very large queues in organ markets, and the suffering and deaths of many of those waiting, without increasing the total cost of transplant surgery by more than about 12 percent. We build on the value-of-life literature and other parts of economic analysis to estimate the equilibrium cost of live transplants for kidneys and livers. We also show that market price for kidneys will be determined by the cost of live donations, even though most organs will come from cadavers.</description><author>Becker, Gary S.; Elias, Julio Jorge</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Transportation costs and international trade in the second era of globalization</title><link>http://www.example.com/articles/1</link><description>Hummels, David
While the precise causes of postwar trade growth are not well understood, declines in transport costs top the lists of usual suspects. However, there is remarkably little systematic evidence documenting the decline. This paper brings to bear an eclectic mix of data in order to provide a detailed accounting of the time-series pattern of shipping costs. The ad-valorem impact of ocean shipping costs is not much lower today than in the 1950s, with technological advances largely trumped by adverse cost shocks. In contrast, air shipping costs have dropped an order of magnitude, and airborne trade has grown rapidly as a result. As a result, international trade has also experienced a significant rise in speed.</description><author>Hummels, David</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Does antitrust need to be modemized?</title><link>http://www.example.com/articles/1</link><description>Carlton, Dennis W.
Economics has had an enormous positive effect on the evolution of antitrust policy over the last 30 years or so. However, the evolving forces of technology and globalization, together with experience gained over time, suggest that further modernization is in order. This paper addresses a number of controversial antitrust doctrines that need fixing, or at least some modernizing. Specifically, I analyze market definition; the interaction of intellectual property and antitrust law; certain types of exclusionary conduct (tying and bundling discounts); and procedural issues involving economic matters such as damage multiples, the right to sue, and laws of contribution. I am currently Deputy Assistant Attorney General for Economic Analysis in the Antitrust Division of the U.S. Department of Justice and have served as a Commissioner on the Congress-appointed Antitrust Modernization Commission (AMC). While I've drawn on these experiences in forming my opinions, the views expressed here are my own and do not necessarily reflect those of the AMC or those of the Department of Justice.</description><author>Carlton, Dennis W.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The causes and consequences of Wal-Mart's growth</title><link>http://www.example.com/articles/1</link><description>Basker, Emek
Wal-Mart is the largest retailer and the largest private employer in the United States. The competitive pressures created by large retailers have long been controversial, and Wal-Mart's growth has raised concerns about its economic impact on workers, communities, and competitors. This paper aims to dispel some of the myths regarding Wal-Mart and to replace them with a systematic accounting of what is known about Wal-Mart's impact on the U.S. and global economy. The paper begins by exploring the source of Wal-Mart's competitive advantage. It then examines some of the economic effects of Wal-Mart: how Wal-Mart stores affect local labor markets, consumer prices, product selection, local and global competitors, and suppliers. I then turn to Wal-Mart's interaction with public policy issues in matters of global trade as well as state and local legislation on wages, benefits, zoning, and subsidies.</description><author>Basker, Emek</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Natural disasters, economic development, and humanitarian aid</title><link>http://www.example.com/articles/1</link><description>Stoermberg, David
Natural disasters are one of the major problems facing humankind. Between 1980 and 2004, two million people were reported killed and five billion people cumulatively affected by around 7,000 natural disasters, according to the dataset maintained by the Centre for Research on the Epidemiology of Disasters (CRED) at University of Louvain (Belgium). The economic costs are considerable and rising. The direct economic damage from natural disasters between 1980-2004 is estimated at around $1 trillion. This paper starts by describing the incidence of natural disasters, where they strike, and their development over time. It then discusses how societal factors act to protect people from or expose them to natural hazards. The final section discusses the determinants and targets of international aid to disaster victims.</description><author>Stoermberg, David</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Human capital and the productivity of suicide bombers</title><link>http://www.example.com/articles/1</link><description>Benmelech, Efraim; Berrebi, Claude
This paper studies the relation between the human capital of suicide bombers and the outcomes of their suicide attacks. We argue that human capital is an important factor in the production of terrorism and that if terrorists behave rationally, we should observe that more able suicide bombers are assigned to more important targets. To validate the theoretical predictions and estimate the returns to human capital in suicide bombing, we use a unique dataset detailing the biographies of Palestinian suicide bombers, the targets they attack, and the number of people that they kill and injure. Our empirical analysis suggests that older and more educated suicide bombers are being assigned by their terror organization to more important targets. We find that more educated and older suicide bombers are less likely to fail in their mission and are more likely to cause increased casualties when they attack.</description><author>Benmelech, Efraim; Berrebi, Claude</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Retrospectives - Edgeworth's hedonimeter and the quest to measure utility</title><link>http://www.example.com/articles/1</link><description>Colander, David
In this article, I discuss some earlier debates about the foundations of utility and its measurement, focusing on the contributions of Francis Y. Edgeworth (1845-1926), a famous British economist who was a leader in the development of a more mathematically structured economics in the late 1800s, and Irving Fisher (1867-1947), one of the first quantitative U.S. economists, best-known today for his work on the quantity theory and interest rate theory. Edgeworth argued that utility was directly measurable and that new developments in "physio-psychology" would make it possible to develop a "hedonimeter" that would allow economists to develop a firm physiological underpinning of utility. Fisher, while agreeing with Edgeworth that it was important to have a workable measure of utility, disagreed with Edgeworth about the possibility of doing so with a hedonimeter and, hence, of having any physiological underpinnings of utility. He argued that instead of searching for physiological underpinnings of utility, economists should instead rely upon backward induction from observed behavior to measured utility. Neither of these views about the possibility of utility measurement carried through, and attempts to measure utility were abandoned in the 1930s, when utility measurement and happiness considerations were determined to be outside the purview of economics. Both Edgeworth and Fisher knew that their approaches to utility measurement opened up a Pandora's box of problems; they opened that box, nonetheless, because they felt that theoretical economics had to be relevant to policy, and, to be relevant, it had to face the problems.</description><author>Colander, David</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Marriage and divorce: Changes and their driving forces</title><link>http://www.example.com/articles/1</link><description>Stevenson, Betsey; Wolfers, Justin
We document key facts about marriage and divorce, comparing trends through the past 150 years and outcomes across demographic groups and countries. While divorce rates have risen over the past 150 years, they have been falling for the past quarter century. Marriage rates have also been falling, but more strikingly, the importance of marriage at different points in the life cycle has changed, reflecting rising age at first marriage, rising divorce followed by high remarriage rates, and a combination of increased longevity with a declining age gap between husbands and wives. Cohabitation has also become increasingly important, emerging as a widely used step on the path to marriage. Out-of-wedlock fertility has also risen, consistent with declining "shotgun marriages". Compared with other countries, marriage maintains a central role in American life. We present evidence on some of the driving forces causing these changes in the marriage market: the rise of the birth control pill and women's control over their own fertility; sharp changes in wage structure, including a rise in inequality and partial closing of the gender wage gap; dramatic changes in home production technologies; and the emergence of the Internet as a new matching technology. We note that recent changes in family forms demand a reassessment of theories of the family and argue that consumption complementarities may be an increasingly important component of marriage. Finally, we discuss how these facts should inform family policy debates.</description><author>Stevenson, Betsey; Wolfers, Justin</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The economics of lesbian and gay families</title><link>http://www.example.com/articles/1</link><description>Black, Dan A.; Sanders, Seth G.; Taylor, Lowell J.
In this essay, we provide some statistics about the gay and lesbian population in the United States, and ask if analysis based on economic reasoning can provide insight into the family outcomes we observe. We do not start with a hypothesis of innate differences in preferences, but instead seek to understand how differences in constraints systematically alter incentives faced by gay, lesbian, and heterosexual people. Our work reinforces a central theme of Gary Becker's: that family life and economic life are interwoven. Decisions within families - including couples' decisions to commit to one another, divorce, bear children, or adopt children - are intrinsically connected to other economic decisions, including human capital accumulation, labor supply, occupational choice, consumption, and decisions about where to live. We provide evidence addressing number of questions: Do differing biological constraints faced by gay, lesbian, and heterosexual couples affect choices over children? Do differences in fertility (or anticipated fertility), again owing to differences in constraints, influence where people live? Do same-sex couples have patterns of household specialization that differ in predictable fashion from heterosexual couples?</description><author>Black, Dan A.; Sanders, Seth G.; Taylor, Lowell J.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Guess who's been coming to dinner? Trends in interracial marriage over the 20th century</title><link>http://www.example.com/articles/1</link><description>Fryer, Roland G.
This paper studies marriages across black, white, and Asian racial lines. Marrying across racial lines is a rare event, even today. Interracial marriages account for approximately 1 percent of white marriages, 5 percent of black marriages, and 14 percent of Asian marriages. Following a brief history of the regulation of race and romance in America, I analyze interracial marriage using census data from 1880-2000, uncovering a rich set of cross-section and time-series patterns. I investigate the extent to which three different theories of interracial marriage can account for the patterns discovered. After also testing a social exchange theory and a search model, I find the data are most consistent with a Becker-style marriage market model in which objective criteria of a potential spouse, their race, and the social price of intermarriage are central.</description><author>Fryer, Roland G.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Biological basics and the economics of the family</title><link>http://www.example.com/articles/1</link><description>Cox, Donald
Many economic models of the family are based on a generic "person 1 - person 2" household or "parent - child" family, rather than their anatomically correct counterparts: sons and daughters, fathers and mothers, and grandfathers and grandmothers. These economic models can offer powerful insights into family behavior, but also can leave certain patterns unexplained and neglect potentially important crosscurrents. "Bio-founded" approaches explicitly consider sex differences in reproductive capabilities and constraints, and can illuminate differences in the goals and interests of men versus women regarding preferences for a mate, decisions to marry or to terminate a marriage, how much to invest in a relationship, how much to invest in children, and how much to value the quality relative to the quantity of children Melding biological insights with family economics can cast new light on existing knowledge and open up novel paths for research. This paper generates biologically based hypotheses about family behavior by using Hamilton's rule, which holds that the costs and benefits of altruistic acts are weighted by the closeness of the genetic relationship, and by noting various fundamentals of human reproductive biology (for instance, a father might be uncertain of his genetic relationship to offspring, but a mother almost never is). This strategy generates a unified approach for modeling diverse aspects of family behavior. My discussion of biological fundamentals will include applications, empirical illustrations, and suggestions for how to merge these basics with current economic thinking.</description><author>Cox, Donald</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Disagreement and the stock market</title><link>http://www.example.com/articles/1</link><description>Hong, Harrison; Stein, Jeremy C.
A large catalog of variables with no apparent connection to risk has been shown to forecast stock returns, both in the time series and the cross-section. For instance, we see medium-term momentum and post-earnings drift in returns - the tendency for stocks that have had unusually high past returns or good earnings news to continue to deliver relatively strong returns over the subsequent six to twelve months (and vice-versa for stocks with low past returns or bad earnings news); we also see longer-run fundamental reversion - the tendency for "glamour" stocks with high ratios of market value to earnings, cashflows, or book value to deliver weak returns over the subsequent several years (and vice-versa for "value" stocks with low ratios of market value to fundamentals). To explain these patterns of predictability in stock returns, we advocate a particular class of heterogeneous-agent models that we call "disagreement models." Disagreement models may incorporate work on gradual information flow, limited attention, and heterogeneous priors, but all highlight the importance of differences in the beliefs of investors. Disagreement models hold the promise of delivering a comprehensive joint account of stock prices and trading volume - and some of the most interesting empirical patterns in the stock market are linked to volume.</description><author>Hong, Harrison; Stein, Jeremy C.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Investor sentiment in the stock market</title><link>http://www.example.com/articles/1</link><description>Baker, Malcolm; Wurgler, Jeffrey
Investor sentiment, defined broadly, is a belief about future cash flows and investment risks that is not justified by the facts at hand. The question is no longer whether investor sentiment affects stock prices, but how to measure investor sentiment and quantify its effects. One approach is "bottom up," using biases in individual investor psychology, such as overconfidence, representativeness, and conservatism, to explain how individual investors underreact or overreact to past returns or fundamentals. The investor sentiment approach that we develop in this paper is, by contrast, distinctly "top down" and macroeconomic: we take the origin of investor sentiment as exogenous and focus on its empirical effects. We show that it is quite possible to measure investor sentiment and that waves of sentiment have clearly discernible, important, and regular effects on individual firms and on the stock market as a whole. The top-down approach builds on the two broader and more irrefutable assumptions of behavioral finance - sentiment and the limits to arbitrage - to explain which stocks are likely to be most affected by sentiment. In particular, stocks that are difficult to arbitrage or to value are most affected by sentiment.</description><author>Baker, Malcolm; Wurgler, Jeffrey</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>What do laboratory experiments measuring social preferences reveal about the real world?</title><link>http://www.example.com/articles/1</link><description>Levitt, Steven D.; List, John A.
A critical question facing experimental economists is whether behavior inside the laboratory is a good indicator of behavior outside the laboratory. To address that question, we build a model in which the choices that individuals make depend not just on financial implications, but also on the nature and extent of scrutiny by others, the particular context in which a decision is embedded, and the manner in which participants and tasks are selected. We present empirical evidence demonstrating the importance of these various factors. To the extent that lab and naturally occurring environments systematically differ on any of these dimensions, the results obtained inside and outside the lab need not correspond. Focusing on experiments designed to measure social preferences, we discuss the extent to which the existing laboratory results generalize to naturally-occurring markets. We summarize cases where the lab may understate the importance of social preferences as well as instances in which the lab might exaggerate their importance. We conclude by emphasizing the importance of interpreting laboratory and field data through the lens of theory.</description><author>Levitt, Steven D.; List, John A.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Hedge funds: Past, present, and future</title><link>http://www.example.com/articles/1</link><description>Stulz, Rene M.
Assets managed by hedge funds have grown faster over the last ten years than assets managed by mutual funds. Hedge funds and mutual funds perform the same economic function, but hedge funds are largely unregulated while mutual funds are tightly regulated. This paper compares the organization, performance, and risks of hedge funds and mutual funds. It then examines whether one can expect increasing convergence between these two investment vehicles and concludes that the performance gap between hedge funds and mutual funds will narrow, that regulatory developments will limit the flexibility of hedge funds, and that hedge funds will become more institutionalized.</description><author>Stulz, Rene M.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>How wages change: Micro evidence from the International Wage Flexibility Project</title><link>http://www.example.com/articles/1</link><description>Dickens, William T.; Goette, Lorenz; Groshen, Erica L.; Holden, Steinar; Messina, Julian; Schweitzer, Mark E.; Turunen, Jarkko; Ward, Melanie E.
nan</description><author>Dickens, William T.; Goette, Lorenz; Groshen, Erica L.; Holden, Steinar; Messina, Julian; Schweitzer, Mark E.; Turunen, Jarkko; Ward, Melanie E.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Markets - Gift cards</title><link>http://www.example.com/articles/1</link><description>Offenberg, Jennifer Pate
The Mobil Oil Company introduced the first retail gift card that recorded value on a magnetic strip in 1995. In under a decade, such gift cards replaced apparel as the number one item sold during the Christmas season. This study will discuss the reasons for the strong surge in the gift card market. It will then consider the value of gift cards as an intermediate option between two alternatives: purchasing a physical gift, which could possibly be returned or exchanged, versus giving cash. Empirical data on the resale price of gift cards from an Internet auction website provide information on the value that recipients place on gift cards suggesting that the difference between the cost of a gift card to the giver and its value to the recipient is substantial, although perhaps not quite as large as the parallel gap involved in physical gifts.</description><author>Offenberg, Jennifer Pate</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The American family and family economics</title><link>http://www.example.com/articles/1</link><description>Lundberg, Shelly; Pollak, Robert A.
Gary Becker's path-breaking Treatise on the Family (1981) subjected individuals' decisions about sex, marriage, childbearing, and childrearing to rational choice analysis. The American family has changed radically in recent decades; we survey these changes as well as the ongoing effort to understand partnering, parenting, and care of the elderly as results of maximizing choices made by individuals. First, we describe the recent changes in the American family: the separation of sex, marriage, and childbearing; fewer children and smaller households; converging work and education patterns for men and women; class divergence in partnering and parenting strategies; and the replacement of family functions and home production by government programs and market transactions. Second, we examine recent work in family economics that attempts to explain these changes. Third, we point out some challenging areas for further analysis and highlight issues of commitment in two primary family relationships: those between men and women, and those between parents and children. Finally, we consider the effectiveness of policies to target benefits to certain family members (for instance, children) or to promote marriage and fertility.</description><author>Lundberg, Shelly; Pollak, Robert A.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>How progressive is the US federal tax system? A historical and international perspective</title><link>http://www.example.com/articles/1</link><description>Piketty, Thomas; Saez, Emmanuel
This paper provides estimates of federal tax rates by income groups in the United States since 1960, with special emphasis on very top income groups. We include individual and corporate income taxes, payroll taxes, and estate and gift taxes. The progressivity of the U.S. federal tax system at the top of the income distribution has declined dramatically since the 1960s. This dramatic drop in progressivity is due primarily to a drop in corporate taxes and in estate and gift taxes combined with a sharp change in the composition of top incomes away from capital income and toward labor income. The sharp drop in statutory top marginal individual income tax rates has contributed only moderately to the decline in tax progressivity. International comparisons confirm that is it critical to take into account other taxes than the individual income tax to properly assess the extent of overall tax progressivity, both for time trends and for cross-country comparisons. The pattern for the United Kingdom is similar to the U.S. pattern. France had less progressive taxes than the United States or the United Kingdom in 1970 but has experienced an increase in tax progressivity and has now a more progressive tax system than the United States or the United Kingdom.</description><author>Piketty, Thomas; Saez, Emmanuel</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Cheating ourselves: The economics of tax evasion</title><link>http://www.example.com/articles/1</link><description>Slemrod, Joel
No government can announce a tax system and then rely on taxpayers' sense of duty to remit what is owed. Some dutiful people will undoubtedly pay what they owe, but many others will not. Over time the ranks of the dutiful will shrink, as they see how they are being taken advantage of by the others. Thus, paying taxes must be made a legal responsibility of citizens, with penalties attendant on noncompliance. But even in the face of those penalties, substantial tax evasion exists. Tax evasion is widespread, always has been, and probably always will be. This essay reviews what is known about the magnitude, nature, and determinants of tax evasion, with an emphasis on the U.S. income tax. It then places this information into a conceptual context, examining various models and theories, and considers policy implications.</description><author>Slemrod, Joel</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Taxing consumption and other sins</title><link>http://www.example.com/articles/1</link><description>Hines, James R.
Federal and state governments in the United States use income and payroll taxes as their primary tools to collect revenue. Relative to the United States, governments in the rest of the world rely much more heavily on taxing consumption. Heavy American reliance on income rather than consumption taxation has not served the U.S. economy well. The inefficiency associated with taxing the return to capital means that the tax system reduces investment in the United States and distorts intertemporal consumption by Americans. While the economic logic of consumption taxation is compelling even for a closed economy, it is even more powerful for an open economy exposed to the world capital market. Consumption taxes in the form of excises can be designed to help protect the environment and control other externalities. Excise taxes can also serve the function of more closely aligning tax burdens with the benefits that taxpayers receive from certain government services. Understandable concerns arise about the distributional consequences of consumption taxation, but a system that relies heavily on consumption taxes, particularly if accompanied by an income tax, can be as progressive as any income tax the United States would realistically want to adopt.</description><author>Hines, James R.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Tax reform unraveling</title><link>http://www.example.com/articles/1</link><description>Graetz, Michael J.
The Tax Reform Act of 1986 was widely heralded as the most significant change in our nation's tax law since the income tax was extended to the masses during World War II. It was the crowning domestic policy achievement of President Ronald Reagan, who proclaimed it "the best antipoverty measure, the best pro-family measure, and the best job-creation measure ever to come out of the Congress of the United States." The law's rate reductions and base broadening reforms were mimicked throughout the countries belonging to the OECD. Even at the time, however, reading the paeans to this legislation was like watching a Tennessee Williams play: something was terribly wrong, but nobody was talking about it. Two decades later, the changes wrought by the 1986 act have proven neither revolutionary nor stable. Tax experts now regard the 1986 act as a promise failed. The public seems to agree, and considerable public support exists for a "flat tax" or a national sales tax to replace the income tax. I shall examine the most important individual and corporate income tax changes since 1986, before turning to proposals for restructuring the nation's tax system.</description><author>Graetz, Michael J.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The goals and promise of the Sarbanes-Oxley Act</title><link>http://www.example.com/articles/1</link><description>Coates, John C.
The primary goal of the Sarbanes-Oxley Act was to fix auditing of U.S. public companies, consistent with its full, official name: the Public Company Accounting Reform and Investor Protection Act of 2002. By consensus, auditing had been working poorly, and increasingly so. The most important, and most promising, part of Sarbanes-Oxley was the creation of a unique, quasi-public institution to oversee and regulate auditing, the Public Company Accounting Oversight Board (PCAOB). In controversial section 404, the law also created new disclosure-based incentives for firms to spend money on internal controls, above increases that would have occurred after the corporate scandals of the early 2000s. In exchange for these higher costs, which have already fallen substantially, Sarbanes-Oxley promises a variety of long-term benefits. Investors will face a lower risk of losses from fraud and theft, and benefit from more reliable financial reporting, greater transparency, and accountability. Public companies will pay a lower cost of capital, and the economy will benefit because of a better allocation of resources and faster growth. Sarbanes-Oxley remains a work in progress - section 404 in particular was implemented too aggressively - but reformers should push for continued improvements in its implementation, by PCAOB, rather than for repeal of the legislation itself.</description><author>Coates, John C.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Corporate governance reforms in continental Europe</title><link>http://www.example.com/articles/1</link><description>Enriques, Luca; Volpin, Paolo
The fundamental problem of corporate governance in the United States is to alleviate the conflict of interest between dispersed small shareowners and powerful controlling managers. The fundamental corporate governance in continental Europe and in most of the rest of the world is different. There, few listed companies are widely held. Instead, the typical firm in stock exchanges around the world has a dominant shareholder, usually an individual or a family, who controls the majority of the votes. In this essay, we begin by describing the differences in the ownership structure of companies in the three main economies of continental Europe - Germany, France, and Italy - with comparisons to the United States and the United Kingdom. We next summarize the corporate governance issues that arise in firms with a dominant shareholder. We take a look at a major European corporate scandal, Parmalat, as an extreme example of investor expropriation in a family-controlled corporation. We outline the legal tools that can be used to tackle abuses by controlling shareholders. Finally, we describe the corporate governance reforms enacted by France, Germany, and Italy between 1991 and 2005 and assess the way in which investor protection in the three countries has changed.</description><author>Enriques, Luca; Volpin, Paolo</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The economic lives of the poor</title><link>http://www.example.com/articles/1</link><description>Banejee, Abhijit V.; Duflo, Esther
The 1990 World Development Report from the World Bank defined the "extremely poor" people of the world as those who are currently living on no more than $1 per day per person. But how actually does one live on less than $1 per day? This essay is about the economic lives of the extremely poor: the choices they face, the constraints they grapple with, and the challenges they meet. A number of recent data sets and a body of new research allow us to start building an image of the way the extremely poor live their lives. Our discussion builds on household surveys conducted in 13 countries: Cote d'Ivoire, Guatemala, India, Indonesia, Mexico, Nicaragua, Pakistan, Panama, Papua New Guinea, Peru, South Africa, Tanzania, and Timor Leste (East Timor). These surveys provide detailed information on extremely poor households around the world, from Asia to Africa to Latin America, including information on what they consume, where they work, and how they save and borrow. We consider the extremely poor - those living in households where the consumption per capita is less than $1.08 per person per day - as well as the merely "poor" - defined as those who live under $2.16 a day - using 1993 purchasing power parity as benchmark. In keeping with convention, we call these the $1 and $2 dollar poverty lines, respectively.</description><author>Banejee, Abhijit V.; Duflo, Esther</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Payday lending</title><link>http://www.example.com/articles/1</link><description>Stegman, Michael A.
A "payday loan" is a short-term loan made for seven to 30 days for a small amount. Fees charged on payday loans generally range from $15 to $30 on each $100 advanced. A typical example would be that in exchange for a $300 advance until the next payday, the borrower writes a post-dated check for $300 and receives $255 in cash - the lender taking a $45 fee off the top. The lender then holds on to the check until the following payday, before depositing it in its own account. When the fee for a short-term payday loan is translated into an annual percentage rate, the implied annual interest rate ranges between 400 and 1000 percent. Virtually no payday loan outlets existed 15 years ago; today, there are more payday loan and check cashing stores nationwide than there are McDonald's, Burger King, Sears, J.C. Penney, and Target stores combined. For economists, several interesting issues arise in the study of payday loans: Is this just a situation in which willing customers and firms interact in the market for ready access to high-cost, short-term credit? Or does the payday loan industry encourage habitual borrowing and the snowballing of unaffordable debt in such a way that the state has a role to play in limiting consumers from their own excesses? Would a ban or overly restrictive regulations on payday lending just revive the market for loan-sharking? And what of a similar practice by mainstream banks, who regularly allow their customers to overdraw their checking accounts if they pay a fee comparable in size to a payday loan charge?</description><author>Stegman, Michael A.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Daron Acemoglu: 2005 John Bates Clark medalist</title><link>http://www.example.com/articles/1</link><description>Shimer, Robert
Daron Acemoglu, winner of the 2005 John Bates Clark Medal, uses theoretical and empirical analysis to tackle critical issues in a variety of fields in economics, including labor economics, macroeconomics, and political economy. His unparalleled combination of originality, thoroughness, and prolificacy has propelled him to the frontier of each field that he has explored. The Clark medal committee notes that "his work is always motivated by real-world questions that arise when facts are difficult to reconcile with existing theory." Daron focuses on a core set of questions and uses the best tools available to answer them. What determines the accumulation of human capital both during formal schooling and on the job? How do the implications of labor market frictions depend on the information available to job searchers? How do economic incentives affect the type of technological change that we observe? Why are there such enormous differences in output per worker and total factor productivity across countries?</description><author>Shimer, Robert</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Markets - Cartel behavior and amateurism in college sports</title><link>http://www.example.com/articles/1</link><description>Kahn, Lawrence M.
This paper studies intercollegiate athletics in the context of the theory of cartels. Some point to the explicit attempts by the National Collegiate Athletic Association (NCAA) to restrict output and payments for factors of production as evidence of cartel behavior. Others argue that such limits enhance product quality by preserving amateurism. I find that the NCAA's compensation limits on athletes lead to high levels of rents from the entertainment revenues produced by the athletes, a finding consistent with the cartel interpretation. The athletes producing these rents are disproportionately African-American, while the beneficiaries are primarily white. The rents are typically spent on facilities, nonrevenue sports, and, possibly, head coaches' salaries. Big-time football and men's basketball programs earn accounting profits, although the athletic departments in which they reside make accounting losses on average. However, there is some evidence, albeit not unanimous, that sports generate alumni contributions, state appropriations, and additional student applications. But, arms race considerations suggest that there may be some societal gains to the aggregate limitation of spending on college athletics.</description><author>Kahn, Lawrence M.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Retrospectives - From usury to interest</title><link>http://www.example.com/articles/1</link><description>Persky, Joseph
Since the Middle Ages, each epoch has participated in the debate over the conditions in which lending should be prohibited as usury. While disagreements over the definition of usury remain, the debate came to its modern climax on the eve of the industrial revolution, in a well-known interchange between Jeremy Bentham and Adam Smith in the late 1780s. Smith, for all his faith in a system of natural liberty, proved unwilling to let the interest rate float. Bentham argued anything else must reduce total welfare. From a superficial perspective, the entire affair amounts to nothing more than a modest dispute between a failing master (Smith died in 1790) and an over-eager disciple. (Bentham acknowledged in the Defence that all he knew of political economy originated in Smith's works.) Yet the argument struck a fundamental chord. Gilbert K. Chesterton identified Bentham's essay on usury as the very beginning of the "modern world." I tend to agree.</description><author>Persky, Joseph</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Macroeconomic modeling for monetary policy evaluation</title><link>http://www.example.com/articles/1</link><description>Gali, Jordi; Gertler, Mark
We describe some of the main features of the recent vintage of macroeconomic models used for monetary policy evaluation. We point to some of the key differences with respect to the earlier generation of macro models and highlight the insights for policy that these new frameworks have to offer. Our discussion emphasizes two key aspects of the new models: 1) the significant role of expectations of future policy actions in the monetary transmission mechanism and 2) the importance for the central bank of tracking the flexible price equilibrium values of the natural levels of output and the real interest rate. We argue that both features have important implications for the conduct of monetary policy.</description><author>Gali, Jordi; Gertler, Mark</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>How the world achieved consensus on monetary policy</title><link>http://www.example.com/articles/1</link><description>Goodfriend, Marvin
The worldwide progress in monetary policy is a great achievement and, especially considering the situation 30 years ago, a remarkable success story. I describe how the world achieved a working consensus on the core principles of monetary policy by the late 1990s. I survey the muddled state of affairs in the 1970s, and then ask: What happened in Federal Reserve policy to produce an understanding of the practical principles of monetary policy? How did formal institutional support for targeting low inflation abroad follow from an international acceptance of these ideas? And how did a consensus theoretical model develop in academia? I explain how the modern theoretical consensus - known alternatively as the New Neoclassical Synthesis or the New Keynesian model of monetary policy - reinforces key advances: the priority for price stability; the targeting of core rather than headline inflation; the importance of credibility for low inflation; and preemptive interest rate policy supported by transparent objectives and procedures. Of course, a working consensus does not constitute complete agreement. Accordingly, the conclusion identifies important monetary policy issues that remain to be explored.</description><author>Goodfriend, Marvin</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The evolution of central bank governance around the world</title><link>http://www.example.com/articles/1</link><description>Crowe, Christopher; Meade, Ellen E.
The past two decades have seen enormous changes in central banks and their practices. In some countries, older institutions have been fundamentally restructured. In other, such as the countries of the former Soviet Union, entirely new central banks have been established. The member countries of the European Union have created a supranational central bank that oversees a monetary union. In all of these situations, central bank law was either revised or written de novo, while institutional objectives, practices, and structures were amended or created from scratch. In this article, we survey and quantify the trends in two major areas of central bank governance: independence and transparency. We document the steady progress toward greater central bank independence and transparency in a large number of industrial and developing countries over the past 10 to 15 years and discuss the effects of these aspects of governance on inflation. Finally, we touch on committee structure and decision making.</description><author>Crowe, Christopher; Meade, Ellen E.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Personnel economics: The economist's view of human resources</title><link>http://www.example.com/articles/1</link><description>Lazear, Edward P.; Shaw, Kathryn L.
Personnel economics drills deeply into the firm to study human resource management practices like compensation, hiring practices, training, and teamwork. Why should pay vary across workers within firms - and how "compressed" should pay be within firms? Should firms pay workers for their performance on the job or for their skills or hours of work? How are pay and promotions structured across jobs to induce optimal effort from employees? Why do firms use teams and how are teams used most effectively? How should all these human resource management practices, from incentive pay to teamwork, be combined within firms? Personnel economists offer new tools to analyze these questions - and new answers as well.</description><author>Lazear, Edward P.; Shaw, Kathryn L.</author><pubDate>Mon, 01 Jan 2007 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item></channel></rss>