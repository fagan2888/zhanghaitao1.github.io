<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Management Science9</title><link>http://www.example.com/rss</link><description>This is the feed for items from my zotero.</description><language>en-US</language><lastBuildDate>Sun, 08 Dec 2019 22:07:42 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Retail Channel Structure Impact on Strategic Engineering Product Design</title><link>http://www.example.com/articles/1</link><description>Williams, Nathan; Kannan, P. K.; Azarm, Shapour
We examine, in a strategic setting, the broad issue of how retail channel structures-retail monopoly versus retail duopoly-impact a manufacturer's optimal new product design, both in terms of engineering design specifications as well as manufacturer and retailer profits. Our strategic framework enables manufacturers in specific contexts to anticipate the reactions of the retailers and competitive manufacturers to new designs in terms of the retail and wholesale pricing and to understand how different channel structures and channel strategies (such as an exclusive channel strategy) impact the engineering design of the new product, conditional on consumer preference distributions and competitor product attributes. Based on a simple numerical and a power tool design example, we illustrate how the insight from the framework translates to design guidelines; specifically, understanding which designs are optimal under differing channel structure conditions, and which design variables need precise targeting given their profit sensitivity.</description><author>Williams, Nathan; Kannan, P. K.; Azarm, Shapour</author><pubDate>Sun, 01 May 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Designing Multiperson Tournaments with Asymmetric Contestants: An Experimental Study</title><link>http://www.example.com/articles/1</link><description>Chen, Hua; Ham, Sung H.; Lim, Noah
Is the right amount of effort exerted in multiperson tournaments where contestants have two different levels of initial endowments (termed "favorites" and "underdogs")? We develop theoretical predictions for the level of effort and the effect of varying the prize structure. We test these predictions for three-person tournaments using an economic experiment in a social environment where contest outcomes are publicly announced. We find that both favorites and underdogs overexert effort relative to the theoretical point predictions. Moreover, in the treatment with two favorites and one underdog, favorites increase their effort when the number of prizes is increased from one to two, contrary to the theory prediction. We show that a generalized model that allows for psychological losses from losing for favorites and psychological gains from winning for underdogs because of social comparisons tracks the experimental results better than the standard theoretical model.</description><author>Chen, Hua; Ham, Sung H.; Lim, Noah</author><pubDate>Sun, 01 May 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>How Does Popularity Information Affect Choices? A Field Experiment</title><link>http://www.example.com/articles/1</link><description>Tucker, Catherine Elizabeth; Zhang, Juanjuan
Popularity information is usually thought to reinforce existing sales trends by encouraging customers to flock to mainstream products with broad appeal. We suggest a countervailing market force: popularity information may benefit niche products with narrow appeal disproportionately, because the same level of popularity implies higher quality for narrow-appeal products than for broad-appeal products. We examine this hypothesis empirically using field experiment data from a website that lists wedding service vendors. Our findings are consistent with this hypothesis: narrow-appeal vendors receive more visits than equally popular broad-appeal vendors after the introduction of popularity information.</description><author>Tucker, Catherine Elizabeth; Zhang, Juanjuan</author><pubDate>Sun, 01 May 2011 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Incentives in New Product Development Projects and the Role of Target Costing</title><link>http://www.example.com/articles/1</link><description>Mihm, Juergen
This paper investigates how self-optimizing engineers affect new product development (NPD) project outcomes and development times. A variety of widely used NPD project management approaches, including heavyweight project management, may allow or even encourage engineers to introduce late design changes and exhibit weak cost compliance, reducing the product's profit or competitiveness. Providing specifically designed incentives for individuals can eliminate such encouragement, and thus improve cost compliance and project timeliness. This paper discusses several practical incentive schemes, including profit-sharing contracts and component-level target costing. For many industrial projects, component-level target costing makes the most efficient use of available information to optimize project outcomes and reduce development times.</description><author>Mihm, Juergen</author><pubDate>Sun, 01 Aug 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Improving Supply Chain Performance and Managing Risk Under Weather-Related Demand Uncertainty</title><link>http://www.example.com/articles/1</link><description>Chen, Frank Youhua; Yano, Candace Arai
We consider a manufacturer-retailer supply chain for a seasonal product whose demand is weather sensitive. The retailer orders from the manufacturer (supplier) prior to the selling season and then sells to the market. We examine how a manufacturer can structure a weather-linked rebate to improve his expected profit. The proposed class of rebate contracts offers several advantages over many other contract structures, including no required verification of leftover inventory and/or markdown amounts, and no adverse effect on sales effort by the retailer. We provide a thorough analysis of the manufacturer's and retailer's decisions in this context. We show that the weather-linked rebate can take many different forms, and this flexibility allows the supplier to design contracts that are Pareto improving and/or limit his risk in offering the contract and the retailer's risk in accepting it. For weather rebates with certain characteristics, the manufacturer can fully hedge his risks of offering a weather rebate by paying a risk premium; we show how this can be accomplished. We also show that the basic structural results extend to settings in which the two parties would like to limit their risk.</description><author>Chen, Frank Youhua; Yano, Candace Arai</author><pubDate>Sun, 01 Aug 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Control and Equilibrium Behavior of Production-Inventory Systems</title><link>http://www.example.com/articles/1</link><description>Wu, Owen Q.; Chen, Hong
The relationship between commodity inventory and short-term price variations has received considerable attention, but the understanding has been limited to single-stage cross-sectional relation. In this paper, we aim to deepen our understanding of the inventory-price relationship in two dimensions: across time and across production stages. We first examine an individual firm controlling production and two stages of inventory under uncertain input and output prices and operating costs. We next establish and characterize the rational expectations equilibrium for an economy in which competitive production firms link a raw material market and a finished goods market, with uncertain and price-sensitive supply and demand. We characterize the dynamics of inventory, market price, and gross margin based on theoretical analysis, simulation, and empirical evidence from the petroleum industry. We find that inventory fluctuations lag behind price variations, and the length of the lags depend on how far the inventory is from the source of the supply or demand shocks. We also find that shocks are both dampened and delayed when propagating through the production stages, and that shocks have a prolonged effect on inventories and prices at both stages.</description><author>Wu, Owen Q.; Chen, Hong</author><pubDate>Sun, 01 Aug 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Joint Dynamic Pricing of Multiple Perishable Products Under Consumer Choice</title><link>http://www.example.com/articles/1</link><description>Akcay, Yalcin; Natarajan, Harihara Prasad; Xu, Susan H.
In response to competitive pressures, firms are increasingly adopting revenue management opportunities afforded by advances in information and communication technologies. Motivated by these revenue management initiatives in industry, we consider a dynamic pricing problem facing a firm that sells given initial inventories of multiple substitutable and perishable products over a finite selling horizon. Because the products are substitutable, individual product demands are linked through consumer choice processes. Hence, the seller must formulate a joint dynamic pricing strategy while explicitly incorporating consumer behavior. For an integrative model of consumer choice based on linear random consumer utilities, we model this multiproduct dynamic pricing problem as a stochastic dynamic program and analyze its optimal prices. The consumer choice model allows us to capture the linkage between product differentiation and consumer choice, and readily specializes to the cases of vertically and horizontally differentiated assortments. When products are vertically differentiated, our results show monotonicity properties (with respect to quality, inventory, and time) of the optimal prices and reveal that the optimal price of a product depends on higher quality product inventories only through their aggregate inventory rather than individual availabilities. Furthermore, we show that the price of a product can be decomposed into the price of its adjacent lower quality product and a markup over this price, with the markup depending solely on the aggregate inventory. We exploit these properties to develop a polynomial-time, exact algorithm for determining the optimal prices and the profit. For a horizontally differentiated assortment, we show that the profit function is unimodal in prices. We also show that individual, rather than aggregate, product inventory availability drives pricing. However, we find that monotonicity properties observed in vertically differentiated assortments do not hold.</description><author>Akcay, Yalcin; Natarajan, Harihara Prasad; Xu, Susan H.</author><pubDate>Sun, 01 Aug 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Choice and Beliefs with Ex Ante Savoring and Ex Post Disappointment</title><link>http://www.example.com/articles/1</link><description>Gollier, Christian; Muermann, Alexander
We propose a new decision criterion under risk in which individuals extract both utility from anticipatory feelings ex ante and disutility from disappointment ex post. The decision maker chooses his degree of optimism, given that more optimism raises both the utility of ex ante feelings and the risk of disappointment ex post. We characterize the optimal beliefs and the preferences under risk generated by this mental process and apply this criterion to a simple portfolio choice/insurance problem. We show that these preferences are compatible with first-degree and second-degree stochastic dominance and yield a preference for early resolution of uncertainty. Furthermore, they are consistent with observed violations of the independence axiom, such as the preference reversal in the Allais paradox, and predict that the decision maker takes on less risk compared to an expected utility maximizer. Our decision criterion can thus help explain the equity premium puzzle and the preference for low deductibles in insurance contracts.</description><author>Gollier, Christian; Muermann, Alexander</author><pubDate>Sun, 01 Aug 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Model of Migration and Use of Platforms: Role of Hierarchy, Current Generation, and Complementarities in Consumer Settings</title><link>http://www.example.com/articles/1</link><description>Xu, Xin; Venkatesh, Viswanath; Tam, Kar Yan; Hong, Se-Joon
We develop and test a model of migration and use of platforms to explain consumers' reactions to the newest generation of an information and communication technology platform. We draw from information systems and consumer behavior research on adoption and use of technologies, and adapt and incorporate the construct of complementarity from macrolevel research on platform leadership, network effects, and innovation ecosystems. We conceptualize complementarities between the hardware and software platforms, software platform and applications, and applications and services. The complementarities are theorized to influence migration intention, with current generation of the consumer's platform being a key moderator. We empirically validated our model with data collected using two waves of surveys from 4,412 consumers (2,333 consumers in the second wave) before and after the introduction of the third generation (3G) mobile data services platform in Hong Kong. We explained 60% of the variance in migration intention that in turn was strongly correlated with migration to and use of 3G.</description><author>Xu, Xin; Venkatesh, Viswanath; Tam, Kar Yan; Hong, Se-Joon</author><pubDate>Sun, 01 Aug 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Flexibility Configurations in Newsvendor Networks: Going Beyond Chaining and Pairing</title><link>http://www.example.com/articles/1</link><description>Bassamboo, Achal; Randhawa, Ramandeep S.; Van Mieghem, Jan A.
We study the classical problem of capacity and flexible technology selection with a newsvendor network model of resource portfolio investment. The resources differ by their level of flexibility, where "level-k flexibility" refers to the ability to process k different product types. We present an exact set-theoretic methodology to analyze newsvendor networks with multiple products and parallel resources. This simple approach is sufficiently powerful to prove that (i) flexibility exhibits decreasing returns and (ii) the optimal portfolio will invest in at most two, adjacent levels of flexibility in symmetric systems, and to characterize (iii) the optimal flexibility configuration for asymmetric systems as well. The optimal flexibility configuration can serve as a theoretical performance benchmark for other configurations suggested in the literature. For example, although chaining is not optimal in our setting, the gap is small and the inclusion of scale economies quickly favors chaining over pairing. We also demonstrate how this methodology can be applied to other settings such as product substitution and queuing systems with parameter uncertainty.</description><author>Bassamboo, Achal; Randhawa, Ramandeep S.; Van Mieghem, Jan A.</author><pubDate>Sun, 01 Aug 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Strategic Entry Before Demand Takes Off</title><link>http://www.example.com/articles/1</link><description>Shen, Qiaowei; Villas-Boas, J. Miguel
In developing industries, firms have to decide whether and when to enter the market depending on the state of demand, existing firms in the industry, and the firm's capabilities. This paper investigates a model of increasing demand, in which firms decide when to enter the market anticipating the strategic behavior of other potential entrants, and the effects of entry on future potential entrants. This paper shows that the ability of early entry to deter future competitors' entry leads firms to enter the market at a rate faster than demand is expanding. If there is the potential for many firms to enter the market, firms may be less likely to enter because of future competitor entry to correct any market opportunities. If firms enter the market depending on their fixed capabilities rather than depending on the firm's circumstances at each moment in time, firms end up entering the market at a faster rate in the early periods.</description><author>Shen, Qiaowei; Villas-Boas, J. Miguel</author><pubDate>Sun, 01 Aug 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Management Economics in a Large Retail Company</title><link>http://www.example.com/articles/1</link><description>Siebert, W. Stanley; Zubanov, Nikolay
We use unique data from 245 stores of a UK retailer to study links among middle (store) manager skills, sales, and manager pay. We find that, of the six management practice areas surveyed, the most important is "commercial awareness," where abler managers achieve up to 13.9% higher sales per worker. We find that many stores have poor managers on this indicator. However, the company is careful to incentivize managers, operating a scheme giving shares (approximately 20%) in both positive and negative deviations of actual sales from expected. Abler managers do not receive higher pay, implying that their skills are company specific.</description><author>Siebert, W. Stanley; Zubanov, Nikolay</author><pubDate>Sun, 01 Aug 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Social Contagion and Information Technology Diffusion: The Adoption of Electronic Medical Records in US Hospitals</title><link>http://www.example.com/articles/1</link><description>Angst, Corey M.; Agarwal, Ritu; Sambamurthy, V.; Kelley, Ken
We use a social contagion lens to study the dynamic, temporal process of the diffusion of electronic medical records in the population of U. S. hospitals. Social contagion acknowledges the mutual influence among organizations within an institutional field and implicates information transmission through direct contact and observation as the mechanisms underlying influence transfer. We propose hypotheses predicting a hospital's likelihood of adopting electronic medical records as a function of its susceptibility to the influence of prior adopters, the infectiousness or potency of influence exerted by adopting hospitals, and its social and spatial proximity to prior adopters. Results obtained by fitting a heterogeneous diffusion model to data from a sample drawn from an annual survey, spanning 1975 to 2005, of almost 4,000 U. S. hospitals suggest that diffusion can be accelerated if specific attention is given to increasing social contagion effects. In particular, with respect to susceptibility to influence, greater hospital size and age are positively related to the likelihood of adoption for nonadopters, whereas younger hospitals are associated with greater infectiousness for adopters. A hospital's "celebrity" status also contributes to its infectiousness. We further find strong effects for social proximity and significant regional effects for spatial proximity and hospital size, suggesting that geographical covariates should be included in diffusion studies. Results also reinforce the importance of theorizing about and including interactions in examinations of social contagion.</description><author>Angst, Corey M.; Agarwal, Ritu; Sambamurthy, V.; Kelley, Ken</author><pubDate>Sun, 01 Aug 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Lean and Hungry or Fat and Content? Entrepreneurs' Wealth and Start-Up Performance</title><link>http://www.example.com/articles/1</link><description>Hvide, Hans K.; Moen, Jarle
If entrepreneurs are liquidity constrained and not able to borrow to operate on an efficient scale, economic theory predicts that entrepreneurs with more personal wealth should do better than those with less wealth. We test this hypothesis using a novel data set covering a large panel of start-ups from Norway. Consistent with liquidity constraints, we find a positive relation between founder prior wealth and start-up size. The relationship between prior wealth and start-up performance, as measured by profitability on assets, increases in the first three wealth quartiles. In the top wealth quartile, however, profitability drops sharply in wealth. Our findings are consistent with a luxury good interpretation of entrepreneurship and that higher wealth may induce a less alert or a less dedicated management. We conclude that an abundance of resources might do more harm than good for start-ups.</description><author>Hvide, Hans K.; Moen, Jarle</author><pubDate>Sun, 01 Aug 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Staffing Call Centers with Uncertain Demand Forecasts: A Chance-Constrained Optimization Approach</title><link>http://www.example.com/articles/1</link><description>Gurvich, Itai; Luedtke, James; Tezcan, Tolga
We consider the problem of staffing call centers with multiple customer classes and agent types operating under quality-of-service (QoS) constraints and demand rate uncertainty. We introduce a formulation of the staffing problem that requires that the QoS constraints are met with high probability with respect to the uncertainty in the demand rate. We contrast this chance-constrained formulation with the average-performance constraints that have been used so far in the literature. We then propose a two-step solution for the staffing problem under chance constraints. In the first step, we introduce a random static planning problem (RSPP) and discuss how it can be solved using two different methods. The RSPP provides us with a first-order (or fluid) approximation for the true optimal staffing levels and a staffing frontier. In the second step, we solve a finite number of staffing problems with known arrival rates-the arrival rates on the optimal staffing frontier. Hence, our formulation and solution approach has the important property that it translates the problem with uncertain demand rates to one with known arrival rates. The output of our procedure is a solution that is feasible with respect to the chance constraint and nearly optimal for large call centers.</description><author>Gurvich, Itai; Luedtke, James; Tezcan, Tolga</author><pubDate>Thu, 01 Jul 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Workplace Peers and Entrepreneurship</title><link>http://www.example.com/articles/1</link><description>Nanda, Ramana; Sorensen, Jesper B.
We examine whether the likelihood of entrepreneurial activity is related to the prior career experiences of an individual's coworkers, using a unique matched employer-employee panel data set. We argue that coworkers can increase the likelihood that an individual will perceive entrepreneurial opportunities as well as increase his or her motivation to pursue those opportunities. We find that an individual is more likely to become an entrepreneur if his or her coworkers have been entrepreneurs before. Peer influences also appear to be substitutes for other sources of entrepreneurial influence: we find that peer influences are strongest for those who have less exposure to entrepreneurship in other aspects of their lives.</description><author>Nanda, Ramana; Sorensen, Jesper B.</author><pubDate>Thu, 01 Jul 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Efficient Structures for Innovative Social Networks</title><link>http://www.example.com/articles/1</link><description>Lovejoy, William S.; Sinha, Amitabh
What lines of communication among members of an organization are most productive in the early, ideation phase of innovation? We investigate this question with a recombination and selection model of knowledge transfer operating through a social network. We find that ideation is accelerated when people in the organization dynamically churn through a large (ideally the entire population) set of conversational partners over time, which naturally begets short path lengths and eliminates information bottlenecks. Group meetings, in which the content of conversations is available to all for consideration, are another way to learn in parallel and accelerate the ideation process, although for complex problems they may not offer significant advantages over the best decentralized networks. The idealized core-periphery graphs emerge as an important family on the time-cost efficient frontier. New sociometrics for the analyses of innovation processes emerge from this investigation.</description><author>Lovejoy, William S.; Sinha, Amitabh</author><pubDate>Thu, 01 Jul 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Detecting Management Fraud in Public Companies</title><link>http://www.example.com/articles/1</link><description>Cecchini, Mark; Aytug, Haldun; Koehler, Gary J.; Pathak, Praveen
This paper provides a methodology for detecting management fraud using basic financial data. The methodology is based on support vector machines. An important aspect therein is a kernel that increases the power of the learning machine by allowing an implicit and generally nonlinear mapping of points, usually into a higher dimensional feature space. A kernel specific to the domain of finance is developed. This financial kernel constructs features shown in prior research to be helpful in detecting management fraud. A large empirical data set was collected, which included quantitative financial attributes for fraudulent and nonfraudulent public companies. Support vector machines using the financial kernel correctly labeled 80% of the fraudulent cases and 90.6% of the nonfraudulent cases on a holdout set. Furthermore, we replicate other leading fraud research studies using our data and find that our method has the highest accuracy on fraudulent cases and competitive accuracy on nonfraudulent cases. The results validate the financial kernel together with support vector machines as a useful method for discriminating between fraudulent and nonfraudulent companies using only publicly available quantitative financial attributes. The results also show that the methodology has predictive value because, using only historical data, it was able to distinguish fraudulent from nonfraudulent companies in subsequent years.</description><author>Cecchini, Mark; Aytug, Haldun; Koehler, Gary J.; Pathak, Praveen</author><pubDate>Thu, 01 Jul 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Why Are Bad Products So Hard to Kill?</title><link>http://www.example.com/articles/1</link><description>Simester, Duncan; Zhang, Juanjuan
It is puzzling that firms often continue to invest in product development projects when they should know that demand will be low. We argue that bad products are hard to kill because firms face an inherent conflict when designing managers' incentives. Rewarding success encourages managers to forge ahead even when demand is low. To avoid investing in low-demand products, the firm must also reward decisions to kill products. However, rewarding managers for killing products effectively undermines the rewards for success. The inability to resolve this tension forces the firm to choose between paying an even larger bonus for success and accepting continued investment in low-demand products. We explore the boundaries of this argument by analyzing how the timing of demand information affects product investment decisions.</description><author>Simester, Duncan; Zhang, Juanjuan</author><pubDate>Thu, 01 Jul 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Structural Estimation of the Effect of Out-of-Stocks</title><link>http://www.example.com/articles/1</link><description>Musalem, Andres; Olivares, Marcelo; Bradlow, Eric T.; Terwiesch, Christian; Corsten, Daniel
W e develop a structural demand model that endogenously captures the effect of out-of-stocks on customer choice by simulating a time-varying set of available alternatives. Our estimation method uses store-level data on sales and partial information on product availability. Our model allows for flexible substitution patterns, which are based on utility maximization principles and can accommodate categorical and continuous product characteristics. The methodology can be applied to data from multiple markets and in categories with a relatively large number of alternatives, slow-moving products, and frequent out-of-stocks (unlike many existing approaches). In addition, we illustrate how the model can be used to assist the decisions of a store manager in two ways. First, we show how to quantify the lost sales induced by out-of-stock products. Second, we provide insights on the financial consequences of out-of-stocks and suggest price promotion policies that can be used to help mitigate their negative economic impact, which run counter to simple commonly used heuristics.</description><author>Musalem, Andres; Olivares, Marcelo; Bradlow, Eric T.; Terwiesch, Christian; Corsten, Daniel</author><pubDate>Thu, 01 Jul 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Is Regime Switching in Stock Returns Important in Portfolio Decisions?</title><link>http://www.example.com/articles/1</link><description>Tu, Jun
The stock market displays regime switching between upturns and downturns. This paper provides a Bayesian framework for making portfolio decisions that takes this regime switching into account, together with asset pricing model uncertainty and parameter uncertainty. The findings reveal that the economic value of accounting for regimes is substantially independent of whether or not model and parameter uncertainties are incorporated: the certainty-equivalent losses associated with ignoring regime switching are generally above 2% per year and can be as high as 10%. These results suggest that the more realistic regime switching model is fundamentally different from the commonly used single-state model, and hence should be employed instead in portfolio decisions irrespective of concerns about model or parameter uncertainty.</description><author>Tu, Jun</author><pubDate>Thu, 01 Jul 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Vertically Differentiated Simultaneous Vickrey Auctions: Theory and Experimental Evidence</title><link>http://www.example.com/articles/1</link><description>Bapna, Ravi; Dellarocas, Chrysanthos; Rice, Sarah
We study settings where a number of sellers simultaneously offer vertically differentiated Vickrey auctions for imperfect substitute goods to unit-demand buyers. Vertical differentiation can arise from differences in item quality, item value certainty, seller reliability, or a combination of these factors. We characterize the form of the bidding equilibria and derive expressions for the corresponding allocative efficiency and expected seller revenue. When bidders are restricted to submit at most one bid, our theory predicts the existence of a unique Bayes-Nash equilibrium that resembles a form of probabilistic "mating-of-likes." Allowing unit-demand bidders to place an arbitrary number of bids induces complex strategy profiles where bidders place positive bids in all available auctions. Higher bidder types tend to follow more targeted strategies, focusing their "serious" bids on fewer and, generally, higher quality auctions. The nature of the bidding equilibria introduces allocative inefficiencies that arise from the lack of coordination in auction selection among bidders. We test our theoretical propositions in a controlled laboratory experiment while also utilizing a domain specific risk score to help assess how the bidders' risk type affects their bidding behavior. In support of our theory we find evidence of a probabilistic assortative matching between bidder and auction types. We also find that low risk type bidders tend to crowd on the highest auction and will pay a premium for the certainty it offers, whereas high risk type bidders fail to appropriately adjust for risk associated with the lowest auction, leading to overbidding. These lead to an interesting focal anomaly whereby bids are concentrated on the highest and lowest auctions, bypassing intermediate auctions.</description><author>Bapna, Ravi; Dellarocas, Chrysanthos; Rice, Sarah</author><pubDate>Thu, 01 Jul 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>eBay's Crowded Evenings: Competition Neglect in Market Entry Decisions</title><link>http://www.example.com/articles/1</link><description>Simonsohn, Uri
Do firms neglect competition when making entry decisions? This paper addresses this question analyzing the time of day at which eBay sellers set their auctions to end. Consistent with competition neglect, it is found that (i) a disproportionate share of auctions end during peak bidding hours, (ii) such hours exhibit lower selling rates and prices, and (iii) peak listing is more prevalent among sellers likely to have chosen ending time strategically, suggesting disproportionate entry is a mistake driven by bounded rationality rather than mindlessness. The results highlight the importance for marketing researchers of assessing rather than assuming the rationality of firm behavior.</description><author>Simonsohn, Uri</author><pubDate>Thu, 01 Jul 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Is Noise Trading Cancelled Out by Aggregation?</title><link>http://www.example.com/articles/1</link><description>Yan, Hongjun
Conventional wisdom suggests that investors' independent biases should cancel each other out and have little impact on equilibrium at the aggregate level. In contrast to this intuition, this paper analyzes models with biased investors and finds that biases often have a significant impact on the equilibrium even if they are independent across investors. First, independent biases affect the equilibrium asset price if investor demand for the asset is a nonlinear function of the bias. Second, even if the demand function is linear in the bias, it may still have a significant impact on the equilibrium because of the fluctuation of the wealth distribution. An initial run-up of the stock price makes optimistic investors richer, which then further pushes the stock price up and leads to lower future returns. This effect can lead to price overshooting, i.e., a negative expected future return. Similarly, an initial drop of the stock price leads to higher future returns. Simple calibrations show that a modest amount of biases can have a large impact on the equilibrium.</description><author>Yan, Hongjun</author><pubDate>Thu, 01 Jul 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Expectation and Chance-Constrained Models and Algorithms for Insuring Critical Paths</title><link>http://www.example.com/articles/1</link><description>Shen, Siqian; Smith, J. Cole; Ahmed, Shabbir
In this paper, we consider a class of two-stage stochastic optimization problems arising in the protection of vital arcs in a critical path network. A project is completed after a series of dependent tasks are all finished. We analyze a problem in which task finishing times are uncertain but can be insured a priori to mitigate potential delays. A decision maker must trade off costs incurred in insuring arcs with expected penalties associated with late project completion times, where lateness penalties are assumed to be lower semicontinuous nondecreasing functions of completion time. We provide decomposition strategies to solve this problem with respect to either convex or nonconvex penalty functions. In particular, for the nonconvex penalty case, we employ the reformulation-linearization technique to make the problem amenable to solution via Benders decomposition. We also consider a chance-constrained version of this problem, in which the probability of completing a project on time is sufficiently large. We demonstrate the computational efficacy of our approach by testing a set of size- and-complexity diversified problems, using the sample average approximation method to guide our scenario generation.</description><author>Shen, Siqian; Smith, J. Cole; Ahmed, Shabbir</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Capturing Consumption Flexibility in Assortment Choice from Scanner Panel Data</title><link>http://www.example.com/articles/1</link><description>Guo, Liang
This study develops and estimates a model to empirically identify two behavioral effects (namely consumption flexibility and state dependence) that may underlie temporal and horizontal assortment choice, using scanner panel data where consumption information is unavailable. The proposed approach permits a consumer's consumption utility to be dependent on previous consumptions, thus capturing state dependence both across purchase occasions and within horizontal assortments. Moreover, consumers' purchase and consumption decisions are modeled at two distinctive and sequentially related stages, which allows for incorporating the effect of consumption flexibility. The model is estimated on scanner panel data of yogurt purchase. It is found that the two captured effects provide strong empirical support with face validity for the temporal and horizontal assortment choice patterns observed in the data. The behavioral insights derived from estimating the proposed model can also be translated into significant managerial implications.</description><author>Guo, Liang</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Nested Simulation in Portfolio Risk Measurement</title><link>http://www.example.com/articles/1</link><description>Gordy, Michael B.; Juneja, Sandeep
Risk measurement for derivative portfolios almost invariably calls for nested simulation. In the outer step, one draws realizations of all risk factors up to the horizon, and in the inner step, one reprices each instrument in the portfolio at the horizon conditional on the drawn risk factors. Practitioners may perceive the computational burden of such nested schemes to be unacceptable and adopt a variety of second-best pricing techniques to avoid the inner simulation. In this paper, we question whether such short cuts are necessary. We show that a relatively small number of trials in the inner step can yield accurate estimates, and we analyze how a fixed computational budget may be allocated to the inner and the outer step to minimize the mean square error of the resultant estimator. Finally, we introduce a jackknife procedure for bias reduction.</description><author>Gordy, Michael B.; Juneja, Sandeep</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Open Platform Strategies and Innovation: Granting Access vs. Devolving Control</title><link>http://www.example.com/articles/1</link><description>Boudreau, Kevin
This paper studies two fundamentally distinct approaches to opening a technology platform and their different impacts on innovation. One approach is to grant access to a platform and thereby open up markets for complementary components around the platform. Another approach is to give up control over the platform itself. Using data on 21 handheld computing systems (1990-2004), I find that granting greater levels of access to independent hardware developer firms produces up to a fivefold acceleration in the rate of new handheld device development, depending on the precise degree of access and how this policy was implemented. Where operating system platform owners went further to give up control (beyond just granting access to their platforms) the incremental effect on new device development was still positive but an order of magnitude smaller. The evidence from the industry and theoretical arguments both suggest that distinct economic mechanisms were set in motion by these two approaches to opening.</description><author>Boudreau, Kevin</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The World Is Not Small for Everyone: Inequity in Searching for Knowledge in Organizations</title><link>http://www.example.com/articles/1</link><description>Singh, Jasjit; Hansen, Morten T.; Podolny, Joel M.
We explore why some employees may be at a disadvantage in searching for information in organizations. The "small-world" argument in social network theory emphasizes that people are, on average, only a few connections away from the information they seek. However, we argue that such a network structure does not benefit everyone: some employees may have longer search paths in locating knowledge in an organization-their world may be large. We theorize that this disadvantage is the result of more than just an inferior network position. Instead, two mechanisms-periphery status and homophily-jointly operate to aggravate the inefficiency of search for knowledge. Employees who belong to the periphery of an organization because of their minority gender status, lower tenure, or poor connectedness have limited awareness of who knows what and a lower ability to seek help from others best suited to guide the search. When they start a search chain, they are likely to engage in homophilous search by contacting colleagues like themselves, thus contacting others who also belong to the periphery. To search effectively, employees on the periphery need to engage in heterophilous search behaviors by crossing social boundaries. We find support for these arguments in a network field experiment consisting of 381 unfolding search chains in a large multinational professional services firm. The framework helps explain employees' unequal access to the knowledge they seek, a poorly understood yet important type of organizational inequity in an information economy.</description><author>Singh, Jasjit; Hansen, Morten T.; Podolny, Joel M.</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Impact of Information Technology on Academic Scientists' Productivity and Collaboration Patterns</title><link>http://www.example.com/articles/1</link><description>Ding, Waverly W.; Levin, Sharon G.; Stephan, Paula E.; Winkler, Anne E.
This study investigates the impact of information technology (IT) on productivity and collaboration patterns in academe. Our data combine information on the diffusion of two noteworthy innovations in IT-BITNET and the Domain Name System (DNS)-with career-history data on research-active life scientists. We analyzed a random sample of 3,114 research-active life scientists from 314 U.S. institutions over a 25-year period and find that the availability of BITNET on a scientist's campus has a positive effect on his or her productivity and collaborative network. Our findings also support the hypothesis of a differential effect of IT across subgroups of the scientific labor force. Women scientists and those working at nonelite institutions benefit more from the availability of IT in terms of overall research output and an increase in the number of new coauthors they work with than do men or individuals at elite institutions. These results suggest that IT is an equalizing force, providing a greater boost to productivity and more collaboration opportunities for scientists who are more marginally positioned in academe.</description><author>Ding, Waverly W.; Levin, Sharon G.; Stephan, Paula E.; Winkler, Anne E.</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Deal or No Deal: Hormones and the Mergers and Acquisitions Game</title><link>http://www.example.com/articles/1</link><description>Levi, Maurice; Li, Kai; Zhang, Feng
Young male CEOs appear to be combative: they are 4% more likely to be acquisitive and, having initiated an acquisition, they are over 20% more likely to withdraw an offer. Furthermore, a young target male CEO is 2% more likely to force a bidder to resort to a tender offer. We argue that this combative nature is a result of testosterone levels that are higher in young males. Testosterone, a hormone associated with male dominance seeking, has been shown to influence prospects for a cooperative outcome of the ultimatum game. Specifically, high-testosterone responders tend to reject low offers even though this is against their interest. It has been argued that this is consistent with a low offer being seen as dominance seeking. The acts of attempting or resisting an acquisition can be viewed as striving to achieve dominance. We argue that the evidence reported in this paper is consistent with the presence of a significant hormone effect in mergers and acquisitions.</description><author>Levi, Maurice; Li, Kai; Zhang, Feng</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Strategies to Fight Ad-Sponsored Rivals</title><link>http://www.example.com/articles/1</link><description>Casadesus-Masanell, Ramon; Zhu, Feng
We analyze the optimal strategy of a high-quality incumbent that faces a low-quality ad-sponsored competitor. In addition to competing through adjustments of tactical variables such as price or the number of ads a product carries, we allow the incumbent to consider changes in its business model. We consider four alternative business models: a subscription-based model; an ad-sponsored model; a mixed model in which the incumbent offers a product that is both subscription based and ad sponsored; and a dual model in which the incumbent offers two products, one based on the ad-sponsored model and the other based on the mixed business model. We show that the optimal response to an ad-sponsored rival often entails business model reconfigurations. We also find that when there is an ad-sponsored entrant, the incumbent is more likely to prefer to compete through the subscription-based or the ad-sponsored model, rather than the mixed or the dual model, because of cannibalization and endogenous vertical differentiation concerns. We discuss how our study helps improve our understanding of notions of strategy, business model, and tactics in the field of strategy.</description><author>Casadesus-Masanell, Ramon; Zhu, Feng</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>International Diversification with Factor Funds</title><link>http://www.example.com/articles/1</link><description>Eun, Cheol S.; Lai, Sandy; de Roon, Frans A.; Zhang, Zhe
We propose a new investment strategy employing "factor funds" to systematically enhance the mean-variance efficiency of international diversification. Our approach is motivated by the increasing evidence that size (SMB), book-to-market (HML), and momentum (MOM) factors, along with the market factor, adequately describe international stock returns, and by the direct link between investors' portfolio choice problems and international asset pricing theories and tests. Using data from 10 developed countries during the period 1981-2008, we show that the "augmented" optimal portfolio involving local factor funds substantially outperforms the "benchmark" optimal portfolio comprising country market indices only as measured by their portfolio Sharpe ratios. This strongly rejects the intersection hypothesis which posits that the local factor funds do not span investment opportunities beyond what country market indices do. Among the three classes of factor funds, HML funds contribute most to the efficiency gains. In addition, the local version of factor funds outperforms the global factor funds. The added gains from local factor diversification are significant for both in-sample and out-of-sample periods, and for a realistic range of additional investment costs for factor funds, and remain robust over time.</description><author>Eun, Cheol S.; Lai, Sandy; de Roon, Frans A.; Zhang, Zhe</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Do Inventory and Gross Margin Data Improve Sales Forecasts for US Public Retailers?</title><link>http://www.example.com/articles/1</link><description>Kesavan, Saravanan; Gaur, Vishal; Raman, Ananth
Firm-level sales forecasts for retailers can be improved if we incorporate cost of goods sold, inventory, and gross margin (defined by us as the ratio of sales to cost of goods sold) as three endogenous variables. We construct a simultaneous equations model, estimated using public financial and nonfinancial data, to provide joint forecasts of annual cost of goods sold, inventory, and gross margin for retailers using historical data. We show that sales forecasts from this model are more accurate than consensus forecasts from equity analysts. Further, the residuals from this model for one fiscal year are used to predict retailers for whom the relative advantage of model forecasts over consensus forecasts would be large in the next fiscal year. Our results show that historical inventory and gross margin contain information useful to forecast sales, and that equity analysts do not fully utilize this information in their sales forecasts.</description><author>Kesavan, Saravanan; Gaur, Vishal; Raman, Ananth</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Diversification, Diseconomies of Scope, and Vertical Contracting: Evidence from the Taxicab Industry</title><link>http://www.example.com/articles/1</link><description>Rawley, Evan; Simcoe, Timothy S.
This paper studies how firms reorganize following diversification, proposing that firms use outsourcing, or vertical disintegration, to manage diseconomies of scope. We also consider the origins of scope diseconomies, showing how different underlying mechanisms generate contrasting predictions about the link between within-firm task heterogeneity and the incentive to outsource following diversification. We test these propositions using microdata on taxicab and limousine fleets from the Economic Census. The results show that taxicab firms outsource, by shifting the composition of their fleets toward owner-operator drivers, when they diversify into the limousine business. The magnitude of the shift toward driver ownership is larger in less urban markets, where the tasks performed by taxicab and limousine drivers are more similar. These findings suggest that (1) firms use outsourcing to manage diseconomies of scope at a particular point in the value chain and (2) interagent conflicts can be an important source of scope diseconomies.</description><author>Rawley, Evan; Simcoe, Timothy S.</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Contracting for Infrequent Restoration and Recovery of Mission-Critical Systems</title><link>http://www.example.com/articles/1</link><description>Kim, Sang-Hyun; Cohen, Morris A.; Netessine, Serguei; Veeraraghavan, Senthil
Firms that rely on functioning mission-critical equipment for their businesses cannot afford significant operational downtime due to system disruptions. To minimize the impact of disruptions, a proper incentive mechanism has to be in place so that the suppliers provide prompt restoration and recovery services to the customer. A widely adopted incentive mechanism is performance-based contracting (PBC), in which suppliers receive compensation based on realized system uptime. A key obstacle is that disruptions occur infrequently, making it very expensive for a supplier to commit the necessary resources for recovery because they will be idle most of the time. In this paper, we show that designing a successful PBC creates nontrivial challenges that are unique to this environment. Namely, because of the infrequent and random nature of disruptions, a seemingly innocuous choice of performance measures used in contracts may create unexpected incentives, resulting in counterintuitive optimal behavior. We compare the efficiencies of two widely used contracts, one based on sample-average downtime and the other based on cumulative downtime, and identify the supplier's ability to influence the frequency of disruptions as an important factor in determining which contract performs better. We also show that implementing PBC may create high agency cost when equipment is very reliable. This counterintuitive situation arises because the realized downtimes from which the customer might intuit about the supplier's capacity investment are highly uncertain when there are not many samples of downtimes, i.e., when disruptions occur rarely.</description><author>Kim, Sang-Hyun; Cohen, Morris A.; Netessine, Serguei; Veeraraghavan, Senthil</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Timing of Effort and Reward: Three-Sided Moral Hazard in a Continuous-Time Model</title><link>http://www.example.com/articles/1</link><description>Yang, Jun
This paper studies a three-sided moral hazard problem with one agent exerting up-front effort and two agents exerting ongoing effort in a continuous-time model. The agents' efforts jointly affect the probability of survival and thus the expected cash flow of the project. In the optimal contract, the timing of payments reflects the timing of effort: payments for up-front effort precede payments for ongoing effort. Several patterns are possible for the cash allocation between the two agents with ongoing effort. In one case, where the two agents face equally severe moral hazard, they share the cash flow equally at each point of time. In another case, where the two agents have different severities of moral hazard, their payments are sequential. In a more general case, the two agents with ongoing effort first receive the cash flow alternately with an increasing frequency of switches and then divide the cash flow at each point of time. This study provides a framework for understanding a broad set of business-contracting issues. The characteristics suggested in the optimal contract help us analyze the causes of business failure such as the recent debacle of mortgage-backed securities.</description><author>Yang, Jun</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Does a Manufacturer Benefit from Selling to a Better-Forecasting Retailer?</title><link>http://www.example.com/articles/1</link><description>Taylor, Terry A.; Xiao, Wenqiang
This paper considers a manufacturer selling to a newsvendor retailer that possesses superior demand-forecast information. We show that the manufacturer's expected profit is convex in the retailer's forecasting accuracy: The manufacturer benefits from selling to a better-forecasting retailer if and only if the retailer is already a good forecaster. If the retailer has poor forecasting capabilities, then the manufacturer is hurt as the retailer's forecasting capability improves. More generally, the manufacturer tends to be hurt (benefit) by improved retailer forecasting capabilities if the product economics are lucrative (poor). Finally, the optimal procurement contract is a quantity discount contract.</description><author>Taylor, Terry A.; Xiao, Wenqiang</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Commercializing Science: Is There a University "Brain Drain" from Academic Entrepreneurship?</title><link>http://www.example.com/articles/1</link><description>Toole, Andrew A.; Czarnitzki, Dirk
When academic researchers participate in commercialization using for-profit firms, there is a potentially costly trade-off-their time and effort are diverted away from academic knowledge production. This is a form of brain drain on the not-for-profit research sector that may reduce knowledge accumulation and adversely impact long-run economic growth. In this paper, we examine the economic significance of the brain drain phenomenon using scientist-level panel data. We identify life scientists who start or join for-profit firms using information from the Small Business Innovation Research program and analyze the research performance of these scientists relative to a control group of randomly selected research peers. Combining our statistical results with data on the number of university spin-offs in the United States from 1994 to 2004, we find the academic brain drain has a nontrivial impact on knowledge production in the not-for-profit research sector.</description><author>Toole, Andrew A.; Czarnitzki, Dirk</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Using Scheduled Ordering to Improve the Performance of Distribution Supply Chains</title><link>http://www.example.com/articles/1</link><description>Chen, Lucy Gongtao; Gavirneni, Srinagesh
We study a supply chain with one supplier and many retailers that face exogenous end-customer demands. The supplier and the retailers all try to minimize their own inventory-related costs. In contrast to the retailers' newsvendor-type ordering behavior (under which retailers may place orders freely in every period), we propose two scheduled ordering policies: the scheduled balanced ordering policy (SBOP) and the scheduled synchronized ordering policy (SSOP). Under both the SBOP and SSOP, retailers are allowed to order freely only in one period of an ordering cycle, and receive fixed shipments in other periods. Retailers take turns to order freely under the SBOP, while under the SSOP all retailers order freely in the same period. With the average supply chain cost per period as the performance measure, we identify mathematical conditions under which scheduled ordering policies outperform the newsvendor-type ordering. Through a large-scale numerical study, we find that scheduled ordering policies are most effective when (i) the supplier's holding and expediting costs are high and the retailer's backorder cost is small, (ii) the end-customer demand variance and correlation are high, and (iii) the supplier's capacity is high. In addition, we observe that the behavior of the SSOP often complements that of the SBOP. Whereas the SBOP is better than SSOP when the supplier's capacity is low and when the end-customer demand correlation level is high, the SSOP is better when the opposite conditions prevail.</description><author>Chen, Lucy Gongtao; Gavirneni, Srinagesh</author><pubDate>Wed, 01 Sep 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Modifying the Mean-Variance Approach to Avoid Violations of Stochastic Dominance</title><link>http://www.example.com/articles/1</link><description>Blavatskyy, Pavlo R.
The mean-variance approach is an influential theory of decision under risk proposed by Markowitz (Markowitz, H. 1952. Portfolio selection. J. Finance 7(1) 77-91). The mean-variance approach implies violations of first-order stochastic dominance not commonly observed in the data. This paper proposes a new model in the spirit of the classical mean-variance approach without violations of stochastic dominance. The proposed model represents preferences by a functional U(L) - rho.gamma (L), where U(L) denotes the expected utility of lottery L, rho is an element of[-1, 1] is a subjective constant, and gamma(L) is the mean absolute (utility) semideviation of lottery L. The model comprises a linear trade-off between expected utility and utility dispersion. The model can accommodate several behavioral regularities such as the Allais paradox and switching behavior in Samuelson's example.</description><author>Blavatskyy, Pavlo R.</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>On the Number of State Variables in Options Pricing</title><link>http://www.example.com/articles/1</link><description>Li, Gang; Zhang, Chu
In this paper, we investigate the methodological issue of determining the number of state variables required for options pricing. After showing the inadequacy of the principal component analysis approach, which is commonly used in the literature, we adopt a nonparametric regression technique with nonlinear principal components extracted from the implied volatilities of various moneyness and maturities as proxies for the transformed state variables. The methodology is applied to the prices of S&amp;P 500 index options from the period 1996-2005. We find that, in addition to the index value itself, two state variables, approximated by the first two nonlinear principal components, are adequate for pricing the index options and fitting the data in both time series and cross sections.</description><author>Li, Gang; Zhang, Chu</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>CEO Ability, Pay, and Firm Performance</title><link>http://www.example.com/articles/1</link><description>Chang, Yuk Ying; Dasgupta, Sudipto; Hilary, Gilles
Do chief executive officers (CEOs) really matter? Do cross-sectional differences in firm performance and CEO pay reflect differences in CEO ability? Examining CEO departures over 1992-2002, we first find that the stock price reaction upon departure is negatively related to the firm's prior performance and to the CEO's prior pay. Second, the CEO's subsequent labor market success is greater if the firm's predeparture performance is better, the prior pay is higher, and the stock market's reaction is more negative. Finally, better prior performance, higher prior pay, and a more negative stock market reaction are associated with worse postdeparture firm performance. Collectively, these results reject the view that differences in firm performance stem entirely from non-CEO factors such as the firms' assets, other employees, or "luck," and that CEO pay is unrelated to the CEO's contribution to firm value.</description><author>Chang, Yuk Ying; Dasgupta, Sudipto; Hilary, Gilles</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Network-Independent Partner Selection and the Evolution of Innovation Networks</title><link>http://www.example.com/articles/1</link><description>Baum, Joel A. C.; Cowan, Robin; Jonard, Nicolas
Empirical research on strategic alliances has focused on the idea that partners are selected on the basis of social capital considerations. In this paper we emphasize instead the role of complementary knowledge stocks and knowledge dynamics, which have received surprisingly limited attention relative to social capital as forces behind the formation and dynamics of innovation networks. To marshal evidence in this regard, we design a simple model of partner selection in which firms ally for the purpose of learning and innovating, and in doing so create an industry network. We abstract completely from network-based structural and strategic motives for partner selection and focus instead on the idea that firms' knowledge bases must "fit" for joint learning and innovation to be possible, and thus for an alliance to be feasible. The striking result is that, despite containing no social capital considerations, this simple model replicates the firm conduct, network structure, and contingent effects of network position on performance observed and discussed in the empirical literature.</description><author>Baum, Joel A. C.; Cowan, Robin; Jonard, Nicolas</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Target Age and the Acquisition of Innovation in High-Technology Industries</title><link>http://www.example.com/articles/1</link><description>Ransbotham, Sam; Mitra, Sabyasachi
External acquisition of new technology is a growing trend in the innovation and product development process, particularly in high-technology industries, as firms complement internal research and development efforts with aggressive acquisition programs. Yet, despite its importance, there has been little empirical research on the timing of acquisition decisions in high-technology environments. Should organizations wait until more information is available about the target and its markets so that a better valuation can be obtained? Or should the target be acquired early to lower acquisition cost and gain early access to key technologies? Applying an event study methodology to technology acquisitions in the telecommunications industry from 1995 to 2001, we find evidence that supports acquiring early in the face of uncertainty. Our analytical model and empirical analysis uncover two characteristics of young targets that drive benefits from early acquisitions-flexible growth options that provide greater opportunities for synergistic fit, and greater valuation uncertainty that leads to lower prices. However, the negative effect of target age on acquirer value is partially mitigated if the target has recent patents or is privately held. In addition, the probability of acquisition is higher for targets that have signals of higher quality, and lower for targets that have superior access to capital and resources.</description><author>Ransbotham, Sam; Mitra, Sabyasachi</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Time-Tradeoff Sequences for Analyzing Discounting and Time Inconsistency</title><link>http://www.example.com/articles/1</link><description>Attema, Arthur E.; Bleichrodt, Han; Rohde, Kirsten I. M.; Wakker, Peter P.
This paper introduces time-tradeoff (TTO) sequences as a general tool to analyze intertemporal choice. We give several applications. For empirical purposes, we can measure discount functions without requiring any measurement of or assumption about utility. We can quantitatively measure time inconsistencies and simplify their qualitative tests. TTO sequences can be administered and analyzed very easily, using only pencil and paper. For theoretical purposes, we use TTO sequences to axiomatize (quasi-) hyperbolic discount functions. We demonstrate the feasibility of measuring TTO sequences in an experiment, in which we tested the axiomatizations. Our findings suggest rejections of several currently popular discount functions and call for the development of new ones. It is especially desirable that such discount functions can accommodate increasing impatience.</description><author>Attema, Arthur E.; Bleichrodt, Han; Rohde, Kirsten I. M.; Wakker, Peter P.</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Portfolio Liquidation with Distress Risk</title><link>http://www.example.com/articles/1</link><description>Brown, David B.; Carlin, Bruce Ian; Lobo, Miguel Sousa
We analyze the problem of an investor who needs to unwind a portfolio in the face of recurring and uncertain liquidity needs, with a model that accounts for both permanent and temporary price impact of trading. We first show that a risk-neutral investor who myopically deleverages his position to meet an immediate need for cash always prefers to sell more liquid assets. If the investor faces the possibility of a downstream shock, however, the solution differs in several important ways. If the ensuing shock is sufficiently large, the nonmyopic investor unwinds positions more than immediately necessary and, all else being equal, prefers to retain more of the assets with low temporary price impact in order to hedge against possible distress. More generally, optimal liquidation involves selling strictly more of the assets with a lower ratio of permanent to temporary impact, even if these assets are relatively illiquid. The results suggest that properly accounting for the possibility of future shocks should play a role in managing large portfolios.</description><author>Brown, David B.; Carlin, Bruce Ian; Lobo, Miguel Sousa</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Prediction Markets: Alternative Mechanisms for Complex Environments with Few Traders</title><link>http://www.example.com/articles/1</link><description>Healy, Paul J.; Linardi, Sera; Lowery, J. Richard; Ledyard, John O.
Double auction prediction markets have proven successful in large-scale applications such as elections and sporting events. Consequently, several large corporations have adopted these markets for smaller-scale internal applications where information may be complex and the number of traders is small. Using laboratory experiments, we test the performance of the double auction in complex environments with few traders and compare it to three alternative mechanisms. When information is complex we find that an iterated poll (or Delphi method) outperforms the double auction mechanism. We present five behavioral observations that may explain why the poll performs better in these settings.</description><author>Healy, Paul J.; Linardi, Sera; Lowery, J. Richard; Ledyard, John O.</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Technology Usage and Online Sales: An Empirical Study</title><link>http://www.example.com/articles/1</link><description>De, Prabuddha; Hu, Yu; Rahman, Mohammad S.
Despite the widespread adoption of search and recommendation technologies on the Internet, empirical research that examines the effect of these technologies is scarce. How do online consumers use these technologies? Does consumers' technology usage have an effect on the sales to them or their purchasing patterns? This paper empirically measures consumers' usage of website technologies by analyzing server log data. We match technology usage data to sales data, controlling for consumers' historical purchasing behavior. Our unique data set allows us to reveal the relationship between technology usage and online sales. Our analyses show that consumers' information technology usage has a significant effect on the sales to them, but this effect varies for different technologies and across different products. In particular, the use of directed search has a positive effect on the sales of promoted products, whereas it has a negative effect on the sales of nonpromoted products. In contrast, the use of a recommendation system has a positive effect on the sales of both promoted and nonpromoted products. Surprisingly, the use of nondirected search has an insignificant effect on online sales.</description><author>De, Prabuddha; Hu, Yu; Rahman, Mohammad S.</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Predicting the Next Big Thing: Success as a Signal of Poor Judgment</title><link>http://www.example.com/articles/1</link><description>Denrell, Jerker; Fang, Christina
Successfully predicting that something will become a big hit seems impressive. Managers and entrepreneurs who have made successful predictions and have invested money on this basis are promoted, become rich, and may end up on the cover of business magazines. In this paper, we show that an accurate prediction about such an extreme event, e. g., a big hit, may in fact be an indication of poor rather than good forecasting ability. We first demonstrate how this conclusion can be derived from a formal model of forecasting. We then illustrate that the basic result is consistent with data from two lab experiments as well as field data on professional forecasts from the Wall Street Journal Survey of Economic Forecasts.</description><author>Denrell, Jerker; Fang, Christina</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Capacity Sizing Under Parameter Uncertainty: Safety Staffing Principles Revisited</title><link>http://www.example.com/articles/1</link><description>Bassamboo, Achal; Randhawa, Ramandeep S.; Zeevi, Assaf
We study a capacity sizing problem in a service system that is modeled as a single-class queue with multiple servers and where customers may renege while waiting for service. A salient feature of the model is that the mean arrival rate of work is random (in practice this is a typical consequence of forecasting errors). The paper elucidates the impact of uncertainty on the nature of capacity prescriptions, and relates these to well established rules-of-thumb such as the square-root safety staffing principle. We establish a simple and intuitive relationship between the incoming load (measured in Erlangs) and the extent of uncertainty in arrival rates (measured via the coefficient of variation) that characterizes the extent to which uncertainty dominates stochastic variability or vice versa. In the former case it is shown that traditional square-root safety staffing logic is no longer valid, yet simple capacity prescriptions derived via a suitable newsvendor problem are surprisingly accurate.</description><author>Bassamboo, Achal; Randhawa, Ramandeep S.; Zeevi, Assaf</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>An Experimental Test of Advice and Social Learning</title><link>http://www.example.com/articles/1</link><description>Celen, Bogachan; Kariv, Shachar; Schotter, Andrew
Social learning describes any situation in which individuals learn by observing the behavior of others. In the real world, however, individuals learn not just by observing the actions of others but also from seeking advice. This paper introduces advice giving into the standard social-learning experiment of Celen and Kariv (Celen, B., S. Kariv. 2005. An experimental test of observational learning under imperfect information. Econom. Theory 26(3) 677-699). The experiments are designed so that both pieces of information-action and advice-are equally informative (in fact, identical) in equilibrium. Despite the informational equivalence of advice and actions, we find that subjects in a laboratory social-learning situation appear to be more willing to follow the advice given to them by their predecessor than to copy their action, and that the presence of advice increases subjects' welfare.</description><author>Celen, Bogachan; Kariv, Shachar; Schotter, Andrew</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Maximizing the Efficiency of the U.S. Liver Allocation System Through Region Design</title><link>http://www.example.com/articles/1</link><description>Kong, Nan; Schaefer, Andrew J.; Hunsaker, Brady; Roberts, Mark S.
Cadaveric liver transplantation is the only viable therapy for end-stage liver disease patients without a living donor. However, this type of transplantation is hindered in the United States by donor scarcity and rapid viability decay. Given these difficulties, the current U. S. liver allocation policy balances allocation likelihood and geographic proximity by allocating cadaveric livers hierarchically. We consider the problem of maximizing the efficiency of intraregional transplants through the redesign of liver allocation regions. We formulate the problem as a set partitioning problem that clusters organ procurement organizations into regions. We develop an estimate of viability-adjusted intraregional transplants to capture the trade-off between large and small regions. We utilize branch and price because the set partitioning formulation includes too many potential regions to handle explicitly. We formulate the pricing problem as a mixed-integer program and design a geographic-decomposition heuristic to generate promising columns quickly. Because the optimal solution depends on the design of geographic decomposition, we develop an iterative procedure that integrates branch and price with local search to alleviate this dependency. Finally, we present computational studies that show the benefit of region redesign and the efficacy of our solution approach. Our carefully calibrated test instances can be solved within a reasonable amount of time, and the resulting region designs yield a noticeable improvement over the current configuration.</description><author>Kong, Nan; Schaefer, Andrew J.; Hunsaker, Brady; Roberts, Mark S.</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Bundling of Technological Products with Network Externality</title><link>http://www.example.com/articles/1</link><description>Prasad, Ashutosh; Venkatesh, R.; Mahajan, Vijay
For many high-tech and Internet-related products, utility to consumers depends in part on the size of the user base, a phenomenon called network externality. A firm with a portfolio of these and other products-that are often asymmetric in their degree of network externality or marginal cost-may have to look beyond the traditional strategies of pure components, pure bundling, and mixed bundling. One such strategic alternative in a two-product case would be a so-called mixed bundling-1 under which the bundle and product 1 are offered, but the other product can only be purchased in a bundled form. The purpose of this study is to compare and contrast the impact of such asymmetry or symmetry in (direct) network externality and cost on the choice of bundling strategies. We model a monopolist firm that has a product in each of two categories and faces heterogeneous consumers. Results suggest that pure bundling is more profitable when both products have low marginal costs or high network externality whereas pure components or mixed bundling-1 is more profitable when the products diverge in their costs and network externality (e. g., only one product has network externality). Traditional mixed bundling is optimal in other instances.</description><author>Prasad, Ashutosh; Venkatesh, R.; Mahajan, Vijay</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Imperfect Competition in Financial Markets: An Empirical Study of Island and Nasdaq</title><link>http://www.example.com/articles/1</link><description>Biais, Bruno; Bisiere, Christophe; Spatt, Chester
The competition between Island and Nasdaq at the beginning of the century offers a natural laboratory to study competition between and within trading platforms and its consequences for liquidity supply. Our empirical strategy takes advantage of the difference between the pricing grids used on Island and Nasdaq, as well as of the decline in the Nasdaq tick. Using the finer grid prevailing on their market, Island limit order traders undercut Nasdaq quotes, much more than they undercut one another. The drop in the Nasdaq tick size triggered a drop in Island spreads, despite the Island tick already being very thin before Nasdaq decimalization. We also estimate a structural model of liquidity supply and find that Island limit order traders earned rents before Nasdaq decimalization. Our results suggest that perfect competition cannot be taken for granted, even on transparent open limit order books with a very thin pricing grid.</description><author>Biais, Bruno; Bisiere, Christophe; Spatt, Chester</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Behavior of Risk and Market Prices of Risk Over the Nasdaq Bubble Period</title><link>http://www.example.com/articles/1</link><description>Bakshi, Gurdip; Wu, Liuren
We exploit the information in the options market to study the variations of return risk and market prices of different sources of risk during the rise and fall of the Nasdaq market. We specify a model that accommodates fluctuations in both risk levels and market prices of different sources of risk, and we estimate the model using the time-series returns and option prices on the Nasdaq 100 tracking stock. Our analysis reveals three key variations during the period from March 1999 to March 2001. First, return volatility increased together with the rising Nasdaq index level, even though the two tend to move in opposite directions. Second, although the market price of diffusion return risk averages around 1.82 over the whole sample, the estimates reached negative territory at the end of 1999. The estimates reverted back to highly positive values after the collapse of the Nasdaq market. Third, the market price of jump risk increased with the rising Nasdaq valuation, and this increase in market price coincided with an increased imbalance in open interest between put and call options.</description><author>Bakshi, Gurdip; Wu, Liuren</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Seller Search and Market Outcomes in Online Auctions</title><link>http://www.example.com/articles/1</link><description>Kuruzovich, Jason; Viswanathan, Siva; Agarwal, Ritu
It has become widely accepted that information technology (IT) has had a profound influence on market transactions, with lower search costs for buyers often considered the key to lower prices and higher consumer welfare. However, sellers also use online channels to search for buyers whose product preferences and valuations match the sellers' offerings, and limited research has examined the impact of IT on sellers' search strategies or associated market outcomes. In this study, we investigate how market characteristics, the length of time the seller searches the auction marketplace for a buyer, and seller search in other websites influence the final sale price in online auctions. The online auction market for used vehicles provides a valuable opportunity to observe search processes of sellers, as the unique vehicle identification number associated with each vehicle enables the tracking of an individual item across both subsequent auctions and across other websites. We find that the market characteristics, duration of search, and search in other websites are each associated with a higher final sale price. Our findings highlight the importance of examining both buyer and seller search behaviors to further our understanding of the impacts of IT on market outcomes and efficiency.</description><author>Kuruzovich, Jason; Viswanathan, Siva; Agarwal, Ritu</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Design for Location? The Impact of Manufacturing Offshore on Technology Competitiveness in the Optoelectronics Industry</title><link>http://www.example.com/articles/1</link><description>Fuchs, Erica; Kirchain, Randolph
This paper presents a case study of the impact of manufacturing offshore on technology competitiveness in the optoelectronics industry. It examines a critical design/facility location decision being faced by optoelectronic component manufacturers. This paper uses a combination of simulation modeling and empirical data to demonstrate the economic constraints facing these firms. The results show that production location changes the relative production economics of the two competing designs-one emerging, one prevailing-that are currently perfect substitutes for each other on the telecom market, but not necessarily perfect substitutes in other markets in the long term. Specifically, if optoelectronic component firms shift production from the United States to countries in developing East Asia, the emerging designs that were developed in the United States no longer pay. Production characteristics are different abroad, and the prevailing design can be more cost effective in developing country production environments. The emerging designs, however, have performance characteristics that may be valuable in the long term to the larger computing market and to pushing forward Moore's law. This paper concludes by exploring the dilemma this creates for the optoelectronic component manufacturers and recommending a framework based on which the results may be generalized to other industries.</description><author>Fuchs, Erica; Kirchain, Randolph</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>What Makes Them Tick? Employee Motives and Firm Innovation</title><link>http://www.example.com/articles/1</link><description>Sauermann, Henry; Cohen, Wesley M.
Economists studying innovation and technological change have made significant progress toward understanding firms' profit incentives as drivers of innovation. However, innovative performance in firms should also depend heavily on the pecuniary and nonpecuniary motives of the employees actually working in research and development. Using data on more than 1,700 Ph.D. scientists and engineers, we examine the relationships between individuals' motives (e. g., desire for intellectual challenge, income, or responsibility) and their innovative performance. We find that motives matter, but different motives have very different effects: Motives regarding intellectual challenge, independence, and money have a strong positive relationship with innovative output, whereas motives regarding job security and responsibility tend to have a negative relationship. We also explore possible mechanisms underlying the observed relationships between motives and performance. Although hours worked (quantity of effort) have a strong positive effect on performance, motives appear to affect innovative performance primarily via other dimensions of effort (character of effort). Finally, we find some evidence that the role of motives differs in upstream research versus downstream development.</description><author>Sauermann, Henry; Cohen, Wesley M.</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Integrating Dynamic Pricing and Replenishment Decisions Under Supply Capacity Uncertainty</title><link>http://www.example.com/articles/1</link><description>Feng, Qi
This paper examines an integrated decision-making process regarding pricing for uncertain demand and sourcing from uncertain supply, which are often studied separately in the literature. Our analysis of the integrated system suggests that the base stock list price policy fails to achieve optimality even under deterministic demand. Instead, the optimal policy is characterized by two critical values: a reorder point and a target safety stock. Under this policy, a positive order is issued if and only if the inventory level is below the reorder point. When this happens, the optimal order and price are coordinated to achieve a constant target safety stock, which aims at hedging the demand uncertainty. We further investigate the profit improvement obtained from deploying dynamic pricing, as opposed to static pricing. Our results indicate that either supply limit or supply uncertainty may induce a significant benefit from dynamic pricing, and the compound effect of supply limit and uncertainty can be much more pronounced than the individual effects. Whether or not the supply capacity is limited has a major implication on the value of dynamic pricing. Under unlimited supply, dynamic pricing is more valuable when procurement cost is high or when demand is more sensitive to price. With limited supply, however, the capacity restriction tends to be relaxed, reducing the value of dynamic pricing.</description><author>Feng, Qi</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Selling with Binding Reservations in the Presence of Strategic Consumers</title><link>http://www.example.com/articles/1</link><description>Osadchiy, Nikolay; Vulcano, Gustavo
We analyze a revenue management problem in which a seller endowed with an initial inventory operates a selling with binding reservations scheme. Upon arrival, each consumer, trying to maximize his own utility, must decide either to buy at the full price and get the item immediately or to place a nonwithdrawable reservation at a discount price and wait until the end of the sales season where the leftover units are allocated according to first-come-first-serve priority. We prove the existence of an equilibrium consumer's strategy in this game and develop a simple and accurate asymptotic approximation for it. Through an extensive numerical study, we find that our proposed mechanism delivers higher revenues than the markdown practice with a preannounced fixed discount. The benefit is more emphasized when the seller is more patient than the consumers and (1) the ratio between the number of units put up for sale and the expected demand is moderate and/or (2) the heterogeneity of the consumers' valuations is moderate to high. In our numerical experiments, the revenue gap can reach more than 12%, which is quite significant for retail businesses that typically operate with narrow margins.</description><author>Osadchiy, Nikolay; Vulcano, Gustavo</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Firm as a Socialization Device</title><link>http://www.example.com/articles/1</link><description>Ramalingam, Abhijit; Rauh, Michael T.
Why do firms exist? What is their function? What do managers do? What is the role, if any, of social motivation in the market? In this paper, we address these questions with a new theory of the firm, which unites some major themes in management, principal-agent theory, and economic sociology. We show that although the market is a superior incentive mechanism, the firm has a comparative advantage with respect to social motivation. We then show that the market is efficient in environments that favor the provision of incentives, such as when subjective risk is low and performance is easy to measure. The firm is efficient in other environments where incentives are costly and/or ineffective. We compare our model and results with the views of Durkheim (Durkheim, E. 1984. The Division of Labor in Society. Free Press, New York) and Granovetter (Granovetter, M. 1985. Economic action and social structure: The problem of embeddedness. Amer. J. Sociol. 91(3) 481-510).</description><author>Ramalingam, Abhijit; Rauh, Michael T.</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Bundling Strategies When Products Are Vertically Differentiated and Capacities Are Limited</title><link>http://www.example.com/articles/1</link><description>Banciu, Mihai; Gal-Or, Esther; Mirchandani, Prakash
We consider a seller who owns two capacity-constrained resources and markets two products (components) corresponding to these resources as well as a bundle comprising the two components. In an environment where all customers agree that one of the two components is of higher quality than the other and that the bundle is of the highest quality, we derive the seller's optimal bundling strategy. We demonstrate that the optimal solution depends on the absolute and relative availabilities of the two resources as well as upon the extent of subadditivity of the quality of the products. The possible strategies that can arise as equilibrium behavior include a pure components strategy, a partial-or full-spectrum mixed bundling strategy, and a pure bundling strategy, where the latter strategy is optimal when capacities are unconstrained. These conclusions are contrary to findings in the prior literature on bundling that demonstrated the unambiguous dominance of the full-spectrum mixed bundling strategy. Thus, our work expands the frontier of bundling to an environment with vertically differentiated components and limited resources. We also explore how the bundling strategies change as we introduce an element of horizontal differentiation wherein different types of customers value the available components differently.</description><author>Banciu, Mihai; Gal-Or, Esther; Mirchandani, Prakash</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>A Dynamic Inventory Model with the Right of Refusal</title><link>http://www.example.com/articles/1</link><description>Bhaskaran, Sreekumar; Ramachandran, Karthik; Semple, John
We consider a dynamic inventory (production) model with general convex order (production) costs and excess demand that can be accepted or refused by the firm. Excess demand that is accepted is backlogged and results in a backlog cost whereas demand that is refused results in a lost sales charge. Endogenizing the sales decision is appropriate in the presence of general convex order costs so that the firm is not forced to backlog a unit whose subsequent satisfaction would reduce total profits. In each period, the firm must determine the optimal order and sales strategy. We show that the optimal policy is characterized by an optimal buy-up-to level that increases with the initial inventory level and an order quantity that decreases with the initial inventory level. More importantly, we show the optimal sales strategy is characterized by a critical threshold, a backlog limit, that dictates when to stop selling. This threshold is independent of the initial inventory level and the amount purchased. We investigate various properties of this new policy. As demand stochastically increases, the amount purchased increases but the amount backlogged decreases, reflecting a shift in the way excess demand is managed. We develop two regularity conditions, one that ensures some backlogs are allowed in each period, and another that ensures the amount backlogged is nondecreasing in the length of the planning horizon. We illustrate the buy-up-to levels in our model are bounded above by buy-up-to levels from the pure lost sales and pure backlogging models. We explore additional extensions using numerical experiments.</description><author>Bhaskaran, Sreekumar; Ramachandran, Karthik; Semple, John</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Bargaining Chains</title><link>http://www.example.com/articles/1</link><description>Lovejoy, William S.
We consider a firm that designs a new product and wishes to bring it to market but does not have ownership or control over all of the resources required to make that happen. The firm must select and contract with one of several possible tier 1 suppliers for necessary inputs, who do the same with their (tier 2) suppliers, etc. This general situation is common in industry. We assume tier-wise negotiations, sole sourcing within each tier, complete local information, and horizontal competition. We develop a bargaining-based solution to the negotiations between two adjacent multifirm tiers and show its consistency with familiar solution concepts from the theories of bargaining and cooperative games. We then link up multiple bargaining modules to generate chainwide predictions for efficiency and profitability in supply chains with an arbitrary number of tiers and an arbitrary number of firms per tier. We investigate the implications of the results for investments in process improvements or supplier development.</description><author>Lovejoy, William S.</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>An Exact Algorithm for Finding Extreme Supported Nondominated Points of Multiobjective Mixed Integer Programs</title><link>http://www.example.com/articles/1</link><description>Ozpeynirci, Ozgur; Koksalan, Murat
In this paper, we present an exact algorithm to find all extreme supported nondominated points of multiobjective mixed integer programs. The algorithm uses a composite linear objective function and finds all the desired points in a finite number of steps by changing the weights of the objective functions in a systematic way. We develop further variations of the algorithm to improve its computational performance and demonstrate our algorithm's performance on multiobjective assignment, knapsack, and traveling salesperson problems with three and four objectives.</description><author>Ozpeynirci, Ozgur; Koksalan, Murat</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Reassessing Data Quality for Information Products</title><link>http://www.example.com/articles/1</link><description>Dey, Debabrata; Kumar, Subodha
The quality profile of information retrieved from a database using a query is quite important in the context of managerial decision making. Parssian et al. (Parssian, A., S. Sarkar, V. S. Jacob. 2004. Assessing data quality for information products: Impact of selection, projection, and Cartesian product. Management Sci. 50(7) 967-982) propose a methodology to determine the quality profile of the result of a query from the quality profile of the source data. Although they consider an important problem, and the proposed methodology is quite useful in practice, some of their results for the selection operation are not correct in general. Here, we identify these errors and present appropriate corrections.</description><author>Dey, Debabrata; Kumar, Subodha</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Design and Analysis of Diagnostic Service Centers</title><link>http://www.example.com/articles/1</link><description>Wang, Xiaofang; Debo, Laurens G.; Scheller-Wolf, Alan; Smith, Stephen F.
In the health-care domain, diagnostic service centers provide advice to patients over the phone about what the most appropriate course of action is based on their symptoms. Managers of such centers must strike a balance between accuracy of advice, callers' waiting time, and staffing costs by setting the appropriate capacity (staffing) and service depth. We model this problem as a multiple-server queueing system, with the servers performing a sequential testing process and the customers deciding whether or not to use the service, based on their expectation of accuracy and congestion. We find the dual concerns of accuracy and congestion lead to a counterintuitive impact of capacity: Increasing capacity might increase congestion. In addition, (i) patient population size is an important driver in management decisions, not only in staffing but also in accuracy of advice; (ii) increasing asymmetry in error costs may not increase asymmetry in the corresponding error rates; and (iii) the error costs for the two major stakeholders-the service manager and the patient-may impact the optimal staffing level in different ways. Finally, we highlight the relevance of our model and results to challenges in practice elicited during interviews with current clinical researchers and practitioners.</description><author>Wang, Xiaofang; Debo, Laurens G.; Scheller-Wolf, Alan; Smith, Stephen F.</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Reference Dependence in Multilocation Newsvendor Models: A Structural Analysis</title><link>http://www.example.com/articles/1</link><description>Ho, Teck-Hua; Lim, Noah; Cui, Tony Haitao
We propose a behavioral theory to predict actual ordering behavior in multilocation inventory systems. The theory rests on a well-known stylized fact of human behavior: people's preferences are reference dependent. We incorporate reference dependence into the newsvendor framework by assuming that there are psychological costs of leftovers and stockouts. We also hypothesize that the psychological aversion to leftovers is greater than the disutility for stockouts. We then experimentally test the proposed theory in both the centralized and decentralized inventory structures using subjects motivated by substantial financial incentives. Consistent with the proposed theory, actual orders exhibit the so-called "pull-to-center" bias and the degree of bias is greater in the high-profit margin than in the low-profit margin condition. These systematic biases are shown to eliminate the risk-pooling benefit when the demands across store locations are strongly correlated. Because the proposed model nests the standard inventory and ex post inventory error minimization theories as special cases, one can systematically evaluate the predictive power of each alternative using the generalized likelihood principle. We structurally estimate all three theories using the experimental data, and the estimation results strongly suggest that the proposed behavioral theory captures actual orders and profits better. We also conduct two experiments to validate the behavioral model by manipulating the relative salience of the psychological costs of leftovers versus that of stockouts to alleviate the pull-to-center bias.</description><author>Ho, Teck-Hua; Lim, Noah; Cui, Tony Haitao</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Manipulation Robustness of Collaborative Filtering</title><link>http://www.example.com/articles/1</link><description>Van Roy, Benjamin; Yan, Xiang
A collaborative filtering system recommends to users products that similar users like. Collaborative filtering systems influence purchase decisions and hence have become targets of manipulation by unscrupulous vendors. We demonstrate that nearest neighbors algorithms, which are widely used in commercial systems, are highly susceptible to manipulation and introduce new collaborative filtering algorithms that are relatively robust.</description><author>Van Roy, Benjamin; Yan, Xiang</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Trading Higher Software Piracy for Higher Profits: The Case of Phantom Piracy</title><link>http://www.example.com/articles/1</link><description>Gopal, Ram D.; Gupta, Alok
Faced with the sustained problem of piracy that costs nearly $40 billion in annual revenue losses, the software industry has adopted a number of technical, legal, and economic strategies to curb piracy and stem the resulting losses. Our work complements and contributes to the existing literature by exploring the possible effect of another economic lever-product bundling-on the relationship governing piracy and seller profits. The traditional economic rationale of demand pooling from bundling that enables sellers to extract higher surplus and its particular attractiveness for information goods with negligible marginal and bundling costs carry over to our analysis. However, the presence of piracy injects several new facets to our analysis. Bundling creates a shared level of piracy of disparate products, and under certain conditions to the detriment of one of the products. We argue that by construction of the copyright laws, the act of bundling itself can have a deterrence effect. This deterrence effect, along with shared piracy of products and demand pooling are ingredients that together dictate the overall piracy, pricing, profit, and welfare outcomes. Our analysis reveals several interesting insights. Bundling can be profitable even when the very act of bundling increases the piracy level of one of the products in the bundle. Termed phantom piracy, this represents a situation where sellers trade off higher piracy for one product in favor of lower piracy for the other product while deriving overall higher profits. Extensive simulation analysis shows that the region of phantom piracy is vastly expanded when additional products are introduced to the bundle. Conversely, under certain conditions, a profit maximizing seller opts not to bundle even when bundling can serve to lower the overall level of piracy. Price discounts that are typically offered by bundling are sharply deepened when piracy enters the equation. When piracy is a phenomenon to contend with, product bundling always increases consumer surplus even in scenarios where the seller may not realize higher profits. Unlike other forms of price discrimination that are often viewed by consumers with a jaundiced eye as they attempt to extract additional surplus from the consumers, product bundling in the software context can be a win-win scenario for both the buyers and the sellers.</description><author>Gopal, Ram D.; Gupta, Alok</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Bundling Strategies Under Heavy-Tailed Valuations</title><link>http://www.example.com/articles/1</link><description>Ibragimov, Rustam; Walden, Johan
We develop a framework for the optimal bundling problem of a multiproduct monopolist, who provides goods to consumers with private valuations that are random draws from a distribution with heavy tails. We show that in the Vickrey auction setting, the buyers prefer separate provision of the goods to any bundles. We also provide a complete characterization of the optimal bundling strategies for a monopolist producer, who provides goods for profit-maximizing prices. For products with low marginal costs, the seller's optimal strategy is to provide goods separately when consumers' valuations are heavy-tailed and in a single bundle when valuations are thin-tailed. These conclusions are reversed for goods with high marginal costs. For simplicity, we use a specific class of independent and identically distributed random variables, but our results can be generalized to include dependence, skewness, and the case of nonidentical one-dimensional distributions.</description><author>Ibragimov, Rustam; Walden, Johan</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Conditional Coskewness in Stock and Bond Markets: Time-Series Evidence</title><link>http://www.example.com/articles/1</link><description>Yang, Jian; Zhou, Yinggang; Wang, Zijun
In the context of a three-moment intertemporal capital asset pricing model specification, we characterize conditional coskewness between stock and bond excess returns using a bivariate regime-switching model. We find that both conditional U. S. stock coskewness (the relation between stock return and bond volatility) and bond coskewness (the relation between bond return and stock volatility) command statistically and economically significant negative ex ante risk premiums. The impacts of stock and bond coskewness on the conditional stock and bond premiums are quite robust to various model specifications and various sample periods, and also hold in another major developed country (the United Kingdom). The findings also carry important implications for portfolio management.</description><author>Yang, Jian; Zhou, Yinggang; Wang, Zijun</author><pubDate>Mon, 01 Nov 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Investor Inattention and the Market Reaction to Merger Announcements</title><link>http://www.example.com/articles/1</link><description>Louis, Henock; Sun, Amy
Prior studies suggest that investors have limited attention. Tests of the inattention hypothesis have been performed in the context of relatively small corporate events, particularly earnings announcements. Presumably, large corporate events would always attract sufficient investor attention. However, we find evidence indicating that inattention affects investors' information processing even in the context of one of the largest and most important corporate events-merger announcements. More specifically, consistent with the notion that investors are less attentive to Friday announcements, we find that the market reaction to Friday stock swap announcements is muted, as evidenced by lower acquirers' merger announcement abnormal trading volumes and less pronounced acquirers' merger announcement abnormal stock returns.</description><author>Louis, Henock; Sun, Amy</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Mechanism Design for "Free" but "No Free Disposal" Services: The Economics of Personalization Under Privacy Concerns</title><link>http://www.example.com/articles/1</link><description>Chellappa, Ramnath K.; Shivendu, Shivendu
Online personalization services belong to a class of economic goods with a "no free disposal" (NFD) property where consumers do not always prefer more services to less because of the privacy concerns. These concerns arise from the revelation of information necessary for the provision of personalization services. We examine vendor strategies in a market where consumers have heterogeneous concerns about privacy. In successive generalizations, we allow the vendor to offer a fixed level of personalization, variable levels of personalization, and monetary transfers (coupons) to the consumers that depend on the level of personalization chosen. We show that a vendor offering a fixed level of personalization does not offer a coupon unless his marginal value of information (MVI) is sufficiently high, and even when personalization is costless, the vendor does not cover the market. Under a fixed services offering, the vendor serves the same market with or without couponing. Next, we demonstrate that in the absence of couponing, the vendor's optimal variable personalization services contract maximizes surplus for all heterogeneous consumers, which is in contrast to standard results from monopolistic screening. When the vendor can offer coupons that vary according to personalization levels, the optimal contract is not fully revealing unless his MVI is high and he will not offer coupons when this MVI is low. However, a vendor with a moderate MVI (between certain thresholds) offers a bunched contract, wherein consumers with low privacy concerns receive a variable services-coupon contract, those with moderate privacy concerns receive a fixed services-coupon contract, and those with high privacy concerns do not participate in the market. The coupon value is decreasing in privacy sensitivity of consumers.</description><author>Chellappa, Ramnath K.; Shivendu, Shivendu</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Competitive Consequences of Using a Category Captain</title><link>http://www.example.com/articles/1</link><description>Subramanian, Upender; Raju, Jagmohan S.; Dhar, Sanjay K.; Wang, Yusong
Many retailers designate one national brand manufacturer in each product category as a "category captain" to help manage the entire category. A category captain may perform demand-enhancing services such as better shelf arrangements, shelf-space management, and design and management of in-store displays. In this paper, we examine when and why a retailer may engage one manufacturer exclusively as a category captain to provide such service and the implications. We find that demand substitutability of competing brands gives rise to a service efficiency effect-service that expands the category is more effective in increasing a manufacturer's sales and margin than service that shifts demand from a rival's brand. We show that the service efficiency effect may motivate a category captain to provide a service that benefits all brands in the category even though doing so is more costly. We further show that, in categories that are less price competitive, there is higher competition between manufacturers to become the category captain. Consequently, a retailer may obtain better service by using a category captain than by engaging both manufacturers simultaneously. Our findings may help explain why a retailer may rely on a category captain despite concerns regarding opportunism and why there is limited empirical evidence of harm to rival manufacturers.</description><author>Subramanian, Upender; Raju, Jagmohan S.; Dhar, Sanjay K.; Wang, Yusong</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Culture Clash: The Costs and Benefits of Homogeneity</title><link>http://www.example.com/articles/1</link><description>Van den Steen, Eric
This paper develops an economic theory of the costs and benefits of corporate culture-in the sense of shared beliefs and values-in order to study the effects of "culture clash" in mergers and acquisitions. I first use a simple analytical framework to show that shared beliefs lead to more delegation, less monitoring, higher utility (or satisfaction), higher execution effort (or motivation), faster coordination, less influence activities, and more communication, but also to less experimentation and less information collection. When two firms that are each internally homogeneous but different from each other merge, the above results translate to specific predictions about how the change in homogeneity will affect firm behavior. This paper's predictions can also serve more in general as a test for the theory of culture as shared beliefs.</description><author>Van den Steen, Eric</author><pubDate>Fri, 01 Oct 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The End of the Robinson-Patman Act? Evidence from Legal Case Data</title><link>http://www.example.com/articles/1</link><description>Luchs, Ryan; Geylani, Tansev; Dukes, Anthony; Srinivasan, Kannan
The Robinson-Patman Act (RP), an antitrust statute aimed at protecting small businesses, limits price setting in distribution channels. To avoid costly penalties under RP, managers take a variety of precautions when pricing to retailers and wholesalers. But how likely is a court to find a defendant guilty of violating the RP? We find that this likelihood has dropped drastically as a result of recent Supreme Court rulings from more than 1 in 3 before 1993 to less than 1 in 20 for the period 2006-2010. The analysis also points to an increased success of the no harm to competition defense, which reflects the view that the courts have raised the hurdle for plaintiffs to establish competitive harm. Finally, our results indicate that smaller plaintiffs over time have fared worse than larger ones, a trend that challenges the notion that RP protects small businesses.</description><author>Luchs, Ryan; Geylani, Tansev; Dukes, Anthony; Srinivasan, Kannan</author><pubDate>Wed, 01 Dec 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Competing Manufacturers in a Retail Supply Chain: On Contractual Form and Coordination</title><link>http://www.example.com/articles/1</link><description>Cachon, Gerard P.; Koek, A. Guerhan
It is common for a retailer to sell products from competing manufacturers. How then should the firms manage their contract negotiations? The supply chain coordination literature focuses either on a single manufacturer selling to a single retailer or one manufacturer selling to many (possibly competing) retailers. We find that some key conclusions from those market structures do not apply in our setting, where multiple manufacturers sell through a single retailer. We allow the manufacturers to compete for the retailer's business using one of three types of contracts: a wholesale-price contract, a quantity-discount contract, or a two-part tariff. It is well known that the latter two, more sophisticated contracts enable the manufacturer to coordinate the supply chain, thereby maximizing the profits available to the firms. More importantly, they allow the manufacturer to extract rents from the retailer, in theory allowing the manufacturer to leave the retailer with only her reservation profit. However, we show that in our market structure these two sophisticated contracts force the manufacturers to compete more aggressively relative to when they only offer wholesale-price contracts, and this may leave them worse off and the retailer substantially better off. In other words, although in a serial supply chain a retailer may have just cause to fear quantity discounts and two-part tariffs, a retailer may actually prefer those contracts when offered by competing manufacturers. We conclude that the properties a contractual form exhibits in a one-manufacturer supply chain may not carry over to the realistic setting in which multiple manufacturers must compete to sell their goods through the same retailer.</description><author>Cachon, Gerard P.; Koek, A. Guerhan</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>An Analysis of Coordination Mechanisms for the US Cash Supply Chain</title><link>http://www.example.com/articles/1</link><description>Dawande, Milind; Mehrotra, Mili; Mookerjee, Vijay; Sriskandarajah, Chelliah
The overuse of its currency processing facilities by depository institutions (DIs) has motivated the Federal Reserve (Fed) to impose its new cash recirculation policy. This overuse is characterized by the practice of cross-shipping, where a DI both deposits and withdraws cash of the same denomination in the same business week in the same geographical area. Under the new policy, which came into effect July 2007, the Fed has imposed a recirculation fee on cross-shipped cash. The Fed intends to use this fee to induce DIs to effectively recirculate cash so that the societal cost of providing cash to the public is lowered. To examine the efficacy of this mechanism, we first characterize the social optimum and then analyze the response of DIs under a recirculation fee levied on cross-shipped cash. We show that neither a linear recirculation fee, which is the Fed's current practice, nor a more sophisticated nonlinear fee is sufficient to guarantee a socially optimal response from DIs. We then derive a fundamentally different mechanism that induces DIs to self-select the social optimum. Our mechanism incorporates a fairness adjustment that avoids penalizing DIs that recirculate their fair share of cash and rewards DIs that recirculate more than this amount. We demonstrate that the mechanism is easy to implement and tolerates a reasonable amount of imprecision in the problem parameters. We also discuss a concept of welfare-preserving redistribution wherein the Fed allows a group of DIs to reallocate (amongst themselves) their deposits and demand if such a possibility does not increase societal cost. Finally, we analyze the impact of incorporating the custodial inventory program, another component of the Fed's new policy.</description><author>Dawande, Milind; Mehrotra, Mili; Mookerjee, Vijay; Sriskandarajah, Chelliah</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Component-Based Technology Transfer in the Presence of Potential Imitators</title><link>http://www.example.com/articles/1</link><description>Sun, Jiong; Debo, Laurens G.; Kekre, Sunder; Xie, Jinhong
Technology transfer to low-cost locations offers global firms an opportunity to reduce their variable costs involved in serving emerging markets. However, such moves may also make imitation by local competitors easier. As a consequence, technology transfer may create competition in the local market. We introduce component-based technology transfer for the global firm as a means to deter or accommodate the imitators' entry, recognizing that components may differ in technological complexity. By choosing a subset of components to transfer, the global firm's decision has an impact not only on the imitators' fixed entry costs, but also on postentry competition based on variable costs. Our research identifies two different types of deterrence strategies-the barrier-erecting strategy and the market-grabbing strategy. In the former deterrence strategy, the global firm retains enough component technology in the home country to make the potential imitator's fixed entry costs so high that it is not worthwhile entering. In the latter deterrence strategy, the global firm transfers enough component technology to the emerging market, reducing the global firm's variable cost to make the potential imitator's revenues so low that it is not worthwhile entering. Which deterrence strategy the global firm should employ depends on the degree to which geographical proximity reduces imitation costs and the degree of differentiation between the local firm's and the global firm's products. Some other interesting and counterintuitive results arise. For example, it may benefit a global firm to transfer less technology for products with a higher emerging market potential.</description><author>Sun, Jiong; Debo, Laurens G.; Kekre, Sunder; Xie, Jinhong</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Innovation in Business Groups</title><link>http://www.example.com/articles/1</link><description>Belenzon, Sharon; Berkovitz, Tomer
Using novel data on European firms, this paper investigates the relationship between business groups and innovation. Controlling for various firm characteristics, we find that group affiliates are more innovative than standalones. We examine several hypotheses to explain this finding, focusing on group internal capital markets and knowledge spillovers. We find that group affiliation is particularly important for innovation in industries that rely more on external funding and in groups with more diversified capital sources, consistent with the internal capital markets hypothesis. Our results suggest that knowledge spillovers are not the main driver of innovation in business groups because firms affiliated with the same group do not have a common research focus and are unlikely to cite each other's patents.</description><author>Belenzon, Sharon; Berkovitz, Tomer</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Randomization vs. Selection: How to Choose in the Absence of Preference?</title><link>http://www.example.com/articles/1</link><description>Danan, Eric
Decision makers sometimes have to choose between alternative options about which they have no preference: either they judge the options equally valuable (indifference) or they have no judgment about their relative value (noncomparability). Choosing randomly is generally considered a natural way to deal with such situations. This paper shows, however, that systematic randomization between noncomparable options may lead to a chain of decisions resulting in monetary losses (a money pump). Furthermore, these losses can be avoided by deliberately selecting one of the noncomparable options instead of randomizing. Thus, randomization among noncomparable options is costly relative to deliberate selection. On the other hand, randomization among indifferent options is costless relative to deliberate selection.</description><author>Danan, Eric</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Vertical Flexibility in Supply Chains</title><link>http://www.example.com/articles/1</link><description>Hopp, Wallace J.; Iravani, Seyed M. R.; Xu, Wendy Lu
Jordan and Graves (Jordan, W. C., S. C. Graves. 1995. Principles on the benefits of manufacturing process flexibility. Management Sci. 41(4) 577-594) initiated a stream of research on supply chain flexibility, which was furthered by Graves and Tomlin (Graves, S. C., B. T. Tomlin. 2003. Process. exibility in supply chains. Management Sci. 49(7) 907-919), that examined various structures for achieving horizontal. exibility within a single level of a supply chain. In this paper, we extend the theory of supply chain. exibility by considering placement of vertical. exibility across multiple stages in a supply chain. Specifically, we consider two types of. exibility logistics. exibility and process flexibility-and examine how demand, production, and supply variability at a single stage impacts the best stage in the supply chain for each type of. exibility. Under the assumptions that margins are the same regardless of. exibility location, capacity investment costs are the same within and across stages, and. exibility is limited to a single stage of logistics ( process). exibility accompanied with necessary process (logistics). exibility, we show that both types of. exibility are most effective when positioned directly at the source of variability. However, although expected profit increases as logistics. exibility is positioned closer to the source of variability (i.e., downstream for demand variability and upstream for supply variability), locating process. exibility anywhere except at the stage with variability leads to the same decrease in expected profit.</description><author>Hopp, Wallace J.; Iravani, Seyed M. R.; Xu, Wendy Lu</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Package Size Decisions</title><link>http://www.example.com/articles/1</link><description>Koenigsberg, Oded; Kohli, Rajeev; Montoya, Ricardo
W e describe a model examining how a firm might choose the package size and price for a product that deteriorates over time. Our model considers four factors: (1) the usable life of the product, (2) the rates at which consumers use the product, (3) the relation between package size and the variable cost of the product, and (4) the minimum quantities consumers seek to consume for each dollar they spend (we call these reservation quantities). We allow heterogeneity in the usage rates and reservation quantities for the consumers. We show that when the cost increases as a linear or convex function of the package size, the firm should make packages of the smallest possible size. Smaller packages reduce waste and allow consumers to more closely match their purchases with desired consumption. This in turn allows the firm to charge a higher unit price and also sell more unit volume. The results imply that in a market with multiple package sizes ( produced by the same or competing firms), at least one of the packages must have the smallest possible size, provided the fixed cost of making the product is sufficiently low. For concave cost functions, the firm may find it optimal to make larger than smallest-size packages.</description><author>Koenigsberg, Oded; Kohli, Rajeev; Montoya, Ricardo</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Impact of Misalignment of Organizational Structure and Product Architecture on Quality in Complex Product Development</title><link>http://www.example.com/articles/1</link><description>Gokpinar, Bilal; Hopp, Wallace J.; Iravani, Seyed M. R.
Product architecture and organizational communication play significant roles in complex product development efforts. By using networks to characterize both product structure and communication patterns, we examine the impact of mismatches between these on new product development (NPD) performance. Specifically, we study the vehicle development process of a major auto company and use vehicle quality (warranty repairs) as our NPD performance metric. Our empirical results indicate that centrality in a product architecture network is related to quality according to an inverted-U relationship, which suggests that vehicle subsystems of intermediate complexity exhibit abnormally high levels of quality problems. To identify specific subsystems in danger of excessive quality problems, we characterize mismatches between product architecture and organizational structure by de. ning a new metric, called coordination deficit, and show that it is positively associated with quality problems. These results deepen our understanding of the impact of organizational structure and product architecture on the NPD process and provide tools with which managers can diagnose and improve their NPD systems.</description><author>Gokpinar, Bilal; Hopp, Wallace J.; Iravani, Seyed M. R.</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Commodity Trading with a Capacitated Storage Asset</title><link>http://www.example.com/articles/1</link><description>Secomandi, Nicola
This paper considers the so-called warehouse problem with both space and injection/withdrawal capacity limits. This is a foundational problem in the merchant management of assets for the storage of commodities, such as energy sources and natural resources. When the commodity spot price evolves according to an exogenous Markov process, this work shows that the optimal inventory-trading policy of a risk-neutral merchant is characterized by two stage and spot-price dependent basestock targets. Under some assumptions, these targets are monotone in the spot price and partition the available inventory and spot-price space in each stage into three regions, where it is, respectively, optimal to buy and inject, do nothing, and withdraw and sell. In some cases of practical importance, one can easily compute the optimal basestock targets. The structure of the optimal policy is nontrivial because in each stage the merchant's qualification of high (selling) and low (buying) commodity prices in general depends on the merchant's inventory availability. This is a consequence of the interplay between the capacity and space limits of the storage asset and brings to light the nontrivial nature of the interface between trading and operations. A computational analysis based on natural gas data shows that mismanaging this interface can yield significant value losses. Moreover, adapting the merchant's optimal trading policy to the spot-price stochastic evolution has substantial value. This value can be almost entirely generated by reacting to the unfolding of price uncertainty, that is, by sequentially reoptimizing a model that ignores this source of uncertainty.</description><author>Secomandi, Nicola</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Revenue Management with Strategic Customers: Last-Minute Selling and Opaque Selling</title><link>http://www.example.com/articles/1</link><description>Jerath, Kinshuk; Netessine, Serguei; Veeraraghavan, Senthil K.
Companies in a variety of industries (e.g., airlines, hotels, theaters) often use last-minute sales to dispose of unsold capacity. Although this may generate incremental revenues in the short term, the long-term consequences of such a strategy are not immediately obvious: More discounted last-minute tickets may lead to more consumers anticipating the discount and delaying the purchase rather than buying at the regular ( higher) prices, hence potentially reducing revenues for the company. To mitigate such behavior, many service providers have turned to opaque intermediaries, such as Hotwire.com, that hide many descriptive attributes of the service ( e. g., departure times for airline tickets) so that the buyer cannot fully predict the ultimate service provider. Using a stylized economic model, this paper attempts to explain and compare the benefits of last-minute sales directly to consumers versus through an opaque intermediary. We utilize the notion of rational expectations to model consumer purchasing decisions: Consumers make early purchase decisions based on expectations regarding future availability, and these expectations are correct in equilibrium. We show that direct last-minute sales are preferred over selling through an opaque intermediary when consumer valuations for travel are high or there is little service differentiation between competing service providers, or both; otherwise, opaque selling dominates. Moreover, contrary to the usual belief that such sales are purely mechanisms for disposal of unused capacity, we show that opaque selling becomes more preferred over direct last-minute selling as the probability of having high demand increases. When firms randomize between opaque selling and last-minute selling strategies, they are increasingly likely to choose the opaque selling strategy as the probability of high demand increases. When firms with unequal capacities use the opaque selling strategy, consumers know more clearly where the opaque ticket is from and the efficacy of opaque selling decreases.</description><author>Jerath, Kinshuk; Netessine, Serguei; Veeraraghavan, Senthil K.</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Navel Gazing: Academic Inbreeding and Scientific Productivity</title><link>http://www.example.com/articles/1</link><description>Horta, Hugo; Veloso, Francisco M.; Grediaga, Rocio
The practice of having Ph.D. graduates employed by the university that trained them, commonly called "academic inbreeding," has long been suspected to be damaging to scholarly practices and achievement. Despite this perception, existing work on academic inbreeding is scarce and mostly exploratory. Using data from Mexico, we find evidence that, first, academic inbreeding is associated with lower scholarly output. Second, the academically inbred faculty is relatively more centered on its own institution and less open to the rest of the scientific world. This navel-gazing tendency is a critical driver of its reduced scientific output when compared with noninbred faculties. Third, we reveal that academic inbreeding could be the result of an institutional practice, such that these faculty members contribute disproportionately more to teaching and outreach activities, which allows noninbred faculty members to dedicate themselves to the research endeavor. Thus, a limited presence of inbreds can benefit the research output of noninbreds and potentially the whole university, but a dominantly inbred environment will stifle productivity, even for noninbreds. Overall, our analysis suggests that administrators and policy makers in developing nations who aim to develop a thriving research environment should consider mechanisms to limit this practice.</description><author>Horta, Hugo; Veloso, Francisco M.; Grediaga, Rocio</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Charitable Motives and Bidding in Charity Auctions</title><link>http://www.example.com/articles/1</link><description>Leszczyc, Peter T. L. Popkowski; Rothkopf, Michael H.
Research on bidding in auctions has generally relied on the assumption of self-interested bidders. This work relaxes that assumption in the context of charity auctions. Because understanding charitable motives has important implications for auction design and charities' fundraising strategies, this study investigates bidders' specific types of charitable motives and the strength of these motives. We carry out three controlled field experiments consisting of real-life auctions conducted on a local Internet auction site. We use a novel design in which we simultaneously run charity and noncharity auctions for identical products and vary the percentage donated to charity. Results show that auctions with proceeds donated to charity lead to significantly higher selling prices, a result due to a higher bidding by bidders with charitable motives rather than to increased bidder entry. We also find that increased prices only occur when the charitable donation is a percentage of the auction revenue, and that a fixed charitable donation associated with each auction has no effect on prices. Furthermore, we find that prices are increasing in the percentage donated to charity. We find considerable support for a model of voluntary shill-like bidding, where charitable bidders try to increase proceeds in charity auctions. We also find that auctions with 25% of revenue donated to charity had higher net revenue than noncharity auctions. Hence, companies may be able to use charity auctions as part of a corporate social responsibility strategy and at the same time increase profitability even though they donate part of the proceeds to charity.</description><author>Leszczyc, Peter T. L. Popkowski; Rothkopf, Michael H.</author><pubDate>Mon, 01 Mar 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>An Example and a Proposal Concerning the Correlation of Worker Processing Times in Parallel Tasks</title><link>http://www.example.com/articles/1</link><description>Schultz, Kenneth L.; Schoenherr, Tobias; Nembhard, David
Models and understanding of line design depend on accurate assessments of the effects of design parameters on human actions. Although equity theory predicts that workers will react to the speed of people around them, experimental work has failed to find this effect in an industrial setting with parallel workstations or a change in coworkers. With the current research we contribute to the understanding of line design by using archival data from a manufacturing line. We show that workers do react to the speed of their coworkers, but that individual reactions vary widely. Because workers are different both in speed and reaction, managerial implications are not straightforward. We model an optimal and a heuristic rearrangement of workers and suggest a modified heuristic that performs well for increasing throughput. Our methodology combines empirical approaches, analytical modeling, and Monte Carlo simulation.</description><author>Schultz, Kenneth L.; Schoenherr, Tobias; Nembhard, David</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Detailing vs. Direct-to-Consumer Advertising in the Prescription Pharmaceutical Industry</title><link>http://www.example.com/articles/1</link><description>Bala, Ram; Bhardwaj, Pradeep
The pharmaceutical industry has always used sales representatives to target physicians (detailing), who are a key link in sales and market share for prescription pharmaceuticals. Since August of 1997, when the Food and Drug Administration eased the restrictions on direct-to-consumer advertising (DTCA), there has been a dramatic increase in the use of DTCA by pharmaceutical firms to target end customers (patients). DTCA seems to have two different effects on pharmaceutical markets. The first is to inform patients about the availability of drugs for some ailments, thus expanding the market (constructive). The second is to persuade patients to talk about specific brands when they meet physicians, with the objective of influencing market share (combative). We consider both effects of DTCA in the presence of a detailing program in a competitive environment. We incorporate the dynamics of physician-patient interaction in a game-theoretic model where firms decide on the form of DTCA to adopt (constructive or combative) and then compete in the marketplace by choosing detailing and DTCA levels. We answer four questions: What is the impact of adopting DTCA on competitive intensity? How do optimal detailing levels for a firm change with the adoption of DTCA? How should the DTCA strategy for a firm vary depending on whether it is stronger or weaker in its degree of influence in the physician's office? Finally, under what conditions would competing firms voluntarily decide to pursue constructive DTCA?</description><author>Bala, Ram; Bhardwaj, Pradeep</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Inventory Dynamics and Supply Chain Coordination</title><link>http://www.example.com/articles/1</link><description>Krishnan, Harish; Winter, Ralph A.
This paper extends the theory of supply chain incentive contracts from the static newsvendor framework of the existing literature to the simplest dynamic setting. A manufacturer distributes a product through retailers who compete on both price and fill rates. We show that inventory durability is the key factor in determining the underlying nature of incentive distortions and their contractual resolutions. When the product is highly perishable, retailers are biased toward excessive price competition and inadequate inventories. Vertical price floors or inventory buybacks (subsidies for unsold inventory) can coordinate incentives in both pricing and inventory decisions. When the product is less perishable, the distortion is reversed and vertical price ceilings or inventory penalties can coordinate incentives.</description><author>Krishnan, Harish; Winter, Ralph A.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The "I Designed It Myself" Effect in Mass Customization</title><link>http://www.example.com/articles/1</link><description>Franke, Nikolaus; Schreier, Martin; Kaiser, Ulrike
Many companies offer websites that enable customers to design their own individual products, which the manufacturer can then produce to order. To date, the economic value of products self-designed using mass customization (MC) toolkits has been attributed to the two factors of preference fit achieved (which should be as high as possible) and design effort (which should be as low as possible). On the basis of literature on behavioral decision making, we suggest a third factor, namely the awareness of being the creator of the product design. In the course of five different studies, we provide experimental evidence that this "I designed it myself" effect creates economic value for the customer. Regardless of the two other factors, self-designed products generate a significantly higher willingness to pay. This effect is mediated by feelings of accomplishment and moderated by the outcome of the process as well as the individual's perceived contribution to the self-design process. These findings have important implications for MC companies: It is not enough merely to design MC toolkits in such a way that preference fit is maximized and design effort is minimized. To capture the full value of MC, toolkits should also elicit "I designed it myself" feelings.</description><author>Franke, Nikolaus; Schreier, Martin; Kaiser, Ulrike</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Global Dual Sourcing: Tailored Base-Surge Allocation to Near- and Offshore Production</title><link>http://www.example.com/articles/1</link><description>Allon, Gad; Van Mieghem, Jan A.
When designing a sourcing strategy in practice, a key task is to determine the average order rates placed to each source because that affects cost and supplier management. We consider a firm that has access to a responsive nearshore source (e.g., Mexico) and a low-cost offshore source (e. g., China). The firm must determine an inventory sourcing policy to satisfy random demand over time. Unfortunately, the optimal policy is too complex to allow a direct answer to our key question. Therefore, we analyze a tailored base-surge (TBS) sourcing policy that is simple, used in practice, and captures the classic trade-off between cost and responsiveness. The TBS policy combines push and pull controls by replenishing at a constant rate from the offshore source and producing at the nearshore plant only when inventory is below a target. The constant base allocation allows the offshore facility to focus on cost efficiency, whereas the nearshore facility's quick response capability is utilized only dynamically to guarantee high service. The research goals are to (i) determine the allocation of random demand into base and surge capacity, (ii) estimate corresponding working capital requirements, and (iii) identify and value the key drivers of dual sourcing. We present performance bounds on the optimal cost and prove that economic optimization brings the system into heavy traffic. We analyze the sourcing policy that is asymptotically optimal for high-volume systems and present a simple "square-root" formula that is insightful to answer our questions and sufficiently accurate for practice, as is demonstrated with a validation study.</description><author>Allon, Gad; Van Mieghem, Jan A.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>An Empirical Examination of Goals and Performance-to-Goal Following the Introduction of an Incentive Bonus Plan with Participative Goal Setting</title><link>http://www.example.com/articles/1</link><description>Anderson, Shannon W.; Dekker, Henri C.; Sedatole, Karen L.
Prior research documents performance improvements following the implementation of pay-for-performance (PFP) bonus plans. However, bonus plans typically pay for performance relative to a goal, and the manager whose performance is to be evaluated often participates in setting the goal. In these settings, PFP affects managers' incentive to influence goal levels in addition to affecting performance effort. Prior field research is silent on the effect of PFP on goals, the focus of this paper. Using sales and sales goal data from 61 stores of a U.S. retail firm over 10 quarters, we find that the introduction of a performance-based bonus plan with participative goal setting is accompanied by lower goals that are more accurate predictors of subsequent sales performance. Statistical tests indicate that increased goal accuracy is attributable to managers "meeting but not beating" goals and to new information being impounded in goals. We further investigate how differences among managers are associated with goal levels. We find significant "manager effects" but no "supervisor effects." In additional tests we find that cross-sectional differences among managers are related to differing marginal returns to slack-building effort. Turning to the role of new information on goals, we find that prior period performance has incremental power to explain goal levels in the postplan period. Our results provide field-based evidence that PFP and participative goal setting affect the level and accuracy of goals, effects that are associated with both information exchange and with managers' incentives to influence goals.</description><author>Anderson, Shannon W.; Dekker, Henri C.; Sedatole, Karen L.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Design of Decision-Making Organizations</title><link>http://www.example.com/articles/1</link><description>Christensen, Michael; Knudsen, Thorbjorn
Starting from the premise that individuals within an organization are fallible, this paper advances the study of relationships between the organization's decision-making structure and its performance. We offer a general treatment that allows one to analyze the full range of organizational architectures between extreme centralized and decentralized forms (often referred to as hierarchies and polyarchies). Our approach furthermore allows designers to examine the change in the overall reliability of the organizational structure as the number of actors within the organization changes. We provide general proofs that show how decision-making structures can be constructed so they maximize reliability for a given number of agents. Our model can be used directly for a qualitative assessment of decision-making structures. It is thereby useful for assessment of the many complicated hybrid structures that we see in actual decision-making organizations, such as banks, purchasing departments, and military intelligence. An application from a bank illustrates how our framework can be used in practice.</description><author>Christensen, Michael; Knudsen, Thorbjorn</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Another Hidden Cost of Incentives: The Detrimental Effect on Norm Enforcement</title><link>http://www.example.com/articles/1</link><description>Fuster, Andreas; Meier, Stephan
Monetary incentives, such as subsidies or bonuses, are often considered as a way to foster contributions to public goods in society and firms. This paper investigates experimentally the effect of private contribution incentives in the presence of a norm enforcement mechanism. Norm enforcement through peer punishment has been shown to be effective in raising contributions by itself. We test whether and how (centrally provided) private incentives interact with (decentralized) punishment, both of which affect subjects' monetary payoffs. The results of our experiment show that private incentives for contributors can reduce the effectiveness of the norm enforcement mechanism: Free riders are punished less harshly in the treatment with incentives, and as a consequence, average contributions to the public good are no higher than without incentives. This finding ties to and extends previous research on settings in which monetary incentives may fail to have the desired effect.</description><author>Fuster, Andreas; Meier, Stephan</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Lone Inventors as Sources of Breakthroughs: Myth or Reality?</title><link>http://www.example.com/articles/1</link><description>Singh, Jasjit; Fleming, Lee
Are lone inventors more or less likely to invent breakthroughs? Recent research has attempted to resolve this question by considering the variance of creative outcome distributions. It has implicitly assumed a symmetric thickening or thinning of both tails, i.e., that a greater probability of breakthroughs comes at the cost of a greater probability of failures. In contrast, we propose that collaboration can have opposite effects at the two extremes: it reduces the probability of very poor outcomes-because of more rigorous selection processes-while simultaneously increasing the probability of extremely successful outcomes-because of greater recombinant opportunity in creative search. Analysis of over half a million patented inventions supports these arguments: Individuals working alone, especially those without affiliation to organizations, are less likely to achieve breakthroughs and more likely to invent particularly poor outcomes. Quantile regressions demonstrate that the effect is more than an upward mean shift. We find partial mediation of the effect of collaboration on extreme outcomes by the diversity of technical experience of team members and by the size of team members' external collaboration networks. Supporting our meta-argument for the importance of examining each tail of the distribution separately, experience diversity helps trim poor outcomes significantly more than it helps create breakthroughs, relative to the effect of external networks.</description><author>Singh, Jasjit; Fleming, Lee</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Pricing with Speculators and Strategic Consumers</title><link>http://www.example.com/articles/1</link><description>Su, Xuanming
This paper studies a monopolist firm selling a fixed capacity. The firm sets a price before demand uncertainty is resolved. Speculators may enter the market purely with the intention of resale, which can be profitable if demand turns out to be high. Consumers may strategically choose when to purchase, and they may also choose to purchase from the firm or from the speculators. We characterize equilibrium prices and profits and analyze the long-run capacity decisions of the firm. There are three major findings. First, the presence of speculators increases the firm's expected profits even though the resale market competes with the firm. Second, by facilitating resale, the firm can mimic dynamic pricing outcomes and enjoy the associated benefits while charging a fixed price. Third, speculative behavior may generate incentives for the seller to artificially restrict supply, and thus may lead to lower capacity investments. We also explore several model extensions that highlight the robustness of our results.</description><author>Su, Xuanming</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Cost Structure, Customer Profitability, and Retention Implications of Self-Service Distribution Channels: Evidence from Customer Behavior in an Online Banking Channel</title><link>http://www.example.com/articles/1</link><description>Campbell, Dennis; Frei, Frances
This paper uses the context of online banking to investigate the consequences of using self-service distribution channels to alter customer interactions with the firm. Using a sample of retail banking customers observed over a 30-month period at a large U.S. bank, we test whether changes in service consumption, cost to serve, and customer profitability are associated with the adoption of online banking. We find that customer adoption of online banking is associated with (1) substitution, primarily from incrementally more costly self-service delivery channels (automated teller machine and voice response unit); (2) augmentation of service consumption in more costly service delivery channels (branch and call center); (3) a substantial increase in total transaction volume; (4) an increase in estimated average cost to serve resulting from the combination of points (1)-(3); and (5) a reduction in short-term customer profitability. However, we find that use of the online banking channel is associated with higher customer retention rates over one-, two-, and three-year horizons. The documented relationship between the use of online banking and customer retention remains positive even after controlling for self-selection into the online channel. We also find evidence that future market shares for our sample firm are systematically higher in markets with high contemporaneous utilization rates for the online banking channel. This finding holds even after controlling for contemporaneous market share, suggesting it is not simply the result of increased market power leading to the acquisition of online banking customers.</description><author>Campbell, Dennis; Frei, Frances</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Management Science 2009 Report</title><link>http://www.example.com/articles/1</link><description>Cachon, Gerard P.
nan</description><author>Cachon, Gerard P.</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>A Quantitative Measurement of Regret Theory</title><link>http://www.example.com/articles/1</link><description>Bleichrodt, Han; Cillo, Alessandra; Diecidue, Enrico
This paper introduces a method to measure regret theory, a popular theory of decision under uncertainty. Regret theory allows for violations of transitivity, and it may seem paradoxical to quantitatively measure an intransitive theory. We adopt the trade-off method and show that it is robust to violations of transitivity. Our method makes no assumptions about the shape of the functions reflecting utility and regret. It can be performed at the individual level, taking account of preference heterogeneity. Our data support the main assumption of regret theory, that people are disproportionately averse to large regrets, even when event-splitting effects are controlled for. The findings are robust: similar results were obtained in two measurements using different stimuli. The data support the reliability of the trade-off method: its measurements could be replicated using different stimuli and were not susceptible to strategic responding.</description><author>Bleichrodt, Han; Cillo, Alessandra; Diecidue, Enrico</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Coping with Uncertainties in Technological Learning</title><link>http://www.example.com/articles/1</link><description>Ma, Tieju
To date, optimization models of endogenous technological change commonly deal with uncertainty in technological learning with risk-factor methods, i.e., by adding expected risk costs resulting from overestimating technological learning rates into an objective function with a subjective risk factor. This paper argues that another way of coping with the uncertainty, risk-constrained methods that have been ignored in existing literatures, could be more practicable (at least as a supplement) for decision support. With a simplified model, this paper explores technology development paths generated by two risk-constrained methods, and compares the two risk-constrained methods with a risk-factor method. Our study shows that comparing with the risk-factor method, the two risk-constrained methods also generate an S-shaped technology diffusion pattern, which accords with historical observations, and they can result in earlier as well as later adoption of an advanced but currently expensive technology, depending on different combinations of uncertainty levels of the technology learning rate and the upper limit on the expected risk cost. Another finding of our research is that two totally different technology development paths can both be optimal solutions, which implies that with early policy interventions there is the possibility that an economy could be led to a low-carbon economy with little additional cost.</description><author>Ma, Tieju</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Drivers of Finished-Goods Inventory in the US Automobile Industry</title><link>http://www.example.com/articles/1</link><description>Cachon, Gerard P.; Olivares, Marcelo
Automobile manufacturers in the U.S. supply chain exhibit significant differences in their days of supply of finished vehicles (average inventory divided by average daily sales rate). For example, from 1995 to 2004, Toyota consistently carried approximately 30 fewer days of supply than General Motors. This suggests that Toyota's well-documented advantage in manufacturing efficiency, product design, and upstream supply chain management extends to their finished-goods inventory in their downstream supply chain from their assembly plants to their dealerships. Our objective in this research is to measure for this industry the effect of several factors on inventory holdings. We find that two factors, the number of dealerships in a manufacturer's distribution network and a manufacturer's production flexibility, explain essentially all of the difference in finished-goods inventory between Toyota and three other manufacturers: Chrysler, Ford, and General Motors.</description><author>Cachon, Gerard P.; Olivares, Marcelo</author><pubDate>Fri, 01 Jan 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Divisor-Based Biproportional Apportionment in Electoral Systems: A Real-Life Benchmark Study</title><link>http://www.example.com/articles/1</link><description>Maier, Sebastian; Zachariassen, Petur; Zachariasen, Martin
Biproportional apportionment methods provide two-way proportionality in electoral systems where the electoral region is subdivided into electoral districts. The problem is to assign integral values to the elements of a matrix that are proportional to a given input matrix, and such that a set of row-and column-sum requirements are fulfilled. In a divisor-based method for biproportional apportionment, the problem is solved by computing appropriate row and column divisors, and by rounding the quotients. We present a comprehensive experimental evaluation of divisor-based biproportional apportionment in an electoral system context. By performing experiments on real-life benchmark instances (election data with multimember districts), we evaluate the general quality of divisor-based apportionments with respect to, e. g., deviation from quota, reversal orderings, and occurrences of ties. For example, we studied the frequency in which a party with a higher vote count in a district ended up with fewer seats in that district.</description><author>Maier, Sebastian; Zachariassen, Petur; Zachariasen, Martin</author><pubDate>Mon, 01 Feb 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Interaction Effect of Rivalry Restraint and Competitive Advantage on Profit: Why the Whole Is Less Than the Sum of the Parts</title><link>http://www.example.com/articles/1</link><description>Makadok, Richard
Rivalry-restraint-based theoretical mechanisms predict that an industry's profits will increase when its firms engage in less price competition, or less direct competition, with each other. Competitive-advantage-based theoretical mechanisms predict that a firm's profits will increase when it creates superior economic value that direct and indirect competitors cannot fully compete away. But what is the interaction effect on profit of simultaneously restraining rivalry and increasing competitive advantage? Do they positively amplify/reinforce each other, or negatively dampen/undermine each other? This paper's theoretical model predicts a negative interaction effect, with potentially significant implications for theory, practice, and pedagogy.</description><author>Makadok, Richard</author><pubDate>Mon, 01 Feb 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Timing of RFID Adoption in a Supply Chain</title><link>http://www.example.com/articles/1</link><description>Whang, Seungjin
This paper studies the incentives behind the adoption of radio-frequency identification (RFID) in a supply chain. One prominent feature of RFID technology is that once RFID tags are attached on the items at an upstream site, the same tags can be reused at its downstream sites at lower or zero variable cost. This creates an interesting, one-sided "free-rider" problem, where the downstream would wait to free-ride on the upstream's first move, but not vice versa. Using a stylized game-theoretic model, we characterize the equilibrium strategies of the two firms. Compared to the first-best solution, firms in equilibrium tend to adopt too late. We then study the dual benefits of technology coordination between the two firms and find that it would not only save redundant costs of putting tags, but also speed up the downstream's RFID adoption. We also show that the equal-cost-split arrangement shifts the bene. t of free-riding to the upstream, thereby mitigating the negative impacts in many cases. But it may distort the market when it operates in the optimal manner. The general message of the model is that technology coordination and cost-split each contribute to the mitigation of the free-rider problem in RFID adoption.</description><author>Whang, Seungjin</author><pubDate>Mon, 01 Feb 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Buyer Uncertainty and Two-Part Pricing: Theory and Applications</title><link>http://www.example.com/articles/1</link><description>Png, I. P. L.; Wang, Hao
We consider two-part pricing of a service offered to risk-averse buyers subject to demand uncertainty. Buyers subscribe to the contract before resolution of the uncertainty. Sellers set two-part prices that trade off between insuring buyers against the uncertainty and the ex post deadweight loss from inefficient usage. If marginal and total benefits from the service are positively correlated (a sufficient condition is that the uncertainty not directly affect the buyer benefit), the usage charge should be set above the marginal cost of the service. If marginal and total benefits are negatively correlated, the usage charge should be set below the marginal cost. These results apply whether the seller has market power or is subject to competition. The difference between the profit-maximizing usage charge and marginal cost increases with buyer risk aversion. Our results can be extended to the case of the seller being more risk averse than the buyers. We discuss applications to pricing of beach and ski resorts, lines of credit, utility computing, and government services.</description><author>Png, I. P. L.; Wang, Hao</author><pubDate>Mon, 01 Feb 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Perturbation of Numerical Confidential Data via Skew-t Distributions</title><link>http://www.example.com/articles/1</link><description>Lee, Seokho; Genton, Marc G.; Arellano-Valle, Reinaldo B.
We propose a new data perturbation method for numerical database security problems based on skew-t distributions. Unlike the normal distribution, the more general class of skew-t distributions is a flexible parametric multivariate family that can model skewness and heavy tails in the data. Because databases having a normal distribution are seldom encountered in practice, the newly proposed approach, coined the skew-t data perturbation (STDP) method, is of great interest for database managers. We also discuss how to preserve the sample mean vector and sample covariance matrix exactly for any data perturbation method. We investigate the performance of the STDP method by means of a Monte Carlo simulation study and compare it with other existing perturbation methods. Of particular importance is the ability of STDP to reproduce characteristics of the joint tails of the distribution in order for database users to answer higher-level questions. We apply the STDP method to a medical database related to breast cancer.</description><author>Lee, Seokho; Genton, Marc G.; Arellano-Valle, Reinaldo B.</author><pubDate>Mon, 01 Feb 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Cross-Function and Same-Function Alliances: How Does Alliance Structure Affect the Behavior of Partnering Firms?</title><link>http://www.example.com/articles/1</link><description>Amaldoss, Wilfred; Staelin, Richard
Firms collaborate to develop and deliver new products. These collaborations vary in terms of the similarity of the competencies that partnering firms bring to the alliance. In same-function alliances, partnering firms have similar competencies, whereas in cross-function alliances, partners have very different competencies. On examining managers' view of these alliances, we find that, on average, same-function alliances are expected to perform better than cross-function alliances, holding fixed the level of inputs. A game-theoretic analysis shows that this apprehension about cross-function alliances is consistent with a Pareto-inferior equilibrium. A Pareto-superior equilibrium, however, suggests that partners in cross-function alliances may invest more in their alliances than those in same-function alliances. It is also often believed that increasing the number of partnering firms is not conducive for collaborative effort. Our analysis shows that this belief is correct for same-function alliances, but not for cross-function alliances. We test these equilibrium predictions in an experiment where we exogenously vary the type of alliance and the number of partnering firms. The experimental results lend support for the Pareto-superior equilibrium. Partners in cross-function alliances invested more than their counterparts in same-function alliances, and this difference in investment levels increased with the number of partnering firms. We extend our model to consider alliances where firms have an opportunity to learn from their partners and later leverage this knowledge outside the scope of their alliance. Though such learning increases the resources committed by alliance partners in the learning phase, it decreases investment in the subsequent competition and also dampens the overall investment across the two stages. In addition, an increase in interalliance competition decreases investments in the focal alliance but increases investment in the competition outside the scope of the alliance.</description><author>Amaldoss, Wilfred; Staelin, Richard</author><pubDate>Mon, 01 Feb 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Predicting Utility Under Satiation and Habit Formation</title><link>http://www.example.com/articles/1</link><description>Baucells, Manel; Sarin, Rakesh K.
We introduce a modi. cation of the discounted utility model that accounts for both satiation and habit formation in intertemporal choice. Preferences depend on the satiation level and the habitual consumption level. These two state variables, together with the shape of the value function, drive the properties of the model. One unique feature of our model is that it addresses the trade-off between seeking variety and maintaining acquired habits. We examine several properties of our model, such as the nontrivial patterns of desirability (willingness to pay) for an additional unit of consumption, or the effect of abstaining from consumption (craving). We explore the shape of optimal consumption patterns in discrete and continuous choice settings. If subjects underestimate the changes in satiation and habituation levels, as occurs under projection bias, our model explains why people buy more when hungry, or prefer variety in advance of consumption but stay with the same consumption good in actual use.</description><author>Baucells, Manel; Sarin, Rakesh K.</author><pubDate>Mon, 01 Feb 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Managing Know-How</title><link>http://www.example.com/articles/1</link><description>Lee, Deishin; Van den Steen, Eric
We study how firms can use a knowledge management system to optimally leverage employee-generated know-how. In particular, we consider the following practical strategic questions for the manager of a knowledge-intensive firm: Should her firm develop a formal knowledge system? And if so, how should it be managed, particularly in terms of what information to record? We find that firms benefit more from a knowledge system when they are larger, face the same issues more frequently, have higher turnover, and face problems about which there is less general knowledge. In terms of what information to record, a key insight is that recording moderately successful practices can be counterproductive, because doing so may inefficiently reduce employees' incentives to experiment. This "strong-form competency trap" forces firms into an exploration exploitation trade-off. Firms that value a knowledge system most should also be most selective in recording information. We further find that recording successes is more valuable than recording failures, which supports firms' focus on best practice. Beyond these main principles, we also show that it may be optimal to disseminate know-how on a plant level but not on a firm level, and that recording backup solutions is most valuable at medium levels of environmental change.</description><author>Lee, Deishin; Van den Steen, Eric</author><pubDate>Mon, 01 Feb 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Hybrid Entrepreneurship</title><link>http://www.example.com/articles/1</link><description>Folta, Timothy B.; Delmar, Frederic; Wennberg, Karl
In contrast to previous efforts to model an individual's movement from wage work into entrepreneurship, we consider that individuals might transition incrementally by retaining their wage job while entering into self-employment. We show that these hybrid entrepreneurs represent a significant share of all entrepreneurial activity. Theoretical arguments are proposed to suggest why hybrid entrants are distinct from self-employment entrants, and why hybrid entry may facilitate subsequent entry into full self-employment. We demonstrate that there are significant theoretical and empirical consequences for this group and our understanding of self-employment entry and labor market dynamics. Using matched employee-employer data over eight years, we test the model on a population of Swedish wage earners in the knowledge-intensive sector.</description><author>Folta, Timothy B.; Delmar, Frederic; Wennberg, Karl</author><pubDate>Mon, 01 Feb 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>An Empirical Analysis of Mobile Voice Service and SMS: A Structural Model</title><link>http://www.example.com/articles/1</link><description>Kim, Youngsoo; Telang, Rahul; Vogt, William B.; Krishnan, Ramayya
In addition to the wireless telephony boom, a similar exponentially increasing trend in wireless data service for example, short message service (SMS)-is visible as technology advances. We develop a structural model to examine user demand for voice service and SMS. Specifically, we measure the own-and cross-price elasticities of these services. The cross-price elasticity is of significant importance because marketing activities are critically influenced by whether the goods are substitutes or complements. The research context poses significant econometric challenges due to three-part tariffs and sequential discrete plan choice and continuous quantity choice decisions. Using detailed individual consumption data of more than 6,000 customers, we find that SMS and voice service are small substitutes. A 10% increase in the price of voice minutes will induce about a 0.8% increase in the demand for SMS. The own-price elasticity of voice is also low, to the order of approximately -0.1. Younger users' demand is far more inelastic than that of older users. We then conduct counterfactual policy experiments that fully capture the effects of changes in key parameters on the firm's revenues. Finally, we discuss the generalizability of our framework.</description><author>Kim, Youngsoo; Telang, Rahul; Vogt, William B.; Krishnan, Ramayya</author><pubDate>Mon, 01 Feb 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Securing the Containerized Supply Chain: Analysis of Government Incentives for Private Investment</title><link>http://www.example.com/articles/1</link><description>Bakshi, Nitin; Gans, Noah
To mitigate the threat that terrorists smuggle weapons of mass destruction into the United States through maritime containers, the U. S. Bureau of Customs and Border Protection (CBP) inspects containers upon entry to domestic ports. Inspection-driven congestion is costly, and CBP provides incentives to firms to improve security upstream in the supply chain, thereby reducing the inspection burden at U. S. ports. We perform an economic analysis of this incentive program, called Customs-Trade Partnership Against Terrorism (C-TPAT), modeling in a game-theoretic framework the strategic interaction between CBP, trading firms, and terrorists. Our equilibrium results highlight the possibility that a properly run program can efficiently shift some of CBP's security burden to private industry. These results also suggest that CBP may have the opportunity to use strategic delay as an incentive for firms to join. Analysis of comparative statics shows that, with increasing capacity, membership in C-TPAT systematically declines.</description><author>Bakshi, Nitin; Gans, Noah</author><pubDate>Mon, 01 Feb 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Effects of Litigation Risk on Board Oversight and CEO Incentive Pay</title><link>http://www.example.com/articles/1</link><description>Laux, Volker
Various commentators have praised the WorldCom and Enron settlements for holding outside directors personally liable, arguing that heightened director liability will induce greater board oversight. This paper shows that the connection between director liability and board behavior is more subtle, because directors have multiple means to respond to an increase in liability exposure: They can increase oversight to prevent accounting manipulation and/or reduce performance-based CEO pay to mitigate the CEO's ex ante incentive to engage in manipulation. These two decisions are interrelated, implying that the effects of director liability on board oversight and CEO incentive pay are ambiguous. In particular, the model predicts that, for firms in which board oversight is difficult and costly (e. g., large firms with complex business operations), a stricter legal environment for directors leads to a lower level of board oversight, lower CEO incentive pay, and lower shareholder value.</description><author>Laux, Volker</author><pubDate>Tue, 01 Jun 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Auditor's Slippery Slope: An Analysis of Reputational Incentives</title><link>http://www.example.com/articles/1</link><description>Corona, Carlos; Randhawa, Ramandeep S.
Reputational concerns have commonly been perceived to have a positive effect on auditing firms' execution of their monitoring and attesting functions. This paper demonstrates that this need not always be the case by studying a two-period game of repeated interaction between a manager and an auditor under the assessment of the market for audit services. Regarding reputation as the sole motivator for the auditor, we illustrate how reputational concerns induce an auditing firm to misreport. We investigate the reasons and circumstances under which such misreporting takes place. In particular, a strategic manager can induce the audit firm down a slippery slope, wherein the managerial fraud increases as the tenure of the audit firm progresses, whereas the auditor's fraud reporting probability decreases.</description><author>Corona, Carlos; Randhawa, Ramandeep S.</author><pubDate>Tue, 01 Jun 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Impossible Frontiers</title><link>http://www.example.com/articles/1</link><description>Brennan, Thomas J.; Lo, Andrew W.
A key result of the capital asset pricing model (CAPM) is that the market portfolio-the portfolio of all assets in which each asset's weight is proportional to its total market capitalization-lies on the mean-variance-efficient frontier, the set of portfolios having mean-variance characteristics that cannot be improved upon. Therefore, the CAPM cannot be consistent with efficient frontiers for which every frontier portfolio has at least one negative weight or short position. We call such efficient frontiers "impossible," and show that impossible frontiers are difficult to avoid. In particular, as the number of assets, n, grows, we prove that the probability that a generically chosen frontier is impossible tends to one at a geometric rate. In fact, for one natural class of distributions, nearly one-eighth of all assets on a frontier is expected to have negative weights for every portfolio on the frontier. We also show that the expected minimum amount of short selling across frontier portfolios grows linearly with n, and even when short sales are constrained to some finite level, an impossible frontier remains impossible. Using daily and monthly U. S. stock returns, we document the impossibility of efficient frontiers in the data.</description><author>Brennan, Thomas J.; Lo, Andrew W.</author><pubDate>Tue, 01 Jun 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Management Insights</title><link>http://www.example.com/articles/1</link><description>Gorman, Michael F.
nan</description><author>Gorman, Michael F.</author><pubDate>Tue, 01 Jun 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Quick Response and Retailer Effort</title><link>http://www.example.com/articles/1</link><description>Krishnan, Harish; Kapuscinski, Roman; Butz, David A.
The benefits of supply chain innovations such as quick response (QR) have been extensively investigated. This paper highlights a potentially damaging impact of QR on retailer effort. By lowering downstream inventories, QR may compromise retailer incentives to exert sales effort on a manufacturer's product and may lead instead to greater sales effort on a competing product. Manufacturer-initiated quick response can therefore back. re, leading to lower sales of the manufacturer's product and, in some cases, to higher sales of a competing product. Evidence from case studies and interviews shows that some manufacturers view high retailer inventory as a means of increasing retailer commitment ("a loaded customer is a loyal customer"). By implication, manufacturers should recognize the effect we highlight in this paper: the potential of QR to lessen retailer sales effort. We show that relatively simple distribution contracts such as minimum-take contracts, advance-purchase discounts, and exclusive dealing, when adopted in conjunction with QR, can remedy the distortionary impact of QR on retailers' incentives. In two recent antitrust cases we find evidence that, consistent with our theory, manufacturers adopted exclusive dealing at almost the same time that they were making QR-type supply chain improvements.</description><author>Krishnan, Harish; Kapuscinski, Roman; Butz, David A.</author><pubDate>Tue, 01 Jun 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Positioning and Pricing in a Variety Seeking Market</title><link>http://www.example.com/articles/1</link><description>Sajeesh, S.; Raju, Jagmohan S.
We study competitive positioning and pricing strategies in markets where consumers seek variety. Variety seeking behavior is modeled as a decrease in the willingness to pay for the product purchased on the previous purchase occasion. Using a three-stage Hotelling-type model, we show that the presence of variety seeking consumers reduces product differentiation offered in equilibrium, thereby explaining some otherwise counterintuitive findings in empirical research. We find that firms charge higher prices in Period 1 and lower prices in Period 2. The lower price in Period 2 represents the price incentive that firms need to offer to prevent the variety seeking consumers from switching. Furthermore, we find that the observed switching in a market may not fully capture the true magnitude of the underlying variety seeking tendencies among consumers. Finally, we show that the presence of variety seeking consumers leads to lower firm profits and a higher consumer surplus. Surplus increases for variety seeking consumers as well as regular consumers. Therefore, the presence of variety seeking consumers benefits everyone in the market.</description><author>Sajeesh, S.; Raju, Jagmohan S.</author><pubDate>Tue, 01 Jun 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Quality Management and Job Quality: How the ISO 9001 Standard for Quality Management Systems Affects Employees and Employers</title><link>http://www.example.com/articles/1</link><description>Levine, David I.; Toffel, Michael W.
Several studies have examined how the ISO 9001 quality management systems standard predicts changes in organizational outcomes such as profits. This is the first large-scale study to explore how employee outcomes such as employment, earnings, and health and safety change when employers adopt ISO 9001. We analyzed a matched sample of nearly 1,000 companies in California. ISO 9001 adopters subsequently had far lower organizational death rates than a matched control group of nonadopters. Among surviving employers, ISO adopters had higher growth rates for sales, employment, payroll, and average annual earnings. Injury rates declined slightly for ISO 9001 adopters, although total injury costs did not. These results have implications for organizational theory, managers, and public policy.</description><author>Levine, David I.; Toffel, Michael W.</author><pubDate>Tue, 01 Jun 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>On the Optimal Product Line Selection Problem with Price Discrimination</title><link>http://www.example.com/articles/1</link><description>Schoen, Cornelia
Product line design decisions are determinant for a firm's market success and, simultaneously, very costly to implement and change. To evaluate the profitability of a design, a number of mathematical programming approaches have been proposed in the last three decades-typically nonlinear integer optimization problems that can only be tackled heuristically for real-world instances. Recently, Chen and Hausman (2000) efficiently exploited the fractional programming properties of a stylized model for product line and price selection with the objective to maximize contribution given homogeneous customer behavior by an aggregate multinomial logit choice model. We extend the approach of Chen and Hausman (Chen, K. D., W. H. Hausman. 2000. Technical note: Mathematical properties of the optimal product line selection problem using choice-based conjoint analysis. Management Sci. 46(2) 327-332) to determine an optimal product line under a personalized or group pricing strategy in markets with multiple heterogeneous consumers such that total profit (including fixed costs) is maximized. Personalized/group pricing is a growing discrimination strategy that more and more businesses are realizing is not only very pro. table, but also often implementable in the era of e-business. Our problem formulation allows to incorporate commonly applied attraction choice models including the multinomial logit, the Bradley-Terry-Luce, and approximately the first choice model. Though the problem is generally nonlinear, we show that the fractional substructure resulting from attraction choice models can still be exploited to globally solve real-world instances in reasonable time.</description><author>Schoen, Cornelia</author><pubDate>Sat, 01 May 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Windows for Aggregating Ratings in Electronic Marketplaces</title><link>http://www.example.com/articles/1</link><description>Aperjis, Christina; Johari, Ramesh
A seller in an online marketplace with an effective reputation mechanism should expect that dishonest behavior results in higher payments now whereas honest behavior results in a better reputation-and thus higher payments-in the future. We study the Window Aggregation Mechanism, a widely used class of mechanisms that shows the average value of the seller's ratings within some fixed window of past transactions. We suggest approaches for choosing the window size that maximizes the range of parameters for which it is optimal for the seller to be truthful. We show that mechanisms that use information from a larger number of past transactions tend to provide incentives for patient sellers to be more truthful but for higher-quality sellers to be less truthful.</description><author>Aperjis, Christina; Johari, Ramesh</author><pubDate>Sat, 01 May 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Markets for Inventors: Learning-by-Hiring as a Driver of Mobility</title><link>http://www.example.com/articles/1</link><description>Palomeras, Neus; Melero, Eduardo
Hiring away inventors has long been recognized as a way of learning used by innovative firms. This paper claims that the characteristics of the knowledge accumulated by an inventor at his current employer affect what hiring firms can learn from him. The implication is that some inventors are more likely to be hired away than their coworkers. We analyze the relationship between the type of knowledge embodied by inventors working at IBM and their probability of moving. Relying on patent data to track the movement of inventors across firms and to characterize the kind of know-how they hold, we identify the following drivers of inventor mobility: the quality of their work; the complementarity of their knowledge with that of other inventors; and, to a lower extent, their expertise in the firm's core areas in which the firm is not a dominant player. Results confirm the role of knowledge characteristics behind the mobility of research and development personnel and suggest that learning is a relevant force in the market for inventors.</description><author>Palomeras, Neus; Melero, Eduardo</author><pubDate>Sat, 01 May 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Contracting for Collaborative Services</title><link>http://www.example.com/articles/1</link><description>Roels, Guillaume; Karmarkar, Uday S.; Carr, Scott
In this paper, we analyze the contracting issues that arise in collaborative services, such as consulting,financial planning, and information technology outsourcing. In particular, we investigate how the choice of contract type-among fixed-fee, time-and-materials, and performance-based contracts-is driven by the service environment characteristics. We find that fixed-fee contracts contingent on performance are preferred when the service output is more sensitive to the vendor's effort, that time-and-materials contracts are optimal when the output is more sensitive to the buyer's effort, and that performance-based contracts dominate when the output is equally sensitive to both the buyer's and the vendor's inputs. We also discuss how the performance of these contracts is affected with output uncertainty, process improvement opportunities, and the involvement of multiple buyers and vendors in the joint-production process. Our model highlights the trade-offs underlying the choice of contracts in a collaborative service environment and identifies service process design changes that improve contract efficiency.</description><author>Roels, Guillaume; Karmarkar, Uday S.; Carr, Scott</author><pubDate>Sat, 01 May 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Assessing Joint Distributions with Isoprobability Contours</title><link>http://www.example.com/articles/1</link><description>Abbas, Ali E.; Budescu, David V.; Gu, Yuhong
We present a new method for constructing joint probability distributions of continuous random variables using isoprobability contours-sets of points with the same joint cumulative probability. This approach reduces the joint probability assessment into a one-dimensional cumulative probability assessment using a sequence of binary choices between various combinations of the variables of interest. The approach eliminates the need to assess directly the dependence, or association, between the variables. We discuss properties of isoprobability contours and methods for their assessment in practice. We also report results of a study in which subjects assessed the 50th percentile isoprobability contour of the joint distribution of weight and height. We use the data to show how to use the assessed contours to construct the joint distribution and to infer (indirectly) the dependence between the variables.</description><author>Abbas, Ali E.; Budescu, David V.; Gu, Yuhong</author><pubDate>Tue, 01 Jun 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Operational Flexibility and Financial Hedging: Complements or Substitutes?</title><link>http://www.example.com/articles/1</link><description>Chod, Jiri; Rudi, Nils; Van Mieghem, Jan A.
We consider a firm that invests in capacity under demand uncertainty and thus faces two related but distinct types of risk: mismatch between capacity and demand and profit variability. Whereas mismatch risk can be mitigated with greater operational. exibility, pro. t variability can be reduced through. nancial hedging. We show that the relationship between these two risk mitigating strategies depends on the type of. exibility: Product. exibility and. nancial hedging tend to be complements (substitutes) -i. e., product. exibility tends to increase (decrease) the value of. nancial hedging, and, vice versa,. nancial hedging tends to increase (decrease) the value of product. exibility -when product demands are positively (negatively) correlated. In contrast to product. exibility, postponement. exibility is a substitute to. nancial hedging as intuitively expected. Although our analytical results assume perfect. exibility and perfect hedging and rely on a linear approximation of the value of hedging, we validate their robustness in an extensive numerical study.</description><author>Chod, Jiri; Rudi, Nils; Van Mieghem, Jan A.</author><pubDate>Tue, 01 Jun 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Contingent Effects of Quality Signaling: Evidence from the Indian Offshore IT Services Industry</title><link>http://www.example.com/articles/1</link><description>Gao, Guodong; Gopal, Anandasivam; Agarwal, Ritu
W e examine the heterogeneous returns to third-party quality signals in the context of the Indian software services industry. Prior theory has argued that quality certification is important in markets characterized by information asymmetry. However, there is limited understanding of the contingent factors that influence the efficacy of the quality signal. We focus on capability maturity model (CMM) certification, which is granted on the basis of a rigorous audit of software vendor's internal quality-oriented software construction practices, as a signal of unobservable quality. Drawing upon prior research in strategy and economics, we theorize that the impacts of CMM certification on a vendor's export performance are conditional on factors reflecting the vendor's strategy (diversification and location) and its competitive environment (the extent of CMM penetration in the vendor's competition). Analysis of panel data supports our predictions related to the contingent value of CMM certification, and shows that a software service provider gains more from certification in terms of its software exports when its service offerings are diversified, when it chooses to locate away from a cluster of other software service firms, and when the extent of CMM penetration in the competition is low. This study extends prior research in the information value of a quality signal on a firm's demand side that has, for the most part, focused solely on direct effects. We discuss the implications of our findings for the strategic trade-offs that managers of software service firms need to make.</description><author>Gao, Guodong; Gopal, Anandasivam; Agarwal, Ritu</author><pubDate>Tue, 01 Jun 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Hierarchical Structure and Search in Complex Organizations</title><link>http://www.example.com/articles/1</link><description>Mihm, Juergen; Loch, Christoph H.; Wilkinson, Dennis; Huberman, Bernardo A.
Organizations engage in search whenever they perform nonroutine tasks, such as the definition and validation of a new strategy, the acquisition of new capabilities, or new product development. Previous work on search and organizational hierarchy has discovered that a hierarchy with a central decision maker at the top can speed up problem solving, but possibly at the cost of solution quality compared with results of a decentralized search. Our study uses a formal model and simulations to explore the effect of an organizational hierarchy on solution stability, solution quality, and search speed. Three insights arise on how a hierarchy can improve organizational search: (1) assigning a lead function that "anchors" a solution speeds up problem solving; (2) local solution choice should be delegated to the lowest level; and (3) structure matters little at the middle management level, but it matters at the front line; front-line groups should be kept small. These results highlight the importance for every organization of adapting its hierarchical structure to its search requirements.</description><author>Mihm, Juergen; Loch, Christoph H.; Wilkinson, Dennis; Huberman, Bernardo A.</author><pubDate>Sat, 01 May 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Valuing Money and Things: Why a $20 Item Can Be Worth More and Less Than $20</title><link>http://www.example.com/articles/1</link><description>McGraw, A. Peter; Sharif, Eldar; Todorov, Alexander
The study of risky decision making has long used monetary gambles to study choice, but many everyday decisions do not involve the prospect of winning or losing money. Monetary gambles, as it turns out, may be processed and evaluated differently than gambles with nonmonetary outcomes. Whereas monetary gambles involve numeric amounts that can be straightforwardly combined with probabilities to yield at least an approximate "expectation" of value, nonmonetary outcomes are typically not numeric and do not lend themselves to easy combination with the associated probabilities. Compared with monetary gambles, the evaluation of nonmonetary prospects typically proves less sensitive to changes in the probability range (inside the extremes of certainty and impossibility), which, among other things, can yield preference reversals. Generalizing on earlier work that attributed similar findings to the role of affect in the evaluation process (Rottenstreich, Y., C. K. Hsee. 2001. Money, kisses, and electric shocks: An affective psychology of risk. Psych. Sci. 12(3) 185-190), we attribute the observed patterns to a fundamental difference in the evaluation of monetary versus nonmonetary outcomes. Potential pitfalls in the use of monetary gambles to study choice are highlighted, and implications and future directions are discussed.</description><author>McGraw, A. Peter; Sharif, Eldar; Todorov, Alexander</author><pubDate>Sat, 01 May 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Dynamic Programming Models and Algorithms for the Mutual Fund Cash Balance Problem</title><link>http://www.example.com/articles/1</link><description>Nascimento, Juliana; Powell, Warren
Fund managers have to decide the amount of a fund's assets that should be kept in cash, considering the trade-off between being able to meet shareholder redemptions and minimizing the opportunity cost from lost investment opportunities. In addition, they have to consider redemptions by individuals as well as institutional investors, the current performance of the stock market and interest rates, and the pattern of investments and redemptions that are correlated with market performance. We formulate the problem as a dynamic program, but this encounters the classic curse of dimensionality. To overcome this problem, we propose a provably convergent approximate dynamic programming algorithm. We also adapt the algorithm to an online environment, requiring no knowledge of the probability distributions for rates of return and interest rates. We use actual data for market performance and interest rates, and demonstrate the quality of the solution (compared to the optimal) for the top 10 mutual funds in each of nine fund categories. We show that our results closely match the optimal solution (in considerably less time), and outperform two static (newsvendor) models. The result is a simple policy that describes when money should be moved into and out of cash based on market performance.</description><author>Nascimento, Juliana; Powell, Warren</author><pubDate>Sat, 01 May 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Reality Check: Combining Choice Experiments with Market Data to Estimate the Importance of Product Attributes</title><link>http://www.example.com/articles/1</link><description>Feit, Eleanor McDonnell; Beltramo, Mark A.; Feinberg, Fred M.
Discrete choice models estimated using hypothetical choices made in a survey setting (i.e., choice experiments) are widely used to estimate the importance of product attributes in order to make product design and marketing mix decisions. Choice experiments allow the researcher to estimate preferences for product features that do not yet exist in the market. However, parameters estimated from experimental data often show marked inconsistencies with those inferred from the market, reducing their usefulness in forecasting and decision making. We propose an approach for combining choice-based conjoint data with individual-level purchase data to produce estimates that are more consistent with the market. Unlike prior approaches for calibrating conjoint models so that they correctly predict aggregate market shares for a "baseline" market, the proposed approach is designed to produce parameters that are more consistent with those that can be inferred from individual-level market data. The proposed method relies on a new general framework for combining two or more sources of individual-level choice data to estimate a hierarchical discrete choice model. Past approaches to combining choice data assume that the population mean for the parameters is the same across both data sets and require that data sets are sampled from the same population. In contrast, we incorporate in the model individual characteristic variables, and assert only that the mapping between individuals' characteristics and their preferences is the same across the data sets. This allows the model to be applied even if the sample of individuals observed in each data set is not representative of the population as a whole, so long as appropriate product-use variables are collected that can explain the systematic deviations between them. The framework also explicitly incorporates a model for the individual characteristics, which allows us to use Bayesian missing-data techniques to handle the situation where each data set contains different demographic variables. This makes the method useful in practice for a wide range of existing market and conjoint data sets. We apply the method to a set of conjoint and market data for minivan choice and find that the proposed method predicts holdout market choices better than a model estimated from conjoint data alone or a model that does not include demographic variables.</description><author>Feit, Eleanor McDonnell; Beltramo, Mark A.; Feinberg, Fred M.</author><pubDate>Sat, 01 May 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Ordering Behavior in Retail Stores and Implications for Automated Replenishment</title><link>http://www.example.com/articles/1</link><description>van Donselaar, Karel H.; Gaur, Vishal; van Woensel, Tom; Broekmeulen, Rob A. C. M.; Fransoo, Jan C.
Retail store managers may not follow order advices generated by an automated inventory replenishment system if their incentives differ from the cost-minimization objective of the system or if they perceive the system to be suboptimal. We study the ordering behavior of retail store managers in a supermarket chain to characterize such deviations in ordering behavior, investigate their potential drivers, and thereby devise a method to improve automated replenishment systems. Using orders, shipments, and point-of-sale data for 19,417 item-store combinations over five stores, we show that (i) store managers consistently modify automated order advices by advancing orders from peak to nonpeak days, and (ii) this behavior is explained significantly by product characteristics such as case pack size relative to average demand per item, net shelf space, product variety, demand uncertainty, and seasonality error. Our regression results suggest that store managers improve upon the automated replenishment system by incorporating two ignored factors: in-store handling costs and sales improvement potential through better in-stock. Based on these results, we construct a method to modify automated order advices by learning from the behavior of store managers. Motivated by the management coefficients theory, our method is efficient to implement and outperforms store managers by achieving a more balanced handling workload with similar average days of inventory.</description><author>van Donselaar, Karel H.; Gaur, Vishal; van Woensel, Tom; Broekmeulen, Rob A. C. M.; Fransoo, Jan C.</author><pubDate>Sat, 01 May 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Are Foreign IT Workers Cheaper? US Visa Policies and Compensation of Information Technology Professionals</title><link>http://www.example.com/articles/1</link><description>Mithas, Sunil; Lucas, Henry C.
The use of H-1B and other work visas to hire foreign information technology (IT) professionals in the United States has attracted significant controversy and policy debates. On one hand, hiring high-skill foreign IT professionals on work visas can be advantageous for U.S. firms and the overall economy. On the other hand, high-skill immigration can adversely impact the wages of foreign and American IT professionals. This study uses data on skills and compensation of more than 50,000 IT professionals in the United States over the period 2000-2005 to study patterns in compensation of foreign and American IT professionals to inform these debates. Contrary to the popular belief that foreign workers are a cheap source of labor for U.S. firms,we find that after controlling for their human capital attributes, foreign IT professionals (those without U. S. citizenship and those with H-1B or other work visas) earn a salary premium when compared with IT professionals with U. S. citizenship. The salary premiums for non-U.S. citizens and for those on work visas fluctuate in response to supply shocks created by the annual caps on new H-1B visas. Setting lower and fully utilized annual caps results in higher salary premiums for non-U.S. citizens and those with work visas. We discuss implications of this study for crafting informed visa-and immigration-related policies by the U. S. government, for staffing practices of firms, and for human capital investments by IT professionals.</description><author>Mithas, Sunil; Lucas, Henry C.</author><pubDate>Sat, 01 May 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Idea Generation and the Quality of the Best Idea</title><link>http://www.example.com/articles/1</link><description>Girotra, Karan; Terwiesch, Christian; Ulrich, Karl T.
In a wide variety of settings, organizations generate a number of possible solutions to a problem-ideas-and then select a few for further development. We examine the effectiveness of two group structures for such tasks-the team structure, in which the group works together in time and space, and the hybrid structure, in which individuals first work independently and then work together. We define the performance of a group as the quality of the best ideas identified. Prior research has defined performance as the average quality of ideas or the number of ideas generated, ignoring what most organizations seek, a few great ideas. We build a theory that relates organizational phenomena to four different variables that govern the quality of the best ideas identified: (1) the average quality of ideas generated, (2) the number of ideas generated, (3) the variance in the quality of ideas generated, and (4) the ability of the group to discern the quality of the ideas. We test this theory with an experiment. We find that groups organized in the hybrid structure are able to generate more ideas, to generate better ideas, and to better discern the quality of the ideas they generate. Moreover, we find that the frequently recommended brainstorming technique of building on others' ideas is counterproductive; teams exhibiting such buildup neither create more ideas, nor are the ideas that build on previous ideas better.</description><author>Girotra, Karan; Terwiesch, Christian; Ulrich, Karl T.</author><pubDate>Thu, 01 Apr 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Prior Consequences and Subsequent Risk Taking: New Field Evidence from the Taiwan Futures Exchange</title><link>http://www.example.com/articles/1</link><description>Liu, Yu-Jane; Tsai, Chih-Ling; Wang, Ming-Chun; Zhu, Ning
We use a data set from market participants in the Taiwan Stock Exchange Capitalization Weighted Stock Index options markets to demonstrate a strong positive relationship between prior trading outcomes and subsequent risk taking. In particular, investors in this market take above-average risks in afternoon trading after morning gains. The phenomenon is prevalent in all three types of market makers' accounts and across different types of market participants. Our findings are consistent with the argument that prior outcomes affect subsequent risk taking through a relationship that is sensitive to the model parameters (i.e., expected return, trading period, and curvature of the value function), because prospect theory can predict both increased and decreased levels of subsequent risk taking. We provide possible explanations behind the phenomenon and discuss reasons for the variety of findings in the existing literature.</description><author>Liu, Yu-Jane; Tsai, Chih-Ling; Wang, Ming-Chun; Zhu, Ning</author><pubDate>Thu, 01 Apr 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Reference Groups and Product Line Decisions: An Experimental Investigation of Limited Editions and Product Proliferation</title><link>http://www.example.com/articles/1</link><description>Amaldoss, Wilfred; Jain, Sanjay
Some luxury goods manufacturers offer limited editions of their products, whereas some others market multiple product lines. Researchers have found that reference groups shape consumer evaluations of these product categories. Yet little empirical research has examined how reference groups affect the product line decisions of firms. Indeed, in a field setting it is quite a challenge to isolate reference group effects from contextual effects and correlated effects. In this paper, we propose a parsimonious model that allows us to study how reference groups influence firm behavior and that lends itself to experimental analysis. With the aid of the model, we investigate the behavior of consumers in a laboratory setting where we can focus on the reference group effects after controlling for the contextual and correlated effects. The experimental results show that in the presence of strong reference group effects, limited editions and multiple products can help improve firms' profits. Furthermore, the trends in the purchase decisions of our participants point to the possibility that they are capable of introspecting close to two steps of thinking at the outset of the game and then learning through reinforcement mechanisms.</description><author>Amaldoss, Wilfred; Jain, Sanjay</author><pubDate>Thu, 01 Apr 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Discretionary Disclosure of Proprietary Information in a Multisegment Firm</title><link>http://www.example.com/articles/1</link><description>Arya, Anil; Frimor, Hans; Mittendorf, Brian
The seminal "unraveling" result in the disclosure literature posits that discretion inevitably leads to full disclosure, even when such disclosure has detrimental consequences. In this paper, we revisit optimal disclosure of proprietary information when firms compete in multiple markets. The analysis demonstrates that in the presence of multiple segments, the unraveling result applies at the firmwide level but not necessarily segment by segment. Instead, when the firm has an ex ante desire to withhold information and segments are sufficiently similar, the ex post disclosure equilibrium entails aggregation of segment details. Aggregation arises because any ex post temptation to disaggregate and reveal particularly favorable news in one segment entails revealing unfavorable news in another segment. A desire to balance profits across segments then leads a firm to disclose firmwide information (a temptation that cannot be avoided), but only in the aggregate.</description><author>Arya, Anil; Frimor, Hans; Mittendorf, Brian</author><pubDate>Thu, 01 Apr 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Information-Based Stock Trading, Executive Incentives, and the Principal-Agent Problem</title><link>http://www.example.com/articles/1</link><description>Kang, Qiang; Liu, Qiao
We examine the role of information-based stock trading in affecting the risk-incentive relation. By incorporating an endogenous informed trading into an optimal incentive contracting model, we analytically show that, apart from reducing incentives, a greater risk increases the level of information-based trading, which consequently enhances executive incentives and offsets the negative risk-incentive relation. We calibrate the model and find that the economic magnitude of this incentive-enhancement effect is significant. Our empirical test using real-world executive compensation data lends strong support to the model prediction. Our results suggest that principals (boards of directors) should consider underlying stock trading characteristics when structuring executive incentives.</description><author>Kang, Qiang; Liu, Qiao</author><pubDate>Thu, 01 Apr 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Analytic Hierarchy Process and the Theory of Measurement</title><link>http://www.example.com/articles/1</link><description>Bernasconi, Michele; Choirat, Christine; Seri, Raffaello
The analytic hierarchy process (AHP) is a decision-making procedure widely used in management for establishing priorities in multicriteria decision problems. Underlying the AHP is the theory of ratio-scale measures developed in psychophysics since the middle of the last century. It is, however, well known that classical ratio-scaling approaches have several problems. We reconsider the AHP in the light of the modern theory of measurement based on the so-called separable representations recently axiomatized in mathematical psychology. We provide various theoretical and empirical results on the extent to which the AHP can be considered a reliable decision-making procedure in terms of the modern theory of subjective measurement.</description><author>Bernasconi, Michele; Choirat, Christine; Seri, Raffaello</author><pubDate>Thu, 01 Apr 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>A General Index of Absolute Risk Attitude</title><link>http://www.example.com/articles/1</link><description>Denuit, Michel M.; Eeckhoudt, Louis
M any results involving expected utility theory call upon the notions of absolute risk aversion, prudence, and/or temperance. This paper exploits a representation of the Friedman-Savage utility premium (Friedman, M., L. J. Savage. 1948. The utility analysis of choices involving risk. J. Political Econom. 56(4) 279-304) to give a general foundation for such coefficients and for their higher-order extensions.</description><author>Denuit, Michel M.; Eeckhoudt, Louis</author><pubDate>Thu, 01 Apr 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Empirical Analysis of Ambulance Travel Times: The Case of Calgary Emergency Medical Services</title><link>http://www.example.com/articles/1</link><description>Budge, Susan; Ingolfsson, Armann; Zerom, Dawit
Using administrative data for high-priority calls in Calgary, Alberta, we estimate how ambulance travel times depend on distance. We find that a logarithmic transformation produces symmetric travel-time distributions with heavier tails than those of a normal distribution. Guided by nonparametric estimates of the median and coefficient of variation, we demonstrate that a previously proposed model for mean fire engine travel times is a valid and useful description of median ambulance travel times. We propose a new specification for the coefficient of variation, which decreases with distance. We illustrate how the resulting travel-time distribution model can be used to create probability-of-coverage maps for diagnosis and improvement of system performance.</description><author>Budge, Susan; Ingolfsson, Armann; Zerom, Dawit</author><pubDate>Thu, 01 Apr 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Enhancing the Motivational Affordance of Information Systems: The Effects of Real-Time Performance Feedback and Goal Setting in Group Collaboration Environments</title><link>http://www.example.com/articles/1</link><description>Jung, J. H.; Schneider, Christoph; Valacich, Joseph
Increasing globalization has created tremendous opportunities and challenges for organizations and societies. Consequently, a broad range of information technologies to better support the collaboration of diverse, and increasingly distributed, sets of participants is ever more utilized. Arguably, the success of such technology-mediated collaboration is dependent upon the quality of each individual's contributions; however, although individuals' motivations to do their best could be significantly influenced by the design of a system's human-computer interface, this area has received little attention within the context of group collaboration environments. We fill this gap by integrating research from human-computer interaction, motivation, and technology-supported group work to theoretically derive mechanisms for increasing each individual's motivation within a collective setting. Specifically, we manipulate the interface of a computer-mediated idea generation system (a widely used collaboration tool) to enhance the system's motivational affordance, i.e., the system's properties that fulfill users' motivational needs. Results from two studies demonstrate that by embedding the theoretically derived mechanisms "providing feedback" and "designing for optimal challenge" into the collaboration environment, significant performance gains were realized. The results suggest that even slight manipulations of the human-computer interface can contribute significantly to the successful design of a wide variety of group collaboration environments.</description><author>Jung, J. H.; Schneider, Christoph; Valacich, Joseph</author><pubDate>Thu, 01 Apr 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Small Firm Effect and the Entrepreneurial Spawning of Scientists and Engineers</title><link>http://www.example.com/articles/1</link><description>Elfenbein, Daniel W.; Hamilton, Barton H.; Zenger, Todd R.
Scientists and engineers in small firms are far more likely than their large firm counterparts to enter entrepreneurship. We label this phenomenon the small firm effect and explore its origins. In particular, we identify four classes of explanations for the small firm effect-preference sorting, ability sorting, opportunity cost, and the possibility that workers in small firms develop entrepreneurial human capital-and examine the empirical evidence for each. We find that preference sorting does play a role in generating the small firm effect: small firms attract those with prior preferences for autonomy who are similarly drawn into entrepreneurship. Similarly, ability sorting plays a role: those who ultimately become entrepreneurs may be drawn first to small firms because they offer tighter pay-for-performance links and can subsequently improve their expected earnings by becoming entrepreneurs, or because the skills required for success in small firms are also valuable in entrepreneurship. Evidence suggests that although those with the very least to lose do enter entrepreneurship with greater frequency, opportunity cost has at best a modest role to play in explaining the small firm effect. Finally, we interpret evidence that prior experience in small firms predicts positive performance outcomes in the early stages of entrepreneurship as suggesting that workers in small firms may develop entrepreneurial human capital that makes them better entrepreneurs. This effect may be largest among those of high ability.</description><author>Elfenbein, Daniel W.; Hamilton, Barton H.; Zenger, Todd R.</author><pubDate>Thu, 01 Apr 2010 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Formal Contracts in the Presence of Relational Enforcement Mechanisms: Evidence from Technology Development Projects</title><link>http://www.example.com/articles/1</link><description>Ryall, Michael D.; Sampson, Rachelle C.
Formal contracting addresses the moral hazard problems inherent in interfirm deals via explicit terms designed to achieve incentive alignment. Alternatively, when firms expect to interact repeatedly, relational mechanisms may achieve similar results without the associated costs. However, as we now know from a growing body of theoretical and empirical work, the resulting intuition-that relational mechanisms will be substituted for formal ones whenever possible-does not generally hold. The extent to which firms substitute relational mechanisms for formal ones in the presence of repeated interaction is an empirical question that forms the basis of this paper. We study a sample of 52 joint technology development contracts in the telecommunications and microelectronics industries and devise a coding scheme to allow empirical comparison of contract terms. Counter to the above intuition (but consistent with recent research), we find that a firm's contracts are more detailed and more likely to include penalties when it engages in frequent deals (whether with the same or different partners). Our results suggest complementarity between formal and relational contracts, and have implications for optimal contracting, particularly in high technology sectors.</description><author>Ryall, Michael D.; Sampson, Rachelle C.</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Mobility, Skills, and the Michigan Non-Compete Experiment</title><link>http://www.example.com/articles/1</link><description>Marx, Matt; Strumsky, Deborah; Fleming, Lee
Whereas a number of studies have considered the implications of employee mobility, comparatively little research has considered institutional factors governing the ability of employees to move from one firm to another. This paper explores a legal constraint on mobility-employee non-compete agreements-by exploiting Michigan's apparently inadvertent 1985 reversal of its non-compete enforcement policy as a natural experiment. Using a differences-in-differences approach, and controlling for changes in the auto industry central to Michigan's economy, we find that the enforcement of non-competes indeed attenuates mobility. Moreover, non-compete enforcement decreases mobility more sharply for inventors with firm-specific skills and for those who specialize in narrow technical fields. The results speak to the literature on employee mobility while offering a credibly exogenous source of variation that can extend previous research on the implications of such mobility.</description><author>Marx, Matt; Strumsky, Deborah; Fleming, Lee</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Employment Horizon and the Choice of Performance Measures: Empirical Evidence from Annual Bonus Plans of Loss-Making Entities</title><link>http://www.example.com/articles/1</link><description>Matejka, Michal; Merchant, Kenneth A.; Van der Stede, Wim A.
We examine the extent to which employment horizon concerns affect the relative emphasis on financial versus nonfinancial performance measures in annual bonus plans. We argue that managers of loss-making firms are likely to voluntarily or forcibly depart in the near future and, consequently, have a shorter employment horizon. Loss-making firms then need to increase the emphasis on forward-looking nonfinancial performance measures to motivate long-term effort of their managers. Thus, we hypothesize that the emphasis on nonfinancial performance measures is greater in loss making than in profitable firms even after controlling for the informativeness of earnings. We find consistent support for our hypothesis using different (archival, survey, and field) data sources and various proxies for short employment horizon and the emphasis on nonfinancial performance measures.</description><author>Matejka, Michal; Merchant, Kenneth A.; Van der Stede, Wim A.</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Entry Timing in Markets with Social Influence</title><link>http://www.example.com/articles/1</link><description>Joshi, Yogesh V.; Reibstein, David J.; Zhang, Z. John
Firms routinely face the challenging decision of whether to enter a new market where a firm's strong presence in an existing market has a positive influence (the leverage effect) on product adoption in the new market, but the reciprocal social influence on the existing market is negative (the backlash effect). In this paper, we show that a firm's optimal entry strategy in this situation cannot be characterized by the familiar "now or never" or "now or at maturity" strategies proposed in the literature. We show that a strong leverage effect does not necessarily provide the justification for a firm to enter a new market, and neither should a strong backlash effect necessarily deter a firm from embracing a new market. The optimal strategy is predicated on a judicious trade-off between the three factors of leverage, backlash, and patience. Thus, an astute manager can always find the opportune time to enter the new market if she takes into account the dynamic and recursive nature of cross-market interaction effects, where leverage enhances the backlash but backlash weakens the leverage in a nonlinear, dynamic fashion. We illustrate that firms stand to benefit from explicit considerations of these effects in deciding whether and when to enter a new market. Furthermore, we explore how the optimal time of entry into the new market relates to the time of peak sales for the existing market, demonstrating that depending on the interactive effects of leverage and backlash, entry could be optimal either before or after peak sales in the existing market.</description><author>Joshi, Yogesh V.; Reibstein, David J.; Zhang, Z. John</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Electronic and Physical Market Channels: A Multiyear Investigation in a Market for Products of Uncertain Quality</title><link>http://www.example.com/articles/1</link><description>Overby, Eric; Jap, Sandy
Many markets that have traditionally relied on collocation of buyers, sellers, and products have introduced electronic channels. Although these electronic channels may provide benefits to buyers and sellers by lowering the transaction costs of participating in the market, there are trade-offs related to quality uncertainty and increased risk that may limit the adoption of the electronic channels. As a result, buyers and sellers use physical channels for some transactions and electronic channels for others. These usage patterns may evolve over time, particularly when the electronic channels are new. We examine buyer and seller use of electronic and physical channels in a market for products of uncertain quality (used vehicles) over a 2.5-year period. Results indicate that transactions involving low quality uncertainty and relatively rare products occurred in the electronic channels, whereas transactions involving high quality uncertainty and relatively plentiful products occurred in the physical channels. These patterns became clearer over time as buyers and sellers gained experience with the electronic channels. The electronic channels led to discounts for products of high quality uncertainty, but not for those of low quality uncertainty.</description><author>Overby, Eric; Jap, Sandy</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Pioneering Plus a Broad Product Line Strategy: Higher Profits or Deeper Losses?</title><link>http://www.example.com/articles/1</link><description>Boulding, William; Christen, Markus
Previous research suggests firms can build a market share advantage by preempting later entrants with a broad product line and expanding rapidly into related markets. Whether such a strategy leads to a pioneering profit advantage relative to followers also depends on its cost effects. In this paper, we examine when the market share advantage of a pioneering firm with a broad product line strategy translates into a profit advantage by examining the cost effects of this strategy. Using the profit impact of marketing strategies data and an estimation method that controls for various unobserved factors, we find significant differences between different industry settings. From these contrasting findings, we generate an emerging theoretical framework that we subject to empirical testing. We conjecture, and empirically verify, that creating a broad product line with a versioning strategy-creating variety from a standard product in anticipating customer demand-does not increase the pioneering cost disadvantage, and thus results in a pioneering profit advantage. On the other hand, with a tailoring strategy-creating variety by customizing a product to actual customer demand-a broad product line substantially increases the pioneering cost disadvantage, thereby making a preemption strategy counterproductive.</description><author>Boulding, William; Christen, Markus</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>The Name-Your-Own-Price Channel in the Travel Industry: An Analytical Exploration</title><link>http://www.example.com/articles/1</link><description>Wang, Tuo; Gal-Or, Esther; Chatterjee, Rabikar
Name-your-own-price (NYOP) retailers, such as Priceline, offer an alternative distribution channel for service providers in the travel industry such as airlines, hotels, and car rental companies. Our research employs an analytical model to identify and understand key trade-offs driving the decision by a service provider to employ an NYOP channel, assuming that such a channel is available. This decision requires the existence of forces that counteract the adverse consequences of cannibalization of sales through traditional posted-price channels. Our analysis provides some insight into these forces. Contracting with the NYOP retailer facilitates market segmentation and price discrimination, and allows for disposal of excess capacity after meeting business travel demand. However, the cost of this flexibility is that the service provider can no longer credibly precommit to maintaining high prices when there is unsold capacity. Also, when contracting with an independent retailer, the service provider is unable to extract the entire revenue generated from NYOP consumers. A key insight from our model is that the rationale for contracting with an NYOP retailer is driven by the uncertainty in business travel demand, not the expectation of excess capacity. Indeed, all else equal, the larger the capacity, the less likely it is that contracting with an NYOP retailer is the right decision on the part of the service provider.</description><author>Wang, Tuo; Gal-Or, Esther; Chatterjee, Rabikar</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>When Is Price Discrimination Profitable?</title><link>http://www.example.com/articles/1</link><description>Anderson, Eric T.; Dana, James D.
We consider a general model of monopoly price discrimination and characterize the conditions under which price discrimination is and is not profitable. We show that an important condition for profitable price discrimination is that the percentage change in surplus (i.e., consumers' total willingness to pay, less the firm's costs) associated with a product upgrade is increasing in consumers' willingness to pay. We refer to this as an increasing percentage differences condition and relate it to many known results in the marketing, economics, and operations management literatures.</description><author>Anderson, Eric T.; Dana, James D.</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Jackknife Estimator for Tracking Error Variance of Optimal Portfolios</title><link>http://www.example.com/articles/1</link><description>Basak, Gopal K.; Jagannathan, Ravi; Ma, Tongshu
We develop a jackknife estimator for the conditional variance of a minimum tracking error variance portfolio constructed using estimated covariances. We empirically evaluate the performance of our estimator using an optimal portfolio of 200 stocks that has the lowest tracking error with respect to the S&amp;P 500 benchmark when three years of daily return data are used for estimating covariances. We find that our jackknife estimator provides more precise estimates and suffers less from in-sample optimism when compared to conventional estimators.</description><author>Basak, Gopal K.; Jagannathan, Ravi; Ma, Tongshu</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Asymptotic Normality for EMS Option Price Estimator with Continuous or Discontinuous Payoff Functions</title><link>http://www.example.com/articles/1</link><description>Yuan, Zhushun; Chen, Gemai
Empirical martingale simulation (EMS) was proposed by Duan and Simonato (Duan, J.-C., J.-G. Simonato. 1998. Empirical martingale simulation for asset prices. Management Sci. 44(9) 1218-1233) as an adjustment to the standard Monte Carlo simulation to reduce simulation errors. The EMS price estimator of derivative contracts was shown to be asymptotically normally distributed in Duan et al. (Duan, J.-C., G. Gauthier, J.-G. Simonato. 2001. Asymptotic distribution of the EMS option price estimator. Management Sci. 47(8) 1122-1132) when the payoffs are piecewise linear and continuous. In this paper, we extend the asymptotic normality result to more general continuous payoffs, and for discontinuous payoffs we make a conjecture.</description><author>Yuan, Zhushun; Chen, Gemai</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Ultimatum Deadlines</title><link>http://www.example.com/articles/1</link><description>Tang, Wenjie; Bearden, J. Neil; Tsetlin, Ilia
An important characteristic of any offer is the deadline at which it expires. We consider an ultimatum deadline game in which the proposer's decision variable is the offer deadline, while the responder faces a standard finite-horizon search problem. We show that the responder's strategy is characterized by a shortest acceptable deadline: at the time of deadline, he accepts an offer if the deadline is longer than his shortest acceptable deadline, and rejects it otherwise. If the proposer has all information available to the responder, the optimal deadline is the responder's shortest acceptable deadline. If the proposer is uncertain about the responder's situation, the optimal deadline gets longer, unless this uncertainty is very large. After normative analysis of the deadline setting problem, we present results from a behavioral study of the game. The average shortest acceptable deadline set by the responders equals the one that would maximize the expected value, whereas the proposers tend to set deadlines that are too short. The prescriptive conclusion for a proposer, emerging from the model and the experiment, is that in case of uncertainty it is better to set a deadline longer than what would be optimal if uncertainty were ignored.</description><author>Tang, Wenjie; Bearden, J. Neil; Tsetlin, Ilia</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Application-Specific R&amp;D Capabilities and the Advantage of Incumbents: Evidence from the Anticancer Drug Market</title><link>http://www.example.com/articles/1</link><description>Sosa, M. Lourdes
This paper examines the proposition that during competence-destroying technological changes, incumbents are incompetent in researching in house a radically new technology. They only retain market leadership if their undestroyed, proprietary complementary assets compensate for their research incompetence. In contrast to prior research, I propose that there is not one but two sets of capabilities necessary to execute research and development (R&amp;D), sets that differ in their market specificity: a technology-specific set (i.e., technological platforms that are non-market specific) and an application-specific set (i.e., knowledge of the application that is therefore market specific). Although all markets require both sets of capabilities to execute R&amp;D, prior research has analyzed cases where the application was not as complex, and therefore application-specific capabilities did not represent strategic factors. Because at the start of a technological discontinuity application-specific capabilities are undestroyed and have accrued only to incumbents, when complex enough, these capabilities can represent a source of competitive advantage for these firms, even in the face of competition from diversifying entrants reusing previously acquired technological platforms. I find evidence consistent with my proposition based on data on outcomes from drug discovery (as estimated through clinical endpoints in phase I trials) for firms competing in the anticancer drug market, one of the most complex markets within pharmaceuticals, as the market transitions into the biotechnology revolution. The proposition in this paper implies that although technological platforms can help firms move across markets, application-specific R&amp;D capabilities can help firms retain leadership within a market across technological discontinuities.</description><author>Sosa, M. Lourdes</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Markdown Pricing: Implications of Inventory Display Formats in the Presence of Strategic Customers</title><link>http://www.example.com/articles/1</link><description>Yin, Rui; Aviv, Yossi; Pazgal, Amit; Tang, Christopher S.
We propose a game-theoretical model of a retailer who sells a limited inventory of a product over a finite selling season by using one of two inventory display formats: display all (DA) and display one (DO). Under DA, the retailer displays all available units so that each arriving customer has perfect information about the actual inventory level. Under DO, the retailer displays only one unit at a time so that each customer knows about product availability but not the actual inventory level. Recent research suggests that when faced with strategic consumers, the retailer could increase expected profits by making an upfront commitment to a price path. We focus on such pricing strategies in this paper, and study the potential benefit of DO compared to DA, and its effectiveness in mitigating the adverse impact of strategic consumer behavior. We find support for our hypothesis that the DO format could potentially create an increased sense of shortage risk, and hence it is better than the DA format. However, although potentially beneficial, a move from DA to DO is typically very far from eliminating the adverse impact of strategic consumer behavior. We observe that, generally, it is not important for a retailer to modify the level of inventory when moving from a DA to a DO format; a change in the display format, along with an appropriate price modification, is typically sufficient. Interestingly, across all scenarios in which a change in inventory is significantly beneficial, we observed that only one of the following two actions takes place: either the premium price is increased along with a reduction in inventory, or inventory is increased along with premium price reduction. We find that the marginal benefit of DO can vary dramatically as a function of the per-unit cost to the retailer. In particular, when the retailer's per-unit cost is relatively high, but not too high to make sales unprofitable or to justify exclusive sales to high-valuation customers only, the benefits of DO appear to be at their highest level, and could reach up to 20% increase in profit. Finally, we demonstrate that by moving from DA to DO, while keeping the price path unchanged, the volatility of the retailer's profit decreases.</description><author>Yin, Rui; Aviv, Yossi; Pazgal, Amit; Tang, Christopher S.</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Experimentation in Financial Markets</title><link>http://www.example.com/articles/1</link><description>Massa, Massimo; Simonov, Andrei
In this paper, we use a unique data set on the Italian interdealer bond market to empirically estimate the process of strategic experimentation. The results show how the information generated in the process of interdealer trading affects the incentive to experiment. Upon receipt of an order, dealers deliberately engage in trade with other dealers either to exploit the information contained in the order they receive or, if they are uncertain about its quality, to assess it by actively experimenting with other dealers. We therefore identify "hiding" and "experimenting" as main types of dealer strategies.</description><author>Massa, Massimo; Simonov, Andrei</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Product Differentiation, Store Differentiation, and Assortment Depth</title><link>http://www.example.com/articles/1</link><description>Hamilton, Stephen F.; Richards, Timothy J.
This paper considers the relationship between product differentiation, store differentiation, and the equilibrium depth of the product assortment. We find an inverted U-shaped relationship between product differentiation and assortment depth, with the depth of the assortment rising at first and then falling with the degree of product differentiation. For product categories that consist of relatively nondifferentiatied variants, a positive relationship arises between assortment depth and category sales, whereas a negative relationship emerges between assortment depth and sales in categories with more differentiated variants. Both the extent and manner in which store differentiation changes has important implications for assortment depth. If retailer market power is augmented following the closure of rival retailers, product assortments become deeper; however, if retailers gain market power by investing in store attributes that facilitate customer loyalty, product assortments become shallower.</description><author>Hamilton, Stephen F.; Richards, Timothy J.</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Responding to Unexpected Overloads in Large-Scale Service Systems</title><link>http://www.example.com/articles/1</link><description>Perry, Ohad; Whitt, Ward
We consider how two networked large-scale service systems that normally operate separately, such as call centers, can help each other when one encounters an unexpected overload and is unable to immediately increase its own staffing. Our proposed control activates serving some customers from the other system when a ratio of the two queue lengths ( numbers of waiting customers) exceeds a threshold. Two thresholds, one for each direction of sharing, automatically detect the overload condition and prevent undesired sharing under normal loads. After a threshold has been exceeded, the control aims to keep the ratio of the two queue lengths at a specified value. To gain insight, we introduce an idealized stochastic model with two customer classes and two associated service pools containing large numbers of agents. To set the important queue-ratio parameters, we consider an approximating deterministic fluid model. We determine queue-ratio parameters that minimize convex costs for this fluid model. We perform simulation experiments to show that the control is effective for the original stochastic model. Indeed, the simulations show that the proposed queue-ratio control with thresholds outperforms the optimal fixed partition of the servers given known fixed arrival rates during the overload, even though the proposed control does not use information about the arrival rates.</description><author>Perry, Ohad; Whitt, Ward</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Price and Product Quality Decisions in a Distribution Channel</title><link>http://www.example.com/articles/1</link><description>Xu, Xiaowei
This paper studies a joint pricing and product quality decision problem in a distribution channel, in which a manufacturer sells a product through a retailer. The manufacturer jointly determines the wholesale price and quality of the product, and the retailer determines the retail price. We find that if the marginal revenue function is strictly concave, then the manufacturer chooses a lower product quality level than if selling the product directly to customers. If the marginal revenue function is affine, then the manufacturer's optimal product quality decision is independent of the distribution channel structure. If the marginal revenue function is strictly convex, then the manufacturer chooses a higher product quality level than if selling the product directly to customers.</description><author>Xu, Xiaowei</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Product Variety and Endogenous Pricing with Evaluation Costs</title><link>http://www.example.com/articles/1</link><description>Villas-Boas, J. Miguel
One important decision firms must make is to select the product line ( characteristics and number of products) to offer consumers. This paper explores the effect of the interaction between consumer evaluation costs and pricing on the optimal product line length to offer consumers. Before deciding to buy a product among all products offered, a consumer learns the product line length. Given the product line length, a consumer decides whether to evaluate the products available and their prices. This decision to evaluate depends on the expected consumer surplus after the evaluation being greater than the evaluation costs. When the firm offers few products, the firm may not attract many consumers because of lack of product fit and may be forced to offer low prices. When the firm offers many products, all consumers will find a great product fit; that is, the variance of consumer valuations per product chosen is lower. This allows the firm to charge high prices to extract ex post consumer surplus, resulting in lower ex ante expected consumer surplus, which may lead consumers not to evaluate the products in the first place. That is, by offering fewer products a firm can commit not to extract all possible consumer surplus. These two forces may then lead to the existence of an interior optimal number of products to offer. The optimal number of products offered is decreasing in the evaluation costs.</description><author>Villas-Boas, J. Miguel</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Arms Race or Detente? How Interfirm Alliance Announcements Change the Stock Market Valuation of Rivals</title><link>http://www.example.com/articles/1</link><description>Oxley, Joanne E.; Sampson, Rachelle C.; Silverman, Brian S.
Most prior event studies find that the announcement of a new alliance is accompanied by a positive stock market response for the partners. This result has usually been interpreted as evidence for the prevailing view that alliances are effective vehicles for partners to acquire or access new skills and thus become stronger competitors. However, partners should also earn positive abnormal returns if alliances are used to shape competitive interactions, attenuating competitive intensity industry-wide. In this study, we disentangle these different mechanisms by examining how alliance announcements affect the stock market's evaluation of allying firms' rivals: if an alliance is expected to make partner firms more competitive, this should lead to negative abnormal returns for partners' rivals; if an alliance is expected to facilitate a reduction in competitive intensity, this should lead to positive abnormal returns for rivals. Results from an event study analysis of research and development alliances in the telecommunications and electronics industries during 1996-2004 provide evidence consistent with competition attenuation in some alliances. Our research thus challenges the increasingly narrow focus on learning and resource accumulation through alliances, and calls for broader consideration of the roles and effects of collaboration, both for individual firms and for industry structure.</description><author>Oxley, Joanne E.; Sampson, Rachelle C.; Silverman, Brian S.</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Relative Performance Compensation, Contests, and Dynamic Incentives</title><link>http://www.example.com/articles/1</link><description>Casas-Arce, Pablo; Martinez-Jerez, F. Asis
Contests (or tournaments) are pervasive in organizations. They help performance evaluation by eliminating common shocks affecting agents' performance. However, tournaments are less effective when participants have heterogeneous ability because participants may conclude that the ability gap is too large to be overcome by their effort. Our theoretical analysis shows that a similar loss of motivation arises when tournaments take place over multiple periods because interim performance acts in a way that is similar to heterogeneous ability. Analyzing the sales contests organized by a commodities company, we document that winning participants decrease their effort as their lead extends, whereas the effort of trailing participants fades only when the gap to a winning position is very large. We also show that, on average, when contests are introduced they induce a higher level of effort among participants, although the incentives weaken as the number of participants increases. Finally, we demonstrate that although retailers respond to the multiple performance dimensions of the incentive program in part by shifting effort toward sales of more expensive products, they channel most of the increased effort toward reaching more customers.</description><author>Casas-Arce, Pablo; Martinez-Jerez, F. Asis</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Unspanned Stochastic Volatility in Affine Models: Evidence from Eurodollar Futures and Options</title><link>http://www.example.com/articles/1</link><description>Bikbov, Ruslan; Chernov, Mikhail
Unspanned stochastic volatility (USV) refers to the inability of bonds to replicate volatility-sensitive derivative securities. Affine term structure models require special restrictions on the parameters to exhibit USV. We use a joint Eurodollar futures and options data set to estimate affine three-factor models with and without USV restrictions. The unrestricted model captures prices of futures and options well. Option pricing errors are much larger in the USV model. The USV model is rejected in favor of the unrestricted model based on the likelihood ratio and Wald tests. We use the implications of the unrestricted model as a benchmark for understanding the extant evidence that favors USV. Specifically, we replicate extant tests in samples simulated from the unrestricted model. We show that none of the existing findings contradict the model without USV restrictions.</description><author>Bikbov, Ruslan; Chernov, Mikhail</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Price-Dependent Profit Sharing as a Channel Coordination Device</title><link>http://www.example.com/articles/1</link><description>Foros, Oystein; Hagen, Kare P.; Kind, Hans Jarle
We show how an upstream firm, by using a price-dependent profit-sharing rule, can prevent destructive competition between downstream firms that produce relatively close substitutes. With this rule, the upstream firm induces the retailers to behave as if demand has become less price elastic. As a result, competing downstream firms will maximize aggregate total channel profit. When downstream firms are better informed about demand conditions than the upstream firm, the same outcome cannot be achieved by vertical restraints such as resale price maintenance. Price-dependent profit sharing may also ensure that the downstream firms undertake efficient market expanding investments. The model is consistent with observations from the market for content commodities distributed by mobile networks.</description><author>Foros, Oystein; Hagen, Kare P.; Kind, Hans Jarle</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Hindsight Bias, Risk Perception, and Investment Performance</title><link>http://www.example.com/articles/1</link><description>Biais, Bruno; Weber, Martin
Once they have observed information, hindsight-biased agents fail to remember how ignorant they were initially; "they knew it all along." We formulate a theoretical model of this bias, providing a foundation for empirical measures and implying that hindsight-biased agents learning about volatility will underestimate it. In an experiment involving 66 students from Mannheim University, we find that hindsight bias reduces volatility estimates. In another experiment, involving 85 investment bankers in London and Frankfurt, we find that more biased agents have lower performance. These findings are robust to differences in location, information, overconfidence, and experience.</description><author>Biais, Bruno; Weber, Martin</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Are We Wise About the Wisdom of Crowds? The Use of Group Judgments in Belief Revision</title><link>http://www.example.com/articles/1</link><description>Mannes, Albert E.
Recent research has advanced our understanding of how people use the advice of others to update their beliefs. Because groups and teams play a significant role in organizations and collectively are wiser than their individual members, it is important to understand their influence on belief revision as well. I report the results of four studies examining intuitions about group wisdom and the informational influence of groups. In their overt assessments, experimental participants rated larger groups as more accurate than smaller groups and discriminated more between them when group size was salient. When provided advice, participants relied more on groups than individuals to update their beliefs, but were only modestly sensitive to group size. Most were suboptimal in the use of that advice, overweighting their initial beliefs and underweighting the more valid judgment of the group. Thus although acknowledged in principle, the wisdom of crowds is only shallowly manifest in observed behavior.</description><author>Mannes, Albert E.</author><pubDate>Sat, 01 Aug 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Testing the APT with the Maximum Sharpe Ratio of Extracted Factors</title><link>http://www.example.com/articles/1</link><description>Zhang, Chu
This paper develops a test of the asymptotic arbitrage pricing theory (APT) via the maximum squared Sharpe ratio of the factors extracted from individual stocks using the Connor-Korajczyk method. The test treats the beta pricing relation as approximate without predetermining the systematic factors, unlike the existing tests that take the relationship as exact and systematic factors as given. This paper also examines the magnitude of pricing errors bounded partly by the maximum squared Sharpe ratio. For most 60-month subperiods of the sample, the hypothesis that the maximum squared Sharpe ratio for monthly returns is greater than 0.25 can be rejected. Simulation indicates that the average pricing error in monthly returns is less than 0.001. These results support the asymptotic APT.</description><author>Zhang, Chu</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Business Unit Reorganization and Innovation in New Product Markets</title><link>http://www.example.com/articles/1</link><description>Karim, Samina
This paper empirically examines how business unit reorganization affects innovation, and explores how the learning process may mediate this relationship. Unit reorganization is the creation, deletion, or recombination of business units within a firm. Innovation is radical and involves product market entry by a firm into markets in which it was not previously active. I test competing hypotheses that predict either a U-shape or inverted U-shape relationship between reorganization and innovation to determine whether and how learning occurs in the presence of unit-level structural change. Theoretical support is drawn from literature on dynamic capabilities and organizational learning. The sample studied is 250 medical firms belonging to the pharmaceutical, healthcare-service, and medical-device industries, studied over a 20-year period. The findings are twofold. First, reorganization is found to exhibit a U-shape relationship with innovation, supporting learning arguments that stress the importance of experiencing a cohort of multiple events. Second, only reorganization experiences within a current period affect future innovation; past experiences do not impact future innovation, implying that firms may face constraints in organizational memory. The study concludes by exploring the structural origin (i.e., from internal, acquired, or recombined units) of innovative activity within firms.</description><author>Karim, Samina</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Defining Bad News: Changes in Return Distributions That Decrease Risky Asset Demand</title><link>http://www.example.com/articles/1</link><description>Hollifield, Burton; Kraus, Alan
We provide a random variable characterization of the necessary and sufficient conditions for a shift of the distribution of rate of return on the risky asset in the two-asset portfolio problem to reduce demand for all strictly risk-averse expected-utility-maximizing investors. We also provide random variable characterizations of the shifts that reduce both demand and expected utility for all strictly risk-averse investors.</description><author>Hollifield, Burton; Kraus, Alan</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Pioneering Inventors or Thicket Builders: Which US Firms Use Continuations in Patenting?</title><link>http://www.example.com/articles/1</link><description>Hegde, Deepak; Mowery, David C.; Graham, Stuart J. H.
Why do firms use continuations in the prosecution of their patents? Motivated by the widespread use of continuations by U.S. firms and the prominence of this procedure in U. S. patent policy debates, we investigate the influence of corporate and patent characteristics on the use of continuations. We employ novel data on applicants and their filings of three types of continuations - the continuation application (CAP), the continuations in part (CIP), and divisions - during 1981 - 2000 to distinguish among the motives for continuing patents. We find that CIPs are disproportionately. led by research and development-intensive firms that patent heavily, and that these continuations are more common in chemical and biological technologies. Patents issuing from CIPs cover relatively important inventions and their use appears consistent with a strategy of protecting "pioneering inventions." In contrast, CAPs and divisions are associated with less important patents assigned to capital-intensive firms, particularly in computer and semiconductor fields, and appear to be used in defensive patenting strategies. We analyze the effects of the 1995 change in patent term, and find that the act reduced continuations overall and shifted the output of continuations toward less important patents.</description><author>Hegde, Deepak; Mowery, David C.; Graham, Stuart J. H.</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Momentum and Mean Reversion in Strategic Asset Allocation</title><link>http://www.example.com/articles/1</link><description>Koijen, Ralph S. J.; Rodriguez, Juan Carlos; Sbuelz, Alessandro
We study a dynamic asset allocation problem in which stock returns exhibit short-run momentum and long-run mean reversion. We develop a tractable continuous-time model that captures these two predictability features and derive the optimal investment strategy in closed form. The model predicts negative hedging demands for medium-term investors, and an allocation to stocks that is nonmonotonic in the investor's horizon. Momentum substantially increases the economic value of hedging time variation in investment opportunities. These utility gains are preserved when we impose realistic borrowing and short-sales constraints and allow the investor to trade on a monthly frequency.</description><author>Koijen, Ralph S. J.; Rodriguez, Juan Carlos; Sbuelz, Alessandro</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Truthful Bundle/Multiunit Double Auctions</title><link>http://www.example.com/articles/1</link><description>Chu, Leon Yang
We address the mechanism design problem for a market with multiple buyers and sellers. Each buyer demands some bundle(s) of various commodities, and each seller supplies multiple units of one commodity. To design truthful double-auction mechanisms, we propose a novel "padding" method that intentionally creates imbalances between the supply availability and demand requirement by introducing a phantom buyer with unlimited budget. To the best of our knowledge, this "padding" method leads to a class of mechanisms that are the first strategy-proof, individually rational, budget-balanced, and asymptotically efficient mechanisms for the specified exchange environment. Furthermore, these mechanisms dominate known truthful bundle/single-unit mechanisms with higher efficiency, lower buying prices, and higher selling prices.</description><author>Chu, Leon Yang</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Technological Innovation and Acquisitions</title><link>http://www.example.com/articles/1</link><description>Zhao, Xinlei
I examine whether technological innovation is a motivating factor in firms' acquisition decisions and how an acquisition (or an acquisition withdrawal) affects technological innovation in subsequent years. I find that firms engaging in acquisition activities are less innovative and have often experienced declines in technological innovation during the years prior to the bid. Among the bidders, the relatively more innovative ones are less likely to complete a deal. During the three years after the bid, successful bidders do not underperform matching firms, whereas failed bidders significantly underperform their nonbidding peers. I further find that formerly less innovative bidders benefit more from acquisitions. These findings suggest that technological innovation affects firms' acquisition decisions, and in turn, acquisitions help firms' innovation efforts.</description><author>Zhao, Xinlei</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Effort, Revenue, and Cost Sharing Mechanisms for Collaborative New Product Development</title><link>http://www.example.com/articles/1</link><description>Bhaskaran, Sreekumar R.; Krishnan, V.
The growing sophistication of component technologies and the rising costs and uncertainties of developing and launching new products require firms to collaborate in the development of new products. However, the management of new product development that occurs jointly between firms presents a new set of challenges in sharing the costs and benefits of innovation. Although collaboration enables each firm to focus on what it does best, it also introduces new issues associated with the alignment of decisions and incentives that have to be managed alongside conventional performance and timing uncertainties of new product development. In this paper, we conceptualize and formulate the joint development of products involving two firms with differing development capabilities and examine the implications of arrangements that go beyond sharing of revenues to include sharing of development cost and work. We term these approaches that involve sharing of the development cost and sharing of the development work investment sharing and innovation sharing, respectively. These cost and effort sharing mechanisms have subtle interactions with the degree to which revenues are shared between firms and the type of development project under consideration. Our analysis shows that investment and innovation sharing are particularly relevant for products with no preexisting revenues, and their benefits also depend on the degree to which revenues are shared between the firms. Whereas investment sharing is more attractive for new-to-the-world product projects with significant timing uncertainty, innovation sharing plays an important role in environments where projects experience product quality uncertainty, firms are similar in their capabilities, and the costs of integration of work across firms can be controlled. Our key contribution involves the modeling of joint work and decision making between collaborating firms and unearthing the complementary role of revenue, cost, and innovative effort sharing mechanisms for new product development. We translate our analytical findings into a managerial framework and illustrate the results with examples from the life-sciences and electronics industries.</description><author>Bhaskaran, Sreekumar R.; Krishnan, V.</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Brand and Price Advertising in Online Markets</title><link>http://www.example.com/articles/1</link><description>Baye, Michael R.; Morgan, John
We model an environment where e-retailers sell similar products and endogenously engage in both brand advertising (to create loyal customers) and price advertising (to attract "shoppers"). In contrast to models where loyalty is exogenous, endogenizing the creation of loyal customers by allowing firms to engage in brand advertising leads to a continuum of symmetric equilibria; however, there is a unique equilibrium in secure strategies, and the set of equilibria converges to this unique equilibrium as the number of potential e-retailers grows arbitrarily large. Price dispersion is a key feature of all of these equilibria, including the limit equilibrium. Branding tightens the range of prices and reduces the value of the price information provided by a comparison site, and this reduces profits for platforms (such as an Internet price comparison site) where firms advertise prices. Data from a leading price comparison site are shown to be consistent with several predictions of the model.</description><author>Baye, Michael R.; Morgan, John</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Quality Improvement Incentives and Product Recall Cost Sharing Contracts</title><link>http://www.example.com/articles/1</link><description>Chao, Gary H.; Iravani, Seyed M. R.; Savaskan, R. Canan
As companies outsource more product design and manufacturing activities to other members of the supply chain, improving end-product quality has become an endeavor extending beyond the boundaries of the firms' in-house process capabilities. In this paper, we discuss two contractual agreements by which product recall costs can be shared between a manufacturer and a supplier to induce quality improvement effort. More specifically, we consider (i) cost sharing based on selective root cause analysis (Contract S), and (ii) partial cost sharing based on complete root cause analysis (Contract P). Using insights from supermodular game theory, for each contractual agreement, we characterize the levels of effort the manufacturer and the supplier would exert in equilibrium to improve their component failure rate when their effort choices are subject to moral hazard. We show that both Contract S and Contract P can achieve the first best effort levels; however, Contract S results in higher profits for the manufacturer and the supply chain. For the case in which the information about the quality of the supplier's product is not revealed to the manufacturer (i. e., the case of information asymmetry), we develop a menu of contracts that can be used to mitigate the impact of information asymmetry. We show that the menu of contracts not only significantly decreases the manufacturer's cost due to information asymmetry, but also improves product quality.</description><author>Chao, Gary H.; Iravani, Seyed M. R.; Savaskan, R. Canan</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Selection Neglect in Mutual Fund Advertisements</title><link>http://www.example.com/articles/1</link><description>Koehler, Jonathan J.; Mercer, Molly
Mutual fund companies selectively advertise their better-performing funds. However, investors respond to advertised performance data as if those data were unselected (i.e., representative of the population). We identify the failure to discount selected or potentially selected data as selection neglect. We examine these phenomena in an archival study (Study 1) and two controlled experiments (Studies 2 and 3). Study 1 identifies selection bias in mutual fund advertising by showing that the median performance rank for advertised funds is between the 79th and 100th percentile. Study 2 finds that both novice investors and financial professionals fall victim to selection neglect in a financial advertising task unless the advertisement makes the selective nature of available performance data transparent. Study 3 shows that selection neglect associated with a large well-known company can be debiased with a simple extrinsic sample space cue, although individual differences in statistical reasoning also matter. We argue that selection neglect results from a general tendency to ignore underlying sample spaces rather than a fundamental misunderstanding about the data selection process or the value of selected data.</description><author>Koehler, Jonathan J.; Mercer, Molly</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Investor Competence, Trading Frequency, and Home Bias</title><link>http://www.example.com/articles/1</link><description>Graham, John R.; Harvey, Campbell R.; Huang, Hai
People are more willing to bet on their own judgments when they feel skillful or knowledgeable. We investigate whether this "competence effect" influences trading frequency and home bias. We find that investors who feel competent trade more often and have more internationally diversified portfolios. We also find that male investors, and investors with larger portfolios or more education, are more likely to perceive themselves as competent than are female investors, and investors with smaller portfolios or less education. Our paper also contributes to understanding the theoretical link between overconfidence and trading frequency. Existing theories on trading frequency have focused on one aspect of overconfidence, i.e., miscalibration. Our paper offers a potential mechanism for the "better-than-average" aspect of overconfidence to influence trading frequency. In the context of our paper, overconfident investors tend to perceive themselves to be more competent, and thus are more willing to act on their beliefs, leading to higher trading frequency.</description><author>Graham, John R.; Harvey, Campbell R.; Huang, Hai</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Privacy Protection and Technology Diffusion: The Case of Electronic Medical Records</title><link>http://www.example.com/articles/1</link><description>Miller, Amalia R.; Tucker, Catherine E.
This paper quantifies the effect of state privacy regulation on the diffusion of electronic medical records (EMRs). EMRs allow medical providers to store and exchange patient information using computers rather than paper records. Hospitals may be more likely to adopt EMRs if they can reassure patients that their confidentiality is legally protected. Alternatively, privacy protection may inhibit adoption if hospitals cannot benefit from easily exchanging patient information. We find that state privacy regulation restricting hospital release of health information reduces aggregate EMR adoption by hospitals by more than 24%. We present evidence that suggests that this is due to the suppression of network externalities.</description><author>Miller, Amalia R.; Tucker, Catherine E.</author><pubDate>Wed, 01 Jul 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Barter Markets for Conjoint Analysis</title><link>http://www.example.com/articles/1</link><description>Ding, Min; Park, Young-Hoon; Bradlow, Eric T.
We propose a new alternative preference measurement method, barter conjoint, to contrast with traditional choice-based conjoint (CBC) approaches. Barter conjoint collects a substantially larger amount of data compared to CBC and allows for information diffusion among respondents. We conducted two empirical studies that compare CBC (with and without incentive alignment) and barter conjoint. The studies employed a total of three product categories, each with two validation tasks (one follows immediately and one conducted two weeks later). Our results confirmed prior research that incentive alignment, in general, substantially improves out-of-sample predictive performance of CBC. Furthermore, we found barter conjoint performs substantially better than the incentive-aligned CBC. However, in the spirit of "no free lunch," barter conjoint is more taxing (in various ways) than CBC, suggesting a potential trade-off between consumer resource allocation (at the time of the task) and (managerial) predictive accuracy downstream. Given that this is the first study on barter conjoint, we discuss various limitations of the current implementation and fruitful directions for future research.</description><author>Ding, Min; Park, Young-Hoon; Bradlow, Eric T.</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>An Extension of the Internal Rate of Return to Stochastic Cash Flows</title><link>http://www.example.com/articles/1</link><description>Hazen, Gordon
The internal rate of return (IRR) is a venerable technique for evaluating deterministic cash flow streams. Part of the difficulty in extending this measure to stochastic cash flows is the lack of coherent methods for accounting for multiple or nonexistent internal rates of return in deterministic streams. Recently such a coherent theory has been developed, and we examine its implications for stochastic cash flows. We devise an extension of the deterministic IRR, which we call the stochastic rate of return on mean investment. It has significant computational and conceptual advantages over the stochastic internal rate. For instance, in the deterministic case, the standard result is that under proper conditions a cash flow stream is acceptable (in the sense of positive present value) if its internal rate exceeds the interest rate. We show that a stochastic cash flow stream is acceptable (in the sense of positive certainty equivalent expected value) if the rate of return on mean investment has a suitably defined certainty equivalent exceeding the risk-free interest rate.</description><author>Hazen, Gordon</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Dynamic Cost Reduction Through Process Improvement in Assembly Networks</title><link>http://www.example.com/articles/1</link><description>Bernstein, Fernando; Koek, A. Guerhan
We consider a decentralized assembly system in which a buyer purchases components from several first-tier suppliers. We examine the dynamics of suppliers' investments in cost-reduction initiatives over the life cycle of a product under different procurement approaches. We model the suppliers' investment decisions under cost-contingent contracts, with wholesale prices determined on the basis of the prevailing component costs, as a dynamic game in closed-loop strategies. We show that there always exists an equilibrium in which the suppliers' investments are synchronized, that is, in each period either all suppliers invest in process improvement or no supplier does. We also consider target-price contracts, under which the assembler announces the rate of component cost reduction to be achieved over the product's life cycle at the beginning of the contractual relationship. We show that target-price contracts lead to higher investment levels and profits if the rates are properly specified. In general, the equilibrium investments of the suppliers are lower than those under centralized control. The buyer can eliminate this inefficiency by subsidizing a certain fraction of the costs of investments. We extend the model to a setting with two competing assemblers and knowledge spillover at the suppliers. We find that the level of inefficiency under decentralized control decreases with increased competition and spillover rate.</description><author>Bernstein, Fernando; Koek, A. Guerhan</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>What Fraction of Stock Option Grants to Top Executives Have Been Backdated or Manipulated?</title><link>http://www.example.com/articles/1</link><description>Heron, Randall A.; Lie, Erik
We estimate that 13.6% of all option grants to top executives during the period 1996-2005 were backdated or otherwise manipulated. Our study primarily focuses on grants that were unscheduled and at-the-money, of which we estimate that 18.9% were manipulated. The fraction is 23.0% before the new two-day. ling requirement took effect on August 29, 2002, and 10.0% afterward. For the minority of grants that are not filed within the required two-day window, the fraction of manipulated grants remains as high as 19.9%. We further find a higher frequency of manipulation among tech firms, small firms, and firms with high stock price volatility. In addition, firms that use smaller (non-big-five) auditing firms are more likely to. le their grants late. Finally, at the firm level, we estimate that 29.2% of firms manipulated grants to top executives at some point between 1996 and 2005.</description><author>Heron, Randall A.; Lie, Erik</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Optimal Market Intelligence Strategy When Management Attention Is Scarce</title><link>http://www.example.com/articles/1</link><description>Christen, Markus; Boulding, William; Staelin, Richard
This paper extends the theoretical literature on firms' optimal information strategies to the situation when a firm's management attention capacity to process available data is scarce. In this case, a firm's optimal market intelligence strategy must trade off learning a little about a broad range of markets (a broad strategy) with gaining a very deep understanding of one or a few markets (a focused strategy). This trade-off is not present when data are scarce, an assumption made in most of the existing literature on optimal information search strategies. However, in data-rich environments, which are of increasing relevance given technology changes, we show a focused market intelligence strategy is always best when managers need to process a substantial amount of data before beginning to gain insights; i.e., there are increasing returns to attention. Interestingly, this focused strategy can also be best with decreasing returns to attention when (a) managers are sufficiently efficient in processing the available data and (b) managers have sufficiently strong initial priors on the unknown market parameters. We show a broad market intelligence strategy is only optimal when new data points are sufficiently redundant, i.e., when the learning rate is sufficiently decreasing with the allocation of more attention. Our results also indicate that advances in information technology can account for the pressure on firms to become more focused and that competition increases the likelihood of a focused strategy. Competition can lead to asymmetric outcomes where firms focus on different markets. Finally, we note that a focused market intelligence strategy, and thus an asymmetric allocation of attention, does not require a priori differences between firms, markets, or market-specific core capabilities. Consequently, a focused market intelligence strategy can result in market-specific core competencies and produce firm differences from equivalent starting conditions.</description><author>Christen, Markus; Boulding, William; Staelin, Richard</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>R&amp;D in the Pharmaceutical Industry: A World of Small Innovations</title><link>http://www.example.com/articles/1</link><description>Ganuza, Juan-Jose; Llobet, Gerard; Dominguez, Beatriz
It is commonly argued that in recent years pharmaceutical companies have targeted their research and development (R&amp;D) at small improvements of existing compounds instead of riskier drastic innovations. In this paper, we show that the bias in the pharmaceutical industry toward small innovations might be driven by the low sensitivity of the demand. In particular, small innovations get a proportionally larger reward because pharmaceutical firms target them at the inelastic segments of the demand. As a consequence, firms find it relatively more pro. table to invest in small innovations. We also study the effect on R&amp;D incentives of marketing strategies and regulatory instruments aimed at controlling pharmaceutical expenditure.</description><author>Ganuza, Juan-Jose; Llobet, Gerard; Dominguez, Beatriz</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Information Exchange in Group Decision Making: The Hidden Profile Problem Reconsidered</title><link>http://www.example.com/articles/1</link><description>Lightle, John P.; Kagel, John H.; Arkes, Hal R.
Group decision making provides a mechanism for channeling individual members' knowledge into productive organizational outcomes. However, in hidden pro. le experiments in which group members have common information favoring an inferior choice, with private information favoring a superior choice, groups typically choose an inferior alternative. We report a hidden profile experiment where we induce homogenous preferences over choice characteristics and provide financial incentives so that the common purpose assumptions of the model hold more completely than in past experiments. Nevertheless, groups continue to choose an inferior alternative most of the time. These failures primarily result from mistakes in recalling information. Mistakes in recalling common information (which favors an inferior candidate) are typically corrected, whereas mistakes in recalling the private information needed to uncover the hidden pro. le cannot be corrected. Therefore, the dismal performance of groups in pooling the information needed to identify the superior option primarily result from the structure of the problem rather than deficiencies in how groups share and process information. The discussions necessary to resolve mistakes in recalling common information also help to explain the often noted fact that groups spend a disproportionate amount of time discussing common information.</description><author>Lightle, John P.; Kagel, John H.; Arkes, Hal R.</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Sensitivity to Distance and Baseline Distributions in Forecast Evaluation</title><link>http://www.example.com/articles/1</link><description>Jose, Victor Richmond R.; Nau, Robert F.; Winkler, Robert L.
Scoring rules can provide incentives for truthful reporting of probabilities and evaluation measures for the probabilities after the events of interest are observed. Often the space of events is ordered and an evaluation relative to some baseline distribution is desired. Scoring rules typically studied in the literature and used in practice do not take account of any ordering of events, and they evaluate probabilities relative to a default baseline distribution. In this paper, we construct rich families of scoring rules that are strictly proper (thereby encouraging truthful reporting), are sensitive to distance (thereby taking into account ordering of events), and incorporate a baseline distribution relative to which the value of a forecast is measured. In particular, we extend the power and pseudospherical families of scoring rules to allow for sensitivity to distance, with or without a specified baseline distribution.</description><author>Jose, Victor Richmond R.; Nau, Robert F.; Winkler, Robert L.</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Trading as Entertainment?</title><link>http://www.example.com/articles/1</link><description>Dorn, Daniel; Sengmueller, Paul
Among 1,000 German brokerage clients for whom both survey responses and actual trading records are available, investors who report enjoying investing or gambling turn over their portfolio at twice the rate of their peers. Including entertainment attributes as additional explanatory variables in cross-sectional regressions of portfolio turnover on objective investor attributes more than doubles the fraction of the total variation of portfolio turnover that can be explained. The results are robust to controlling for gender and proxies for overconfidence constructed from survey responses. Nonpecuniary benefits of trading thus appear to offer a straightforward explanation of the "excessive trading puzzle."</description><author>Dorn, Daniel; Sengmueller, Paul</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Transition to Entrepreneurship from the Public Sector: Predispositional and Contextual Effects</title><link>http://www.example.com/articles/1</link><description>Ozcan, Serden; Reichstein, Toke
Studies of career dynamics implicitly claim that government employees are not entrepreneurial. Utilizing longitudinal data from the U. S. Panel Study for Income Dynamics, we investigate the reasons for the low rate of entrepreneurship from the public sector. We conjecture that it is due to labor market matching processes and the bureaucratic nature of public organizations and bureaucratization of individuals. Our life-course analysis identifies labor market matching as a major determinant: nonentrepreneurial types choose public sector employment. We also uncover tenure and context effects, which decrease and increase the hazard rate of entrepreneurial exit, respectively. Whereas the former effect points toward adaptation and internal labor market sorting, the latter draws attention to exits due to frustration.</description><author>Ozcan, Serden; Reichstein, Toke</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Competition in Service Industries with Segmented Markets</title><link>http://www.example.com/articles/1</link><description>Allon, Gad; Federgruen, Awi
We develop a model for the competitive interactions in service industries where firms cater to multiple customer classes or market segments with the help of shared service facilities or processes so as to exploit pooling benefits. Different customer classes typically have distinct sensitivities to the price of service as well as the delays encountered. In such settings firms need to determine (i) the prices charged to all customer classes; (ii) the waiting time standards, i. e., expected steady state waiting time promised to all classes; (iii) the capacity level; and (iv) a priority discipline enabling the firm to meet the promised waiting time standards under the chosen capacity level, all in an integrated planning model that accounts for the impact of the strategic choices of all competing firms. We distinguish between three types of competition: depending on whether firms compete on the basis of their prices only, waiting time standards only, or on the basis of prices and waiting time standards. We establish in each of the three competition models that a Nash equilibrium exists under minor conditions regarding the demand volumes. We systematically compare the equilibria with those achieved when the firms service each market segment with a dedicated service process.</description><author>Allon, Gad; Federgruen, Awi</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Alliance Structure and the Scope of Knowledge Transfer: Evidence from US-Japan Agreements</title><link>http://www.example.com/articles/1</link><description>Oxley, Joanne; Wada, Tetsuo
Prior research suggests that equity joint ventures (JVs) are particularly effective vehicles for accessing complex technology. Different schools of thought have emphasized different reasons why joint ventures might support greater knowledge transfer than "bare" license agreements: incentive alignment, organizational embeddedness, and enhanced administrative controls. We probe and re. ne these theoretical perspectives, drawing out implications of the different theories for the extent and speed of alliance-related knowledge transfer, as well as for knowledge "leakage" in areas not directly related to alliance activities. Using a proprietary data set derived from regulatory filings with the Japanese government we test these implications in our empirical analysis of U.S.-Japan agreements. The picture that emerges from the analysis is one of particularly intense but contained knowledge transfer in equity joint ventures, relative to bare license agreements: knowledge transfers directly related to the alliance activity are enhanced in the JV, and the speed of integration into the Japanese firm's subsequent innovations also increases. In marked contrast, leakage of unrelated technology is significantly reduced. These findings suggest that administrative structures that reduce technology leakage are a key feature of the equity joint venture, a result that is inconsistent with a "pure" knowledge-based perspective on alliances.</description><author>Oxley, Joanne; Wada, Tetsuo</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Priority Shifting and the Dynamics of Managing Eradicable Infectious Diseases</title><link>http://www.example.com/articles/1</link><description>Tebbens, Radboud J. Duintjer; Thompson, Kimberly M.
Public health budget constraints force policy makers to prioritize resources toward those interventions that yield the highest perceived benefits. Intuitively, it appears optimal to focus resources on affordable interventions against prevalent diseases. However, due to the dynamics of infectious disease eradication, policies focusing on a static perception of priorities may lead to economically suboptimal outcomes. Using a hypothetical two-disease dynamic transmission model, we explore several different decision rules with respect to vaccination policy for eradicable diseases. The simulations show that cost-effectiveness decreases as the extent of priority shifting increases. This model suggests the need for a longer-term dynamic perspective to appropriately recognize costs and benefits of different policies for eradicable diseases.</description><author>Tebbens, Radboud J. Duintjer; Thompson, Kimberly M.</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Active Feature-Value Acquisition</title><link>http://www.example.com/articles/1</link><description>Saar-Tsechansky, Maytal; Melville, Prem; Provost, Foster
Most induction algorithms for building predictive models take as input training data in the form of feature vectors. Acquiring the values of features may be costly, and simply acquiring all values may be wasteful or prohibitively expensive. Active feature-value acquisition (AFA) selects features incrementally in an attempt to improve the predictive model most cost-effectively. This paper presents a framework for AFA based on estimating information value. Although straightforward in principle, estimations and approximations must be made to apply the framework in practice. We present an acquisition policy, sampled expected utility (SEU), that employs particular estimations to enable effective ranking of potential acquisitions in settings where relatively little information is available about the underlying domain. We then present experimental results showing that, compared with the policy of using representative sampling for feature acquisition, SEU reduces the cost of producing a model of a desired accuracy and exhibits consistent performance across domains. We also extend the framework to a more general modeling setting in which feature values as well as class labels are missing and are costly to acquire.</description><author>Saar-Tsechansky, Maytal; Melville, Prem; Provost, Foster</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Coordination Mechanisms in Decentralized Serial Inventory Systems with Batch Ordering</title><link>http://www.example.com/articles/1</link><description>Shang, Kevin H.; Song, Jing-Sheng; Zipkin, Paul H.
This paper studies a periodic-review, serial supply chain in which materials are ordered and shipped according to (R, nQ) policies. Three information scenarios are considered, depending on the level of information available: echelon, local, and quasilocal. In the echelon scenario, each stage can access the inventory and cost information within its echelon (comprising the stage itself and all downstream stages); in the local scenario, each stage only accesses its own local information. Finally, in the quasilocal scenario, each stage knows its local information, plus the actual customer demands. We propose coordination schemes that regulate the stages to achieve the supply chain's optimal cost under each information setting. All these coordination schemes fit comfortably within an emerging practice called supply chain finance, which includes the organization and technology needed to implement them.</description><author>Shang, Kevin H.; Song, Jing-Sheng; Zipkin, Paul H.</author><pubDate>Wed, 01 Apr 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Forecast Accuracy Uncertainty and Momentum</title><link>http://www.example.com/articles/1</link><description>Han, Bing; Hong, Dong; Warachka, Mitch
We demonstrate that stock price momentum and earnings momentum can result from uncertainty surrounding the accuracy of cash flow forecasts. Our model has multiple information sources issuing cash flow forecasts for a stock. The investor combines these forecasts into an aggregate cash flow estimate that has minimal mean-squared forecast error. This aggregate estimate weights each cash flow forecast by the estimated accuracy of its issuer, which is obtained from their past forecast errors. Momentum arises from the investor gradually learning about the relative accuracy of the information sources and updating their weights. Empirical tests validate the model's prediction of stronger momentum in stocks with large information weight fluctuations and high forecast dispersion. We also identify return predictability attributable to changes in the information weights.</description><author>Han, Bing; Hong, Dong; Warachka, Mitch</author><pubDate>Mon, 01 Jun 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item><item><title>Blockbuster Culture's Next Rise or Fall: The Impact of Recommender Systems on Sales Diversity</title><link>http://www.example.com/articles/1</link><description>Fleder, Daniel; Hosanagar, Kartik
This paper examines the effect of recommender systems on the diversity of sales. Two anecdotal views exist about such effects. Some believe recommenders help consumers discover new products and thus increase sales diversity. Others believe recommenders only reinforce the popularity of already-popular products. This paper seeks to reconcile these seemingly incompatible views. We explore the question in two ways. First, modeling recommender systems analytically allows us to explore their path-dependent effects. Second, turning to simulation, we increase the realism of our results by combining choice models with actual implementations of recommender systems. We arrive at three main results. First, some well-known recommenders can lead to a reduction in sales diversity. Because common recommenders (e.g., collaborative filters) recommend products based on sales and ratings, they cannot recommend products with limited historical data, even if they would be rated favorably. In turn, these recommenders can create a rich-get-richer effect for popular products and vice versa for unpopular ones. This bias toward popularity can prevent what may otherwise be better consumer-product matches. That diversity can decrease is surprising to consumers who express that recommendations have helped them discover new products. In line with this, result two shows that it is possible for individual-level diversity to increase but aggregate diversity to decrease. Recommenders can push each person to new products, but they often push users toward the same products. Third, we show how basic design choices affect the outcome, and thus managers can choose recommender designs that are more consistent with their sales goals and consumers' preferences.</description><author>Fleder, Daniel; Hosanagar, Kartik</author><pubDate>Fri, 01 May 2009 00:00:00 GMT</pubDate><guid isPermaLink="true">http://www.example.com/articles/1</guid></item></channel></rss>